{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction - Aly Khater and Justin Sun\n",
    "\n",
    "In this lab, you will learn how to do stock price prediction using LSTM (don't get too happy, because there is a random component to it you cannot predict which resembles more a random walk), perform movie classification, and generate random texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION'] = 'python'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import yfinance as yf\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "%matplotlib inline\n",
    "\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Stock Price Classification\n",
    "\n",
    "In this first part, you will try to predict stock prices of any company. Instead of doing a prediction, you will try to classify stocks as `strong_buy`, `buy`, `neutral`, `sell`, `strong_sell`, if the price in the next day closed $>5\\%$, between $1\\%$ and $5\\%$, within $-1\\%$ and $1\\%$, between $-1\\%$ and $-5\\%$, and more than $-5\\%$, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-01-04</th>\n",
       "      <td>275.279999</td>\n",
       "      <td>275.279999</td>\n",
       "      <td>262.959991</td>\n",
       "      <td>266.666656</td>\n",
       "      <td>266.666656</td>\n",
       "      <td>1781700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-05</th>\n",
       "      <td>264.630005</td>\n",
       "      <td>270.463318</td>\n",
       "      <td>263.130005</td>\n",
       "      <td>268.350006</td>\n",
       "      <td>268.350006</td>\n",
       "      <td>1363800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-06</th>\n",
       "      <td>265.093323</td>\n",
       "      <td>266.666656</td>\n",
       "      <td>262.286682</td>\n",
       "      <td>264.263336</td>\n",
       "      <td>264.263336</td>\n",
       "      <td>2071200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-07</th>\n",
       "      <td>266.290009</td>\n",
       "      <td>270.136658</td>\n",
       "      <td>263.333344</td>\n",
       "      <td>269.403320</td>\n",
       "      <td>269.403320</td>\n",
       "      <td>1285500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-08</th>\n",
       "      <td>268.073334</td>\n",
       "      <td>275.130005</td>\n",
       "      <td>268.019989</td>\n",
       "      <td>272.916656</td>\n",
       "      <td>272.916656</td>\n",
       "      <td>1428600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open        High         Low       Close   Adj Close  \\\n",
       "Date                                                                     \n",
       "2021-01-04  275.279999  275.279999  262.959991  266.666656  266.666656   \n",
       "2021-01-05  264.630005  270.463318  263.130005  268.350006  268.350006   \n",
       "2021-01-06  265.093323  266.666656  262.286682  264.263336  264.263336   \n",
       "2021-01-07  266.290009  270.136658  263.333344  269.403320  269.403320   \n",
       "2021-01-08  268.073334  275.130005  268.019989  272.916656  272.916656   \n",
       "\n",
       "             Volume  \n",
       "Date                 \n",
       "2021-01-04  1781700  \n",
       "2021-01-05  1363800  \n",
       "2021-01-06  2071200  \n",
       "2021-01-07  1285500  \n",
       "2021-01-08  1428600  "
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_ticket = 'ISRG'\n",
    "stock = yf.download(stock_ticket, start='2021-01-01', end='2024-3-5', progress=False)\n",
    "stock.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-02-27</th>\n",
       "      <td>386.459991</td>\n",
       "      <td>389.470001</td>\n",
       "      <td>385.279999</td>\n",
       "      <td>386.459991</td>\n",
       "      <td>386.459991</td>\n",
       "      <td>1042900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-28</th>\n",
       "      <td>384.600006</td>\n",
       "      <td>386.750000</td>\n",
       "      <td>383.559998</td>\n",
       "      <td>386.589996</td>\n",
       "      <td>386.589996</td>\n",
       "      <td>902800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-29</th>\n",
       "      <td>384.410004</td>\n",
       "      <td>389.260010</td>\n",
       "      <td>383.929993</td>\n",
       "      <td>385.600006</td>\n",
       "      <td>385.600006</td>\n",
       "      <td>2134800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-01</th>\n",
       "      <td>383.480011</td>\n",
       "      <td>399.670013</td>\n",
       "      <td>382.320007</td>\n",
       "      <td>397.899994</td>\n",
       "      <td>397.899994</td>\n",
       "      <td>2193900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-04</th>\n",
       "      <td>398.299988</td>\n",
       "      <td>403.000000</td>\n",
       "      <td>396.510010</td>\n",
       "      <td>400.589996</td>\n",
       "      <td>400.589996</td>\n",
       "      <td>1943700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open        High         Low       Close   Adj Close  \\\n",
       "Date                                                                     \n",
       "2024-02-27  386.459991  389.470001  385.279999  386.459991  386.459991   \n",
       "2024-02-28  384.600006  386.750000  383.559998  386.589996  386.589996   \n",
       "2024-02-29  384.410004  389.260010  383.929993  385.600006  385.600006   \n",
       "2024-03-01  383.480011  399.670013  382.320007  397.899994  397.899994   \n",
       "2024-03-04  398.299988  403.000000  396.510010  400.589996  400.589996   \n",
       "\n",
       "             Volume  \n",
       "Date                 \n",
       "2024-02-27  1042900  \n",
       "2024-02-28   902800  \n",
       "2024-02-29  2134800  \n",
       "2024-03-01  2193900  \n",
       "2024-03-04  1943700  "
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first only consider the closing values of the stock prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stock.Close.plot()\n",
    "plt.title(stock_ticket)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_close = stock.Close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "2021-01-04    266.666656\n",
       "2021-01-05    268.350006\n",
       "2021-01-06    264.263336\n",
       "2021-01-07    269.403320\n",
       "2021-01-08    272.916656\n",
       "Name: Close, dtype: float64"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_close.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's consider the percent change of the next value with respect to the current value of the stock. Note that the last entry using `diff(-1)` will be `not a number`, because there is nothing to compare againt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_next = -stock_close.diff(-1) / stock_close\n",
    "stock_next.columns = ['Next']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stock_next.plot()\n",
    "plt.title('Stock Price Difference')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.021479275113030976"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std = np.std(stock_next.values[:-1])\n",
    "std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "r = np.random.normal(0, std, size=len(stock_next[:-1]))\n",
    "plt.plot(stock_next.index[:-1], r)\n",
    "plt.title('Random Walk')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(stock_next.values, bins=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "2021-01-04    0.006313\n",
       "2021-01-05   -0.015229\n",
       "2021-01-06    0.019450\n",
       "2021-01-07    0.013041\n",
       "2021-01-08   -0.006229\n",
       "Name: Close, dtype: float64"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_next.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "2024-02-27    0.000336\n",
       "2024-02-28   -0.002561\n",
       "2024-02-29    0.031898\n",
       "2024-03-01    0.006760\n",
       "2024-03-04         NaN\n",
       "Name: Close, dtype: float64"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_next.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the last entry is `not-a-number`, let's remove the last entry and create the following class values:\n",
    "\n",
    "- 0: sell\n",
    "- 1: neutral\n",
    "- 2: buy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "2024-02-26   -0.004662\n",
       "2024-02-27    0.000336\n",
       "2024-02-28   -0.002561\n",
       "2024-02-29    0.031898\n",
       "2024-03-01    0.006760\n",
       "Name: Close, dtype: float64"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_date = stock_close.index[-1]\n",
    "del stock_close[last_date]\n",
    "del stock_next[last_date]\n",
    "stock_next.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,\n",
       " array([ 0,  0,  0,  0,  0, -1,  1,  0, -1,  0,  1,  0, -1,  0,  1,  0,  0,\n",
       "        -1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, -1,  0,  0,\n",
       "         0, -1,  0,  1,  0, -1, -1,  0, -1,  1,  1,  0,  0,  0,  0,  0, -1,\n",
       "         0,  0,  0,  0,  0,  1,  0,  0,  0,  0,  1,  0,  0,  0,  0,  0,  0,\n",
       "         0,  1,  0,  0,  0,  1, -1,  0,  0,  0,  0,  0,  0,  0, -1,  0,  0,\n",
       "         0, -1,  0, -1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,\n",
       "         0,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  0,  0, -1,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  0,  0,  0,  0,  0,\n",
       "         0,  0, -1,  0,  0,  0,  0,  0, -1,  0,  0,  0,  0, -1, -1,  0,  0,\n",
       "         0, -1,  1,  0,  0, -1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, -1,  0,  0,  1,  0,\n",
       "         0, -1, -1,  0,  0, -1,  0, -1,  0,  1,  0,  0,  1,  0,  0,  0,  0,\n",
       "        -1,  0,  0,  0,  0,  1,  1,  0,  0,  0,  0,  0,  0,  0,  0, -1, -1,\n",
       "        -1,  0,  0,  0, -1,  0, -1,  0,  0, -1,  0, -1,  0,  0,  1,  1,  0,\n",
       "         1, -1,  0,  0,  0,  1,  0, -1,  0,  1,  0, -1,  0,  0, -1,  1,  0,\n",
       "         0,  0,  1,  0,  0, -1, -1,  1,  0,  0, -1,  1,  1,  0,  1, -1,  0,\n",
       "        -1,  1,  1,  1,  1,  0,  0,  0,  0, -1, -1,  0,  0, -1,  0,  1,  0,\n",
       "         0,  1,  1, -1, -1,  0, -1, -1,  1,  0,  0,  0,  1, -1, -1, -1,  0,\n",
       "         0,  0,  1,  0,  1, -1,  0,  0,  0,  0,  0,  0,  1,  0, -1,  1, -1,\n",
       "         0,  1,  0, -1, -1, -1,  0,  1, -1,  0,  0,  1,  0,  1,  0, -1,  0,\n",
       "         0,  1,  0,  0,  0,  0,  0,  0,  0,  0,  1, -1,  1,  1,  1, -1,  1,\n",
       "         0,  1,  1,  0,  0,  1,  0,  0,  0,  0, -1,  1,  0,  0,  0,  0,  0,\n",
       "         0, -1, -1,  0,  0,  1, -1,  0,  0,  0,  0,  0,  0,  1,  0,  1,  0,\n",
       "        -1,  0,  0,  0,  0,  0, -1, -1,  0,  0,  0,  1,  0,  0,  1,  1,  0,\n",
       "         0, -1,  0,  0,  0,  1, -1,  1,  0,  1,  0,  1,  0,  1,  0,  0,  0,\n",
       "         0,  0, -1,  0,  1,  0,  0,  0,  1,  1, -1,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  1,  0,  0,  0,  0,  0,  0,  0,  0,  1,  0, -1,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  1,  0,  0,  0,  0,  0, -1,  1, -1,  0,\n",
       "         0,  0, -1,  0,  0,  0,  0, -1,  1,  0, -1,  0,  1,  1, -1, -1,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0, -1,  0,  0,  0,  0,  0,  0,  0,  1,\n",
       "         0,  0,  0,  0,  0,  0,  1,  0,  1,  0,  0,  1, -1,  0,  1,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0, -1,  0,  0,  0,  0,  0,  0,  0,  0,  0, -1,  0,  0,\n",
       "         0,  0,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  1,  0,  1,  0,  1,  0,  0,  0,  0, -1, -1,  1,  0,  0,  0,  0,\n",
       "         0, -1,  0,  0,  0, -1,  0,  0,  0,  0,  0, -1, -1,  0,  0,  0,  0,\n",
       "         0,  1,  0,  1,  1,  0,  0,  0,  0, -1,  0,  0,  0,  0,  0, -1,  0,\n",
       "         0, -1, -1,  0,  0,  0,  0,  0,  0,  0, -1,  0,  0,  0,  0,  0, -1,\n",
       "        -1,  1,  0,  0,  0,  0, -1,  1,  0, -1, -1,  0,  0,  0,  1,  1,  0,\n",
       "         0,  0,  0,  0,  0,  0,  1,  0,  1,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  0,  0,  0,  1, -1,  1,  0,\n",
       "         0,  0,  0,  0,  0, -1,  0,  0,  0,  0,  1,  0,  0,  0,  0,  1,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  1,  0,  0,  0,  0,  0,  1,  0]))"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = stock_next.values\n",
    "action = np.where(\n",
    "    np.abs(values) > 0.02,\n",
    "    np.sign(values) * 1,\n",
    "    0\n",
    ").astype(np.int32)\n",
    "\n",
    "classes = len(np.unique(action))\n",
    "\n",
    "classes, action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([104., 584., 107.]),\n",
       " array([-1.        , -0.33333333,  0.33333333,  1.        ]),\n",
       " <BarContainer object of 3 artists>)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(action, bins=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `action` is still shifted by 2 from the values obtained before, so we can just add `2` to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x26010cd0d00>]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(action + (classes - 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a training window where we can use LSTM to predict our classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data, action, window=1, validation_split=0.1):\n",
    "    x = []\n",
    "    y = []\n",
    "    for i in range(window, len(data)):\n",
    "        x.append(action[i-window:i])\n",
    "        y.append(action[i])\n",
    "        \n",
    "    train_size = int((1 - validation_split) * len(x))\n",
    "    \n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    return x[:train_size], y[:train_size], x[train_size:], y[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 [0 1 2]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((697, 20), (697, 3), (78, 20), (78, 3))"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = values\n",
    "\n",
    "data = stock_close.values\n",
    "scaler = StandardScaler()\n",
    "data = scaler.fit_transform(data.reshape(-1, 1)).flatten()\n",
    "\n",
    "classes = len(np.unique(action))\n",
    "\n",
    "x_train, y_train, x_test, y_test = split_data(\n",
    "    data, action + (classes-2), window=20, validation_split=0.1)\n",
    "\n",
    "print(classes, np.unique(y_train))\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, classes)\n",
    "y_test = keras.utils.to_categorical(y_test, classes)\n",
    "\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you can create your network to try to predict wheather we should buy or sell stocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_13 (InputLayer)        [(None, 20)]              0         \n",
      "_________________________________________________________________\n",
      "embedding_9 (Embedding)      (None, 20, 4)             12        \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 128)               10368     \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 1024)              263168    \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 3)                 3075      \n",
      "=================================================================\n",
      "Total params: 309,647\n",
      "Trainable params: 309,647\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def CreateModel(i_shape, o_shape):\n",
    "  x_i = keras.layers.Input(i_shape)\n",
    "  x = keras.layers.Embedding(input_dim=3, output_dim=4)(x_i)\n",
    "  x = keras.layers.Flatten()(x)\n",
    "  x = keras.layers.Dense(128, activation='relu')(x)\n",
    "  x = keras.layers.Dropout(0.5)(x)\n",
    "  x = keras.layers.Dense(256, activation='relu')(x)\n",
    "  x = keras.layers.Dropout(0.3)(x)\n",
    "  x = keras.layers.Dense(1024, activation='relu')(x)\n",
    "  x = keras.layers.Dense(o_shape[-1], activation='softmax')(x)\n",
    "  \n",
    "  return keras.models.Model(x_i, x)\n",
    "  \n",
    "optimizer = keras.optimizers.Adam(0.00001)\n",
    "model = CreateModel(x_train.shape[1:], y_train.shape[1:])\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy', optimizer=optimizer, metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 1.0939 - acc: 0.5753 - val_loss: 1.0931 - val_acc: 0.8462\n",
      "Epoch 2/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.0898 - acc: 0.6786 - val_loss: 1.0892 - val_acc: 0.8590\n",
      "Epoch 3/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.0866 - acc: 0.7202 - val_loss: 1.0851 - val_acc: 0.8590\n",
      "Epoch 4/500\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1.0832 - acc: 0.7231 - val_loss: 1.0810 - val_acc: 0.8590\n",
      "Epoch 5/500\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1.0791 - acc: 0.7231 - val_loss: 1.0768 - val_acc: 0.8590\n",
      "Epoch 6/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.0757 - acc: 0.7231 - val_loss: 1.0724 - val_acc: 0.8590\n",
      "Epoch 7/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.0721 - acc: 0.7231 - val_loss: 1.0679 - val_acc: 0.8590\n",
      "Epoch 8/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0675 - acc: 0.7231 - val_loss: 1.0631 - val_acc: 0.8590\n",
      "Epoch 9/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0638 - acc: 0.7231 - val_loss: 1.0582 - val_acc: 0.8590\n",
      "Epoch 10/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0596 - acc: 0.7231 - val_loss: 1.0529 - val_acc: 0.8590\n",
      "Epoch 11/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0552 - acc: 0.7231 - val_loss: 1.0474 - val_acc: 0.8590\n",
      "Epoch 12/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0509 - acc: 0.7231 - val_loss: 1.0417 - val_acc: 0.8590\n",
      "Epoch 13/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0457 - acc: 0.7231 - val_loss: 1.0356 - val_acc: 0.8590\n",
      "Epoch 14/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.0405 - acc: 0.7231 - val_loss: 1.0292 - val_acc: 0.8590\n",
      "Epoch 15/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.0348 - acc: 0.7231 - val_loss: 1.0225 - val_acc: 0.8590\n",
      "Epoch 16/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.0292 - acc: 0.7231 - val_loss: 1.0152 - val_acc: 0.8590\n",
      "Epoch 17/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0237 - acc: 0.7231 - val_loss: 1.0075 - val_acc: 0.8590\n",
      "Epoch 18/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0179 - acc: 0.7231 - val_loss: 0.9996 - val_acc: 0.8590\n",
      "Epoch 19/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0123 - acc: 0.7231 - val_loss: 0.9912 - val_acc: 0.8590\n",
      "Epoch 20/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.0047 - acc: 0.7231 - val_loss: 0.9821 - val_acc: 0.8590\n",
      "Epoch 21/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9975 - acc: 0.7231 - val_loss: 0.9730 - val_acc: 0.8590\n",
      "Epoch 22/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9915 - acc: 0.7231 - val_loss: 0.9632 - val_acc: 0.8590\n",
      "Epoch 23/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9841 - acc: 0.7231 - val_loss: 0.9529 - val_acc: 0.8590\n",
      "Epoch 24/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9750 - acc: 0.7231 - val_loss: 0.9423 - val_acc: 0.8590\n",
      "Epoch 25/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9679 - acc: 0.7231 - val_loss: 0.9308 - val_acc: 0.8590\n",
      "Epoch 26/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9588 - acc: 0.7231 - val_loss: 0.9191 - val_acc: 0.8590\n",
      "Epoch 27/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9503 - acc: 0.7231 - val_loss: 0.9068 - val_acc: 0.8590\n",
      "Epoch 28/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9423 - acc: 0.7231 - val_loss: 0.8940 - val_acc: 0.8590\n",
      "Epoch 29/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.9326 - acc: 0.7231 - val_loss: 0.8808 - val_acc: 0.8590\n",
      "Epoch 30/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.9230 - acc: 0.7231 - val_loss: 0.8676 - val_acc: 0.8590\n",
      "Epoch 31/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.9158 - acc: 0.7231 - val_loss: 0.8539 - val_acc: 0.8590\n",
      "Epoch 32/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.9033 - acc: 0.7231 - val_loss: 0.8398 - val_acc: 0.8590\n",
      "Epoch 33/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.8965 - acc: 0.7231 - val_loss: 0.8256 - val_acc: 0.8590\n",
      "Epoch 34/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8851 - acc: 0.7231 - val_loss: 0.8112 - val_acc: 0.8590\n",
      "Epoch 35/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8774 - acc: 0.7231 - val_loss: 0.7969 - val_acc: 0.8590\n",
      "Epoch 36/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8706 - acc: 0.7231 - val_loss: 0.7821 - val_acc: 0.8590\n",
      "Epoch 37/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8590 - acc: 0.7231 - val_loss: 0.7678 - val_acc: 0.8590\n",
      "Epoch 38/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.8521 - acc: 0.7231 - val_loss: 0.7535 - val_acc: 0.8590\n",
      "Epoch 39/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.8427 - acc: 0.7231 - val_loss: 0.7397 - val_acc: 0.8590\n",
      "Epoch 40/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.8351 - acc: 0.7231 - val_loss: 0.7266 - val_acc: 0.8590\n",
      "Epoch 41/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8296 - acc: 0.7231 - val_loss: 0.7136 - val_acc: 0.8590\n",
      "Epoch 42/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8194 - acc: 0.7231 - val_loss: 0.7009 - val_acc: 0.8590\n",
      "Epoch 43/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8147 - acc: 0.7231 - val_loss: 0.6889 - val_acc: 0.8590\n",
      "Epoch 44/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8077 - acc: 0.7231 - val_loss: 0.6772 - val_acc: 0.8590\n",
      "Epoch 45/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8038 - acc: 0.7231 - val_loss: 0.6667 - val_acc: 0.8590\n",
      "Epoch 46/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.8022 - acc: 0.7231 - val_loss: 0.6563 - val_acc: 0.8590\n",
      "Epoch 47/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7966 - acc: 0.7231 - val_loss: 0.6469 - val_acc: 0.8590\n",
      "Epoch 48/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7911 - acc: 0.7231 - val_loss: 0.6385 - val_acc: 0.8590\n",
      "Epoch 49/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7881 - acc: 0.7231 - val_loss: 0.6311 - val_acc: 0.8590\n",
      "Epoch 50/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7847 - acc: 0.7231 - val_loss: 0.6241 - val_acc: 0.8590\n",
      "Epoch 51/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7810 - acc: 0.7231 - val_loss: 0.6173 - val_acc: 0.8590\n",
      "Epoch 52/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7805 - acc: 0.7231 - val_loss: 0.6112 - val_acc: 0.8590\n",
      "Epoch 53/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7802 - acc: 0.7231 - val_loss: 0.6063 - val_acc: 0.8590\n",
      "Epoch 54/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7811 - acc: 0.7231 - val_loss: 0.6017 - val_acc: 0.8590\n",
      "Epoch 55/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7744 - acc: 0.7231 - val_loss: 0.5972 - val_acc: 0.8590\n",
      "Epoch 56/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7811 - acc: 0.7231 - val_loss: 0.5934 - val_acc: 0.8590\n",
      "Epoch 57/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7762 - acc: 0.7231 - val_loss: 0.5903 - val_acc: 0.8590\n",
      "Epoch 58/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7762 - acc: 0.7231 - val_loss: 0.5872 - val_acc: 0.8590\n",
      "Epoch 59/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7748 - acc: 0.7231 - val_loss: 0.5841 - val_acc: 0.8590\n",
      "Epoch 60/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7738 - acc: 0.7231 - val_loss: 0.5816 - val_acc: 0.8590\n",
      "Epoch 61/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7699 - acc: 0.7231 - val_loss: 0.5795 - val_acc: 0.8590\n",
      "Epoch 62/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7713 - acc: 0.7231 - val_loss: 0.5775 - val_acc: 0.8590\n",
      "Epoch 63/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7686 - acc: 0.7231 - val_loss: 0.5749 - val_acc: 0.8590\n",
      "Epoch 64/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7681 - acc: 0.7231 - val_loss: 0.5732 - val_acc: 0.8590\n",
      "Epoch 65/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7727 - acc: 0.7231 - val_loss: 0.5723 - val_acc: 0.8590\n",
      "Epoch 66/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7730 - acc: 0.7231 - val_loss: 0.5708 - val_acc: 0.8590\n",
      "Epoch 67/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7705 - acc: 0.7231 - val_loss: 0.5699 - val_acc: 0.8590\n",
      "Epoch 68/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7701 - acc: 0.7231 - val_loss: 0.5686 - val_acc: 0.8590\n",
      "Epoch 69/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7698 - acc: 0.7231 - val_loss: 0.5678 - val_acc: 0.8590\n",
      "Epoch 70/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7650 - acc: 0.7231 - val_loss: 0.5666 - val_acc: 0.8590\n",
      "Epoch 71/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7708 - acc: 0.7231 - val_loss: 0.5655 - val_acc: 0.8590\n",
      "Epoch 72/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7654 - acc: 0.7231 - val_loss: 0.5647 - val_acc: 0.8590\n",
      "Epoch 73/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7690 - acc: 0.7231 - val_loss: 0.5645 - val_acc: 0.8590\n",
      "Epoch 74/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7697 - acc: 0.7231 - val_loss: 0.5641 - val_acc: 0.8590\n",
      "Epoch 75/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7690 - acc: 0.7231 - val_loss: 0.5633 - val_acc: 0.8590\n",
      "Epoch 76/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7698 - acc: 0.7231 - val_loss: 0.5632 - val_acc: 0.8590\n",
      "Epoch 77/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7677 - acc: 0.7231 - val_loss: 0.5628 - val_acc: 0.8590\n",
      "Epoch 78/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7713 - acc: 0.7231 - val_loss: 0.5627 - val_acc: 0.8590\n",
      "Epoch 79/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7667 - acc: 0.7231 - val_loss: 0.5622 - val_acc: 0.8590\n",
      "Epoch 80/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7709 - acc: 0.7231 - val_loss: 0.5623 - val_acc: 0.8590\n",
      "Epoch 81/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7666 - acc: 0.7231 - val_loss: 0.5620 - val_acc: 0.8590\n",
      "Epoch 82/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7671 - acc: 0.7231 - val_loss: 0.5616 - val_acc: 0.8590\n",
      "Epoch 83/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7715 - acc: 0.7231 - val_loss: 0.5613 - val_acc: 0.8590\n",
      "Epoch 84/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7656 - acc: 0.7231 - val_loss: 0.5606 - val_acc: 0.8590\n",
      "Epoch 85/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7674 - acc: 0.7231 - val_loss: 0.5599 - val_acc: 0.8590\n",
      "Epoch 86/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7672 - acc: 0.7231 - val_loss: 0.5598 - val_acc: 0.8590\n",
      "Epoch 87/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7760 - acc: 0.7231 - val_loss: 0.5602 - val_acc: 0.8590\n",
      "Epoch 88/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7592 - acc: 0.7231 - val_loss: 0.5598 - val_acc: 0.8590\n",
      "Epoch 89/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7651 - acc: 0.7231 - val_loss: 0.5599 - val_acc: 0.8590\n",
      "Epoch 90/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.7642 - acc: 0.7231 - val_loss: 0.5591 - val_acc: 0.8590\n",
      "Epoch 91/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7676 - acc: 0.7231 - val_loss: 0.5586 - val_acc: 0.8590\n",
      "Epoch 92/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7695 - acc: 0.7231 - val_loss: 0.5589 - val_acc: 0.8590\n",
      "Epoch 93/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7713 - acc: 0.7231 - val_loss: 0.5588 - val_acc: 0.8590\n",
      "Epoch 94/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7667 - acc: 0.7231 - val_loss: 0.5588 - val_acc: 0.8590\n",
      "Epoch 95/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7698 - acc: 0.7231 - val_loss: 0.5587 - val_acc: 0.8590\n",
      "Epoch 96/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7704 - acc: 0.7231 - val_loss: 0.5587 - val_acc: 0.8590\n",
      "Epoch 97/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7691 - acc: 0.7231 - val_loss: 0.5584 - val_acc: 0.8590\n",
      "Epoch 98/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7713 - acc: 0.7231 - val_loss: 0.5589 - val_acc: 0.8590\n",
      "Epoch 99/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7609 - acc: 0.7231 - val_loss: 0.5593 - val_acc: 0.8590\n",
      "Epoch 100/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7643 - acc: 0.7231 - val_loss: 0.5589 - val_acc: 0.8590\n",
      "Epoch 101/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7679 - acc: 0.7231 - val_loss: 0.5583 - val_acc: 0.8590\n",
      "Epoch 102/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7672 - acc: 0.7231 - val_loss: 0.5577 - val_acc: 0.8590\n",
      "Epoch 103/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7659 - acc: 0.7231 - val_loss: 0.5576 - val_acc: 0.8590\n",
      "Epoch 104/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7684 - acc: 0.7231 - val_loss: 0.5577 - val_acc: 0.8590\n",
      "Epoch 105/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7648 - acc: 0.7231 - val_loss: 0.5578 - val_acc: 0.8590\n",
      "Epoch 106/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7643 - acc: 0.7231 - val_loss: 0.5573 - val_acc: 0.8590\n",
      "Epoch 107/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7703 - acc: 0.7231 - val_loss: 0.5577 - val_acc: 0.8590\n",
      "Epoch 108/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7654 - acc: 0.7231 - val_loss: 0.5564 - val_acc: 0.8590\n",
      "Epoch 109/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7629 - acc: 0.7231 - val_loss: 0.5566 - val_acc: 0.8590\n",
      "Epoch 110/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7704 - acc: 0.7231 - val_loss: 0.5566 - val_acc: 0.8590\n",
      "Epoch 111/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7592 - acc: 0.7231 - val_loss: 0.5561 - val_acc: 0.8590\n",
      "Epoch 112/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7659 - acc: 0.7231 - val_loss: 0.5567 - val_acc: 0.8590\n",
      "Epoch 113/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7603 - acc: 0.7231 - val_loss: 0.5562 - val_acc: 0.8590\n",
      "Epoch 114/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7715 - acc: 0.7231 - val_loss: 0.5566 - val_acc: 0.8590\n",
      "Epoch 115/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7669 - acc: 0.7231 - val_loss: 0.5565 - val_acc: 0.8590\n",
      "Epoch 116/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7668 - acc: 0.7231 - val_loss: 0.5566 - val_acc: 0.8590\n",
      "Epoch 117/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7643 - acc: 0.7231 - val_loss: 0.5566 - val_acc: 0.8590\n",
      "Epoch 118/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7662 - acc: 0.7231 - val_loss: 0.5565 - val_acc: 0.8590\n",
      "Epoch 119/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7639 - acc: 0.7231 - val_loss: 0.5564 - val_acc: 0.8590\n",
      "Epoch 120/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7683 - acc: 0.7231 - val_loss: 0.5563 - val_acc: 0.8590\n",
      "Epoch 121/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7643 - acc: 0.7231 - val_loss: 0.5567 - val_acc: 0.8590\n",
      "Epoch 122/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7659 - acc: 0.7231 - val_loss: 0.5565 - val_acc: 0.8590\n",
      "Epoch 123/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7679 - acc: 0.7231 - val_loss: 0.5566 - val_acc: 0.8590\n",
      "Epoch 124/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7614 - acc: 0.7231 - val_loss: 0.5567 - val_acc: 0.8590\n",
      "Epoch 125/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7683 - acc: 0.7231 - val_loss: 0.5563 - val_acc: 0.8590\n",
      "Epoch 126/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7665 - acc: 0.7231 - val_loss: 0.5562 - val_acc: 0.8590\n",
      "Epoch 127/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7640 - acc: 0.7231 - val_loss: 0.5558 - val_acc: 0.8590\n",
      "Epoch 128/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7682 - acc: 0.7231 - val_loss: 0.5558 - val_acc: 0.8590\n",
      "Epoch 129/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7630 - acc: 0.7231 - val_loss: 0.5560 - val_acc: 0.8590\n",
      "Epoch 130/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7658 - acc: 0.7231 - val_loss: 0.5558 - val_acc: 0.8590\n",
      "Epoch 131/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7661 - acc: 0.7231 - val_loss: 0.5553 - val_acc: 0.8590\n",
      "Epoch 132/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7612 - acc: 0.7231 - val_loss: 0.5556 - val_acc: 0.8590\n",
      "Epoch 133/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7643 - acc: 0.7231 - val_loss: 0.5555 - val_acc: 0.8590\n",
      "Epoch 134/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7642 - acc: 0.7231 - val_loss: 0.5555 - val_acc: 0.8590\n",
      "Epoch 135/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7650 - acc: 0.7231 - val_loss: 0.5557 - val_acc: 0.8590\n",
      "Epoch 136/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7606 - acc: 0.7231 - val_loss: 0.5551 - val_acc: 0.8590\n",
      "Epoch 137/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7699 - acc: 0.7231 - val_loss: 0.5552 - val_acc: 0.8590\n",
      "Epoch 138/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7633 - acc: 0.7231 - val_loss: 0.5549 - val_acc: 0.8590\n",
      "Epoch 139/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7627 - acc: 0.7231 - val_loss: 0.5548 - val_acc: 0.8590\n",
      "Epoch 140/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7612 - acc: 0.7231 - val_loss: 0.5547 - val_acc: 0.8590\n",
      "Epoch 141/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.7612 - acc: 0.7231 - val_loss: 0.5545 - val_acc: 0.8590\n",
      "Epoch 142/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.7690 - acc: 0.7231 - val_loss: 0.5547 - val_acc: 0.8590\n",
      "Epoch 143/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.7642 - acc: 0.7231 - val_loss: 0.5542 - val_acc: 0.8590\n",
      "Epoch 144/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7671 - acc: 0.7231 - val_loss: 0.5542 - val_acc: 0.8590\n",
      "Epoch 145/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7658 - acc: 0.7231 - val_loss: 0.5545 - val_acc: 0.8590\n",
      "Epoch 146/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7654 - acc: 0.7231 - val_loss: 0.5548 - val_acc: 0.8590\n",
      "Epoch 147/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7629 - acc: 0.7231 - val_loss: 0.5546 - val_acc: 0.8590\n",
      "Epoch 148/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7626 - acc: 0.7231 - val_loss: 0.5544 - val_acc: 0.8590\n",
      "Epoch 149/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7666 - acc: 0.7231 - val_loss: 0.5548 - val_acc: 0.8590\n",
      "Epoch 150/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7601 - acc: 0.7231 - val_loss: 0.5548 - val_acc: 0.8590\n",
      "Epoch 151/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7638 - acc: 0.7231 - val_loss: 0.5543 - val_acc: 0.8590\n",
      "Epoch 152/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7581 - acc: 0.7231 - val_loss: 0.5547 - val_acc: 0.8590\n",
      "Epoch 153/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7593 - acc: 0.7231 - val_loss: 0.5540 - val_acc: 0.8590\n",
      "Epoch 154/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7685 - acc: 0.7231 - val_loss: 0.5544 - val_acc: 0.8590\n",
      "Epoch 155/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7625 - acc: 0.7231 - val_loss: 0.5538 - val_acc: 0.8590\n",
      "Epoch 156/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7617 - acc: 0.7231 - val_loss: 0.5535 - val_acc: 0.8590\n",
      "Epoch 157/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7590 - acc: 0.7231 - val_loss: 0.5532 - val_acc: 0.8590\n",
      "Epoch 158/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7584 - acc: 0.7231 - val_loss: 0.5531 - val_acc: 0.8590\n",
      "Epoch 159/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7632 - acc: 0.7231 - val_loss: 0.5527 - val_acc: 0.8590\n",
      "Epoch 160/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7723 - acc: 0.7231 - val_loss: 0.5527 - val_acc: 0.8590\n",
      "Epoch 161/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7622 - acc: 0.7231 - val_loss: 0.5526 - val_acc: 0.8590\n",
      "Epoch 162/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7608 - acc: 0.7231 - val_loss: 0.5533 - val_acc: 0.8590\n",
      "Epoch 163/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7628 - acc: 0.7231 - val_loss: 0.5537 - val_acc: 0.8590\n",
      "Epoch 164/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7602 - acc: 0.7231 - val_loss: 0.5534 - val_acc: 0.8590\n",
      "Epoch 165/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7561 - acc: 0.7231 - val_loss: 0.5531 - val_acc: 0.8590\n",
      "Epoch 166/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7532 - acc: 0.7231 - val_loss: 0.5526 - val_acc: 0.8590\n",
      "Epoch 167/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.7618 - acc: 0.7231 - val_loss: 0.5525 - val_acc: 0.8590\n",
      "Epoch 168/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7616 - acc: 0.7231 - val_loss: 0.5522 - val_acc: 0.8590\n",
      "Epoch 169/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7669 - acc: 0.7231 - val_loss: 0.5527 - val_acc: 0.8590\n",
      "Epoch 170/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7601 - acc: 0.7231 - val_loss: 0.5525 - val_acc: 0.8590\n",
      "Epoch 171/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7687 - acc: 0.7231 - val_loss: 0.5523 - val_acc: 0.8590\n",
      "Epoch 172/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7640 - acc: 0.7231 - val_loss: 0.5530 - val_acc: 0.8590\n",
      "Epoch 173/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7707 - acc: 0.7231 - val_loss: 0.5530 - val_acc: 0.8590\n",
      "Epoch 174/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7611 - acc: 0.7231 - val_loss: 0.5528 - val_acc: 0.8590\n",
      "Epoch 175/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7648 - acc: 0.7231 - val_loss: 0.5531 - val_acc: 0.8590\n",
      "Epoch 176/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7636 - acc: 0.7231 - val_loss: 0.5531 - val_acc: 0.8590\n",
      "Epoch 177/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7561 - acc: 0.7231 - val_loss: 0.5529 - val_acc: 0.8590\n",
      "Epoch 178/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7619 - acc: 0.7231 - val_loss: 0.5528 - val_acc: 0.8590\n",
      "Epoch 179/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7630 - acc: 0.7231 - val_loss: 0.5525 - val_acc: 0.8590\n",
      "Epoch 180/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7568 - acc: 0.7231 - val_loss: 0.5524 - val_acc: 0.8590\n",
      "Epoch 181/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7602 - acc: 0.7231 - val_loss: 0.5525 - val_acc: 0.8590\n",
      "Epoch 182/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7588 - acc: 0.7231 - val_loss: 0.5527 - val_acc: 0.8590\n",
      "Epoch 183/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7634 - acc: 0.7231 - val_loss: 0.5521 - val_acc: 0.8590\n",
      "Epoch 184/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7556 - acc: 0.7231 - val_loss: 0.5523 - val_acc: 0.8590\n",
      "Epoch 185/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7627 - acc: 0.7231 - val_loss: 0.5517 - val_acc: 0.8590\n",
      "Epoch 186/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7572 - acc: 0.7231 - val_loss: 0.5515 - val_acc: 0.8590\n",
      "Epoch 187/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7632 - acc: 0.7231 - val_loss: 0.5520 - val_acc: 0.8590\n",
      "Epoch 188/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7603 - acc: 0.7231 - val_loss: 0.5517 - val_acc: 0.8590\n",
      "Epoch 189/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7607 - acc: 0.7231 - val_loss: 0.5518 - val_acc: 0.8590\n",
      "Epoch 190/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7545 - acc: 0.7231 - val_loss: 0.5518 - val_acc: 0.8590\n",
      "Epoch 191/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7594 - acc: 0.7231 - val_loss: 0.5516 - val_acc: 0.8590\n",
      "Epoch 192/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7581 - acc: 0.7231 - val_loss: 0.5519 - val_acc: 0.8590\n",
      "Epoch 193/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7571 - acc: 0.7231 - val_loss: 0.5514 - val_acc: 0.8590\n",
      "Epoch 194/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7577 - acc: 0.7231 - val_loss: 0.5508 - val_acc: 0.8590\n",
      "Epoch 195/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7604 - acc: 0.7231 - val_loss: 0.5512 - val_acc: 0.8590\n",
      "Epoch 196/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7599 - acc: 0.7231 - val_loss: 0.5508 - val_acc: 0.8590\n",
      "Epoch 197/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7602 - acc: 0.7231 - val_loss: 0.5508 - val_acc: 0.8590\n",
      "Epoch 198/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7601 - acc: 0.7231 - val_loss: 0.5506 - val_acc: 0.8590\n",
      "Epoch 199/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7586 - acc: 0.7231 - val_loss: 0.5506 - val_acc: 0.8590\n",
      "Epoch 200/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7600 - acc: 0.7231 - val_loss: 0.5505 - val_acc: 0.8590\n",
      "Epoch 201/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7620 - acc: 0.7231 - val_loss: 0.5508 - val_acc: 0.8590\n",
      "Epoch 202/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7569 - acc: 0.7231 - val_loss: 0.5513 - val_acc: 0.8590\n",
      "Epoch 203/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7643 - acc: 0.7231 - val_loss: 0.5507 - val_acc: 0.8590\n",
      "Epoch 204/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7597 - acc: 0.7231 - val_loss: 0.5508 - val_acc: 0.8590\n",
      "Epoch 205/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7594 - acc: 0.7231 - val_loss: 0.5506 - val_acc: 0.8590\n",
      "Epoch 206/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7663 - acc: 0.7231 - val_loss: 0.5503 - val_acc: 0.8590\n",
      "Epoch 207/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7580 - acc: 0.7231 - val_loss: 0.5508 - val_acc: 0.8590\n",
      "Epoch 208/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7562 - acc: 0.7231 - val_loss: 0.5501 - val_acc: 0.8590\n",
      "Epoch 209/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7591 - acc: 0.7231 - val_loss: 0.5504 - val_acc: 0.8590\n",
      "Epoch 210/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7544 - acc: 0.7231 - val_loss: 0.5503 - val_acc: 0.8590\n",
      "Epoch 211/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7542 - acc: 0.7231 - val_loss: 0.5501 - val_acc: 0.8590\n",
      "Epoch 212/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7600 - acc: 0.7231 - val_loss: 0.5498 - val_acc: 0.8590\n",
      "Epoch 213/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7565 - acc: 0.7231 - val_loss: 0.5497 - val_acc: 0.8590\n",
      "Epoch 214/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7559 - acc: 0.7231 - val_loss: 0.5497 - val_acc: 0.8590\n",
      "Epoch 215/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7585 - acc: 0.7231 - val_loss: 0.5491 - val_acc: 0.8590\n",
      "Epoch 216/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7559 - acc: 0.7231 - val_loss: 0.5497 - val_acc: 0.8590\n",
      "Epoch 217/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7584 - acc: 0.7231 - val_loss: 0.5494 - val_acc: 0.8590\n",
      "Epoch 218/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7621 - acc: 0.7231 - val_loss: 0.5496 - val_acc: 0.8590\n",
      "Epoch 219/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7580 - acc: 0.7231 - val_loss: 0.5494 - val_acc: 0.8590\n",
      "Epoch 220/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7653 - acc: 0.7231 - val_loss: 0.5494 - val_acc: 0.8590\n",
      "Epoch 221/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7573 - acc: 0.7231 - val_loss: 0.5497 - val_acc: 0.8590\n",
      "Epoch 222/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7602 - acc: 0.7231 - val_loss: 0.5492 - val_acc: 0.8590\n",
      "Epoch 223/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7551 - acc: 0.7231 - val_loss: 0.5492 - val_acc: 0.8590\n",
      "Epoch 224/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.7572 - acc: 0.7231 - val_loss: 0.5493 - val_acc: 0.8590\n",
      "Epoch 225/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7589 - acc: 0.7231 - val_loss: 0.5490 - val_acc: 0.8590\n",
      "Epoch 226/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7518 - acc: 0.7231 - val_loss: 0.5490 - val_acc: 0.8590\n",
      "Epoch 227/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7601 - acc: 0.7231 - val_loss: 0.5492 - val_acc: 0.8590\n",
      "Epoch 228/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7568 - acc: 0.7231 - val_loss: 0.5491 - val_acc: 0.8590\n",
      "Epoch 229/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7532 - acc: 0.7231 - val_loss: 0.5485 - val_acc: 0.8590\n",
      "Epoch 230/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7611 - acc: 0.7231 - val_loss: 0.5488 - val_acc: 0.8590\n",
      "Epoch 231/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7581 - acc: 0.7231 - val_loss: 0.5490 - val_acc: 0.8590\n",
      "Epoch 232/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7585 - acc: 0.7231 - val_loss: 0.5486 - val_acc: 0.8590\n",
      "Epoch 233/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7636 - acc: 0.7231 - val_loss: 0.5486 - val_acc: 0.8590\n",
      "Epoch 234/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7555 - acc: 0.7231 - val_loss: 0.5484 - val_acc: 0.8590\n",
      "Epoch 235/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7576 - acc: 0.7231 - val_loss: 0.5486 - val_acc: 0.8590\n",
      "Epoch 236/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7549 - acc: 0.7231 - val_loss: 0.5488 - val_acc: 0.8590\n",
      "Epoch 237/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7574 - acc: 0.7231 - val_loss: 0.5488 - val_acc: 0.8590\n",
      "Epoch 238/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7543 - acc: 0.7231 - val_loss: 0.5478 - val_acc: 0.8590\n",
      "Epoch 239/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7656 - acc: 0.7231 - val_loss: 0.5486 - val_acc: 0.8590\n",
      "Epoch 240/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7571 - acc: 0.7231 - val_loss: 0.5486 - val_acc: 0.8590\n",
      "Epoch 241/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7514 - acc: 0.7231 - val_loss: 0.5486 - val_acc: 0.8590\n",
      "Epoch 242/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7584 - acc: 0.7231 - val_loss: 0.5486 - val_acc: 0.8590\n",
      "Epoch 243/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7566 - acc: 0.7231 - val_loss: 0.5476 - val_acc: 0.8590\n",
      "Epoch 244/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7583 - acc: 0.7231 - val_loss: 0.5477 - val_acc: 0.8590\n",
      "Epoch 245/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7551 - acc: 0.7231 - val_loss: 0.5475 - val_acc: 0.8590\n",
      "Epoch 246/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7580 - acc: 0.7231 - val_loss: 0.5475 - val_acc: 0.8590\n",
      "Epoch 247/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7477 - acc: 0.7231 - val_loss: 0.5480 - val_acc: 0.8590\n",
      "Epoch 248/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7528 - acc: 0.7231 - val_loss: 0.5477 - val_acc: 0.8590\n",
      "Epoch 249/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7541 - acc: 0.7231 - val_loss: 0.5476 - val_acc: 0.8590\n",
      "Epoch 250/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7554 - acc: 0.7231 - val_loss: 0.5476 - val_acc: 0.8590\n",
      "Epoch 251/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7600 - acc: 0.7231 - val_loss: 0.5475 - val_acc: 0.8590\n",
      "Epoch 252/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7572 - acc: 0.7231 - val_loss: 0.5473 - val_acc: 0.8590\n",
      "Epoch 253/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7574 - acc: 0.7231 - val_loss: 0.5471 - val_acc: 0.8590\n",
      "Epoch 254/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7561 - acc: 0.7231 - val_loss: 0.5466 - val_acc: 0.8590\n",
      "Epoch 255/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7586 - acc: 0.7231 - val_loss: 0.5471 - val_acc: 0.8590\n",
      "Epoch 256/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7541 - acc: 0.7231 - val_loss: 0.5476 - val_acc: 0.8590\n",
      "Epoch 257/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7524 - acc: 0.7231 - val_loss: 0.5474 - val_acc: 0.8590\n",
      "Epoch 258/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7477 - acc: 0.7231 - val_loss: 0.5465 - val_acc: 0.8590\n",
      "Epoch 259/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7519 - acc: 0.7231 - val_loss: 0.5469 - val_acc: 0.8590\n",
      "Epoch 260/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7502 - acc: 0.7231 - val_loss: 0.5470 - val_acc: 0.8590\n",
      "Epoch 261/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7565 - acc: 0.7231 - val_loss: 0.5465 - val_acc: 0.8590\n",
      "Epoch 262/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7550 - acc: 0.7231 - val_loss: 0.5461 - val_acc: 0.8590\n",
      "Epoch 263/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7594 - acc: 0.7231 - val_loss: 0.5464 - val_acc: 0.8590\n",
      "Epoch 264/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7494 - acc: 0.7231 - val_loss: 0.5466 - val_acc: 0.8590\n",
      "Epoch 265/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7609 - acc: 0.7231 - val_loss: 0.5468 - val_acc: 0.8590\n",
      "Epoch 266/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7553 - acc: 0.7231 - val_loss: 0.5466 - val_acc: 0.8590\n",
      "Epoch 267/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7549 - acc: 0.7231 - val_loss: 0.5465 - val_acc: 0.8590\n",
      "Epoch 268/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7583 - acc: 0.7231 - val_loss: 0.5469 - val_acc: 0.8590\n",
      "Epoch 269/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7549 - acc: 0.7231 - val_loss: 0.5469 - val_acc: 0.8590\n",
      "Epoch 270/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7455 - acc: 0.7231 - val_loss: 0.5466 - val_acc: 0.8590\n",
      "Epoch 271/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7519 - acc: 0.7231 - val_loss: 0.5461 - val_acc: 0.8590\n",
      "Epoch 272/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7515 - acc: 0.7231 - val_loss: 0.5463 - val_acc: 0.8590\n",
      "Epoch 273/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7576 - acc: 0.7231 - val_loss: 0.5467 - val_acc: 0.8590\n",
      "Epoch 274/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7539 - acc: 0.7231 - val_loss: 0.5466 - val_acc: 0.8590\n",
      "Epoch 275/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7554 - acc: 0.7231 - val_loss: 0.5464 - val_acc: 0.8590\n",
      "Epoch 276/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7498 - acc: 0.7231 - val_loss: 0.5466 - val_acc: 0.8590\n",
      "Epoch 277/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7473 - acc: 0.7231 - val_loss: 0.5462 - val_acc: 0.8590\n",
      "Epoch 278/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7606 - acc: 0.7231 - val_loss: 0.5458 - val_acc: 0.8590\n",
      "Epoch 279/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7521 - acc: 0.7231 - val_loss: 0.5459 - val_acc: 0.8590\n",
      "Epoch 280/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7539 - acc: 0.7231 - val_loss: 0.5455 - val_acc: 0.8590\n",
      "Epoch 281/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7508 - acc: 0.7231 - val_loss: 0.5458 - val_acc: 0.8590\n",
      "Epoch 282/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7502 - acc: 0.7231 - val_loss: 0.5455 - val_acc: 0.8590\n",
      "Epoch 283/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7464 - acc: 0.7231 - val_loss: 0.5458 - val_acc: 0.8590\n",
      "Epoch 284/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7582 - acc: 0.7231 - val_loss: 0.5458 - val_acc: 0.8590\n",
      "Epoch 285/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7597 - acc: 0.7231 - val_loss: 0.5458 - val_acc: 0.8590\n",
      "Epoch 286/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7573 - acc: 0.7231 - val_loss: 0.5456 - val_acc: 0.8590\n",
      "Epoch 287/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7490 - acc: 0.7231 - val_loss: 0.5460 - val_acc: 0.8590\n",
      "Epoch 288/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7493 - acc: 0.7231 - val_loss: 0.5456 - val_acc: 0.8590\n",
      "Epoch 289/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7532 - acc: 0.7231 - val_loss: 0.5452 - val_acc: 0.8590\n",
      "Epoch 290/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7533 - acc: 0.7231 - val_loss: 0.5451 - val_acc: 0.8590\n",
      "Epoch 291/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7579 - acc: 0.7231 - val_loss: 0.5450 - val_acc: 0.8590\n",
      "Epoch 292/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.7546 - acc: 0.7231 - val_loss: 0.5454 - val_acc: 0.8590\n",
      "Epoch 293/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7570 - acc: 0.7231 - val_loss: 0.5450 - val_acc: 0.8590\n",
      "Epoch 294/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7532 - acc: 0.7231 - val_loss: 0.5450 - val_acc: 0.8590\n",
      "Epoch 295/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7585 - acc: 0.7231 - val_loss: 0.5450 - val_acc: 0.8590\n",
      "Epoch 296/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7548 - acc: 0.7231 - val_loss: 0.5452 - val_acc: 0.8590\n",
      "Epoch 297/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7562 - acc: 0.7231 - val_loss: 0.5450 - val_acc: 0.8590\n",
      "Epoch 298/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7579 - acc: 0.7231 - val_loss: 0.5455 - val_acc: 0.8590\n",
      "Epoch 299/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7534 - acc: 0.7231 - val_loss: 0.5453 - val_acc: 0.8590\n",
      "Epoch 300/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7562 - acc: 0.7231 - val_loss: 0.5451 - val_acc: 0.8590\n",
      "Epoch 301/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7484 - acc: 0.7231 - val_loss: 0.5450 - val_acc: 0.8590\n",
      "Epoch 302/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7533 - acc: 0.7231 - val_loss: 0.5444 - val_acc: 0.8590\n",
      "Epoch 303/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7485 - acc: 0.7231 - val_loss: 0.5442 - val_acc: 0.8590\n",
      "Epoch 304/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7563 - acc: 0.7231 - val_loss: 0.5447 - val_acc: 0.8590\n",
      "Epoch 305/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7612 - acc: 0.7231 - val_loss: 0.5447 - val_acc: 0.8590\n",
      "Epoch 306/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7504 - acc: 0.7231 - val_loss: 0.5449 - val_acc: 0.8590\n",
      "Epoch 307/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7514 - acc: 0.7231 - val_loss: 0.5448 - val_acc: 0.8590\n",
      "Epoch 308/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7538 - acc: 0.7231 - val_loss: 0.5446 - val_acc: 0.8590\n",
      "Epoch 309/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7500 - acc: 0.7231 - val_loss: 0.5447 - val_acc: 0.8590\n",
      "Epoch 310/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7488 - acc: 0.7231 - val_loss: 0.5446 - val_acc: 0.8590\n",
      "Epoch 311/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7583 - acc: 0.7231 - val_loss: 0.5445 - val_acc: 0.8590\n",
      "Epoch 312/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7518 - acc: 0.7231 - val_loss: 0.5443 - val_acc: 0.8590\n",
      "Epoch 313/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7486 - acc: 0.7231 - val_loss: 0.5444 - val_acc: 0.8590\n",
      "Epoch 314/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7575 - acc: 0.7231 - val_loss: 0.5442 - val_acc: 0.8590\n",
      "Epoch 315/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7477 - acc: 0.7231 - val_loss: 0.5440 - val_acc: 0.8590\n",
      "Epoch 316/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7502 - acc: 0.7231 - val_loss: 0.5438 - val_acc: 0.8590\n",
      "Epoch 317/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7485 - acc: 0.7231 - val_loss: 0.5443 - val_acc: 0.8590\n",
      "Epoch 318/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7534 - acc: 0.7231 - val_loss: 0.5442 - val_acc: 0.8590\n",
      "Epoch 319/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7427 - acc: 0.7231 - val_loss: 0.5438 - val_acc: 0.8590\n",
      "Epoch 320/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7529 - acc: 0.7231 - val_loss: 0.5438 - val_acc: 0.8590\n",
      "Epoch 321/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7609 - acc: 0.7231 - val_loss: 0.5436 - val_acc: 0.8590\n",
      "Epoch 322/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7524 - acc: 0.7231 - val_loss: 0.5439 - val_acc: 0.8590\n",
      "Epoch 323/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7527 - acc: 0.7231 - val_loss: 0.5437 - val_acc: 0.8590\n",
      "Epoch 324/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7554 - acc: 0.7231 - val_loss: 0.5440 - val_acc: 0.8590\n",
      "Epoch 325/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7522 - acc: 0.7231 - val_loss: 0.5442 - val_acc: 0.8590\n",
      "Epoch 326/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7525 - acc: 0.7231 - val_loss: 0.5442 - val_acc: 0.8590\n",
      "Epoch 327/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7456 - acc: 0.7231 - val_loss: 0.5440 - val_acc: 0.8590\n",
      "Epoch 328/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7445 - acc: 0.7231 - val_loss: 0.5441 - val_acc: 0.8590\n",
      "Epoch 329/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7515 - acc: 0.7231 - val_loss: 0.5435 - val_acc: 0.8590\n",
      "Epoch 330/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7509 - acc: 0.7231 - val_loss: 0.5438 - val_acc: 0.8590\n",
      "Epoch 331/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7531 - acc: 0.7231 - val_loss: 0.5436 - val_acc: 0.8590\n",
      "Epoch 332/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7571 - acc: 0.7231 - val_loss: 0.5437 - val_acc: 0.8590\n",
      "Epoch 333/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7524 - acc: 0.7231 - val_loss: 0.5437 - val_acc: 0.8590\n",
      "Epoch 334/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7507 - acc: 0.7231 - val_loss: 0.5432 - val_acc: 0.8590\n",
      "Epoch 335/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7486 - acc: 0.7231 - val_loss: 0.5434 - val_acc: 0.8590\n",
      "Epoch 336/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7494 - acc: 0.7231 - val_loss: 0.5433 - val_acc: 0.8590\n",
      "Epoch 337/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7471 - acc: 0.7231 - val_loss: 0.5431 - val_acc: 0.8590\n",
      "Epoch 338/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7595 - acc: 0.7231 - val_loss: 0.5430 - val_acc: 0.8590\n",
      "Epoch 339/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7504 - acc: 0.7231 - val_loss: 0.5431 - val_acc: 0.8590\n",
      "Epoch 340/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7592 - acc: 0.7231 - val_loss: 0.5434 - val_acc: 0.8590\n",
      "Epoch 341/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7487 - acc: 0.7231 - val_loss: 0.5433 - val_acc: 0.8590\n",
      "Epoch 342/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7548 - acc: 0.7231 - val_loss: 0.5432 - val_acc: 0.8590\n",
      "Epoch 343/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7550 - acc: 0.7231 - val_loss: 0.5436 - val_acc: 0.8590\n",
      "Epoch 344/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7433 - acc: 0.7231 - val_loss: 0.5433 - val_acc: 0.8590\n",
      "Epoch 345/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7574 - acc: 0.7231 - val_loss: 0.5434 - val_acc: 0.8590\n",
      "Epoch 346/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7545 - acc: 0.7231 - val_loss: 0.5437 - val_acc: 0.8590\n",
      "Epoch 347/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7483 - acc: 0.7231 - val_loss: 0.5434 - val_acc: 0.8590\n",
      "Epoch 348/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7422 - acc: 0.7231 - val_loss: 0.5426 - val_acc: 0.8590\n",
      "Epoch 349/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7505 - acc: 0.7231 - val_loss: 0.5430 - val_acc: 0.8590\n",
      "Epoch 350/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7542 - acc: 0.7231 - val_loss: 0.5430 - val_acc: 0.8590\n",
      "Epoch 351/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7513 - acc: 0.7231 - val_loss: 0.5424 - val_acc: 0.8590\n",
      "Epoch 352/500\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.7447 - acc: 0.7231 - val_loss: 0.5426 - val_acc: 0.8590\n",
      "Epoch 353/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7501 - acc: 0.7231 - val_loss: 0.5427 - val_acc: 0.8590\n",
      "Epoch 354/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7427 - acc: 0.7231 - val_loss: 0.5427 - val_acc: 0.8590\n",
      "Epoch 355/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7461 - acc: 0.7231 - val_loss: 0.5424 - val_acc: 0.8590\n",
      "Epoch 356/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7501 - acc: 0.7231 - val_loss: 0.5424 - val_acc: 0.8590\n",
      "Epoch 357/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7382 - acc: 0.7231 - val_loss: 0.5421 - val_acc: 0.8590\n",
      "Epoch 358/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7524 - acc: 0.7231 - val_loss: 0.5425 - val_acc: 0.8590\n",
      "Epoch 359/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7436 - acc: 0.7231 - val_loss: 0.5424 - val_acc: 0.8590\n",
      "Epoch 360/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7440 - acc: 0.7231 - val_loss: 0.5420 - val_acc: 0.8590\n",
      "Epoch 361/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7496 - acc: 0.7231 - val_loss: 0.5422 - val_acc: 0.8590\n",
      "Epoch 362/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7437 - acc: 0.7231 - val_loss: 0.5421 - val_acc: 0.8590\n",
      "Epoch 363/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7481 - acc: 0.7231 - val_loss: 0.5421 - val_acc: 0.8590\n",
      "Epoch 364/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7490 - acc: 0.7231 - val_loss: 0.5418 - val_acc: 0.8590\n",
      "Epoch 365/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7425 - acc: 0.7231 - val_loss: 0.5420 - val_acc: 0.8590\n",
      "Epoch 366/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7466 - acc: 0.7231 - val_loss: 0.5419 - val_acc: 0.8590\n",
      "Epoch 367/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7482 - acc: 0.7231 - val_loss: 0.5416 - val_acc: 0.8590\n",
      "Epoch 368/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7470 - acc: 0.7231 - val_loss: 0.5419 - val_acc: 0.8590\n",
      "Epoch 369/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7427 - acc: 0.7231 - val_loss: 0.5419 - val_acc: 0.8590\n",
      "Epoch 370/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7426 - acc: 0.7231 - val_loss: 0.5414 - val_acc: 0.8590\n",
      "Epoch 371/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7466 - acc: 0.7231 - val_loss: 0.5413 - val_acc: 0.8590\n",
      "Epoch 372/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7482 - acc: 0.7231 - val_loss: 0.5416 - val_acc: 0.8590\n",
      "Epoch 373/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7461 - acc: 0.7231 - val_loss: 0.5417 - val_acc: 0.8590\n",
      "Epoch 374/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7466 - acc: 0.7231 - val_loss: 0.5414 - val_acc: 0.8590\n",
      "Epoch 375/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7474 - acc: 0.7231 - val_loss: 0.5412 - val_acc: 0.8590\n",
      "Epoch 376/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7474 - acc: 0.7231 - val_loss: 0.5418 - val_acc: 0.8590\n",
      "Epoch 377/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7473 - acc: 0.7231 - val_loss: 0.5416 - val_acc: 0.8590\n",
      "Epoch 378/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7367 - acc: 0.7231 - val_loss: 0.5413 - val_acc: 0.8590\n",
      "Epoch 379/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7500 - acc: 0.7231 - val_loss: 0.5413 - val_acc: 0.8590\n",
      "Epoch 380/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7420 - acc: 0.7231 - val_loss: 0.5407 - val_acc: 0.8590\n",
      "Epoch 381/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7517 - acc: 0.7231 - val_loss: 0.5410 - val_acc: 0.8590\n",
      "Epoch 382/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7408 - acc: 0.7231 - val_loss: 0.5406 - val_acc: 0.8590\n",
      "Epoch 383/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7429 - acc: 0.7231 - val_loss: 0.5405 - val_acc: 0.8590\n",
      "Epoch 384/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7433 - acc: 0.7231 - val_loss: 0.5407 - val_acc: 0.8590\n",
      "Epoch 385/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7504 - acc: 0.7231 - val_loss: 0.5407 - val_acc: 0.8590\n",
      "Epoch 386/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7382 - acc: 0.7231 - val_loss: 0.5405 - val_acc: 0.8590\n",
      "Epoch 387/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7473 - acc: 0.7231 - val_loss: 0.5405 - val_acc: 0.8590\n",
      "Epoch 388/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7468 - acc: 0.7231 - val_loss: 0.5408 - val_acc: 0.8590\n",
      "Epoch 389/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7510 - acc: 0.7231 - val_loss: 0.5406 - val_acc: 0.8590\n",
      "Epoch 390/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7359 - acc: 0.7231 - val_loss: 0.5400 - val_acc: 0.8590\n",
      "Epoch 391/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7467 - acc: 0.7231 - val_loss: 0.5403 - val_acc: 0.8590\n",
      "Epoch 392/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7454 - acc: 0.7231 - val_loss: 0.5400 - val_acc: 0.8590\n",
      "Epoch 393/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7483 - acc: 0.7231 - val_loss: 0.5402 - val_acc: 0.8590\n",
      "Epoch 394/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7480 - acc: 0.7231 - val_loss: 0.5401 - val_acc: 0.8590\n",
      "Epoch 395/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7437 - acc: 0.7231 - val_loss: 0.5407 - val_acc: 0.8590\n",
      "Epoch 396/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7477 - acc: 0.7231 - val_loss: 0.5402 - val_acc: 0.8590\n",
      "Epoch 397/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7491 - acc: 0.7231 - val_loss: 0.5409 - val_acc: 0.8590\n",
      "Epoch 398/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7454 - acc: 0.7231 - val_loss: 0.5409 - val_acc: 0.8590\n",
      "Epoch 399/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7405 - acc: 0.7231 - val_loss: 0.5406 - val_acc: 0.8590\n",
      "Epoch 400/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7401 - acc: 0.7231 - val_loss: 0.5408 - val_acc: 0.8590\n",
      "Epoch 401/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7475 - acc: 0.7231 - val_loss: 0.5404 - val_acc: 0.8590\n",
      "Epoch 402/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7417 - acc: 0.7231 - val_loss: 0.5405 - val_acc: 0.8590\n",
      "Epoch 403/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7434 - acc: 0.7231 - val_loss: 0.5401 - val_acc: 0.8590\n",
      "Epoch 404/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7473 - acc: 0.7231 - val_loss: 0.5401 - val_acc: 0.8590\n",
      "Epoch 405/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7503 - acc: 0.7231 - val_loss: 0.5403 - val_acc: 0.8590\n",
      "Epoch 406/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7438 - acc: 0.7231 - val_loss: 0.5408 - val_acc: 0.8590\n",
      "Epoch 407/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.7429 - acc: 0.7231 - val_loss: 0.5406 - val_acc: 0.8590\n",
      "Epoch 408/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.7542 - acc: 0.7231 - val_loss: 0.5405 - val_acc: 0.8590\n",
      "Epoch 409/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7374 - acc: 0.7231 - val_loss: 0.5398 - val_acc: 0.8590\n",
      "Epoch 410/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7455 - acc: 0.7231 - val_loss: 0.5395 - val_acc: 0.8590\n",
      "Epoch 411/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7522 - acc: 0.7231 - val_loss: 0.5398 - val_acc: 0.8590\n",
      "Epoch 412/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7452 - acc: 0.7231 - val_loss: 0.5399 - val_acc: 0.8590\n",
      "Epoch 413/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7383 - acc: 0.7231 - val_loss: 0.5401 - val_acc: 0.8590\n",
      "Epoch 414/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7492 - acc: 0.7231 - val_loss: 0.5401 - val_acc: 0.8590\n",
      "Epoch 415/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7410 - acc: 0.7231 - val_loss: 0.5402 - val_acc: 0.8590\n",
      "Epoch 416/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7392 - acc: 0.7231 - val_loss: 0.5401 - val_acc: 0.8590\n",
      "Epoch 417/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7382 - acc: 0.7231 - val_loss: 0.5397 - val_acc: 0.8590\n",
      "Epoch 418/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7507 - acc: 0.7231 - val_loss: 0.5397 - val_acc: 0.8590\n",
      "Epoch 419/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7363 - acc: 0.7231 - val_loss: 0.5393 - val_acc: 0.8590\n",
      "Epoch 420/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7451 - acc: 0.7231 - val_loss: 0.5397 - val_acc: 0.8590\n",
      "Epoch 421/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7427 - acc: 0.7231 - val_loss: 0.5395 - val_acc: 0.8590\n",
      "Epoch 422/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7549 - acc: 0.7231 - val_loss: 0.5401 - val_acc: 0.8590\n",
      "Epoch 423/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7369 - acc: 0.7231 - val_loss: 0.5400 - val_acc: 0.8590\n",
      "Epoch 424/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7444 - acc: 0.7231 - val_loss: 0.5400 - val_acc: 0.8590\n",
      "Epoch 425/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7416 - acc: 0.7231 - val_loss: 0.5395 - val_acc: 0.8590\n",
      "Epoch 426/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7413 - acc: 0.7231 - val_loss: 0.5397 - val_acc: 0.8590\n",
      "Epoch 427/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7413 - acc: 0.7231 - val_loss: 0.5396 - val_acc: 0.8590\n",
      "Epoch 428/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7506 - acc: 0.7231 - val_loss: 0.5394 - val_acc: 0.8590\n",
      "Epoch 429/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7413 - acc: 0.7231 - val_loss: 0.5394 - val_acc: 0.8590\n",
      "Epoch 430/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7377 - acc: 0.7231 - val_loss: 0.5392 - val_acc: 0.8590\n",
      "Epoch 431/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7423 - acc: 0.7231 - val_loss: 0.5393 - val_acc: 0.8590\n",
      "Epoch 432/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7382 - acc: 0.7231 - val_loss: 0.5390 - val_acc: 0.8590\n",
      "Epoch 433/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7368 - acc: 0.7231 - val_loss: 0.5386 - val_acc: 0.8590\n",
      "Epoch 434/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7414 - acc: 0.7231 - val_loss: 0.5386 - val_acc: 0.8590\n",
      "Epoch 435/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7430 - acc: 0.7231 - val_loss: 0.5388 - val_acc: 0.8590\n",
      "Epoch 436/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7419 - acc: 0.7231 - val_loss: 0.5392 - val_acc: 0.8590\n",
      "Epoch 437/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7474 - acc: 0.7231 - val_loss: 0.5389 - val_acc: 0.8590\n",
      "Epoch 438/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7340 - acc: 0.7231 - val_loss: 0.5391 - val_acc: 0.8590\n",
      "Epoch 439/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7426 - acc: 0.7231 - val_loss: 0.5390 - val_acc: 0.8590\n",
      "Epoch 440/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7349 - acc: 0.7231 - val_loss: 0.5389 - val_acc: 0.8590\n",
      "Epoch 441/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7425 - acc: 0.7231 - val_loss: 0.5389 - val_acc: 0.8590\n",
      "Epoch 442/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7358 - acc: 0.7231 - val_loss: 0.5389 - val_acc: 0.8590\n",
      "Epoch 443/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7442 - acc: 0.7231 - val_loss: 0.5392 - val_acc: 0.8590\n",
      "Epoch 444/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7455 - acc: 0.7231 - val_loss: 0.5388 - val_acc: 0.8590\n",
      "Epoch 445/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7456 - acc: 0.7231 - val_loss: 0.5386 - val_acc: 0.8590\n",
      "Epoch 446/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7469 - acc: 0.7231 - val_loss: 0.5391 - val_acc: 0.8590\n",
      "Epoch 447/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7419 - acc: 0.7231 - val_loss: 0.5389 - val_acc: 0.8590\n",
      "Epoch 448/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7363 - acc: 0.7231 - val_loss: 0.5391 - val_acc: 0.8590\n",
      "Epoch 449/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7361 - acc: 0.7231 - val_loss: 0.5388 - val_acc: 0.8590\n",
      "Epoch 450/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7402 - acc: 0.7231 - val_loss: 0.5384 - val_acc: 0.8590\n",
      "Epoch 451/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7421 - acc: 0.7231 - val_loss: 0.5388 - val_acc: 0.8590\n",
      "Epoch 452/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7366 - acc: 0.7231 - val_loss: 0.5387 - val_acc: 0.8590\n",
      "Epoch 453/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7361 - acc: 0.7231 - val_loss: 0.5383 - val_acc: 0.8590\n",
      "Epoch 454/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7398 - acc: 0.7231 - val_loss: 0.5383 - val_acc: 0.8590\n",
      "Epoch 455/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7419 - acc: 0.7231 - val_loss: 0.5380 - val_acc: 0.8590\n",
      "Epoch 456/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7333 - acc: 0.7231 - val_loss: 0.5376 - val_acc: 0.8590\n",
      "Epoch 457/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7400 - acc: 0.7231 - val_loss: 0.5377 - val_acc: 0.8590\n",
      "Epoch 458/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7395 - acc: 0.7231 - val_loss: 0.5376 - val_acc: 0.8590\n",
      "Epoch 459/500\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.7451 - acc: 0.7231 - val_loss: 0.5380 - val_acc: 0.8590\n",
      "Epoch 460/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7381 - acc: 0.7231 - val_loss: 0.5378 - val_acc: 0.8590\n",
      "Epoch 461/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7436 - acc: 0.7231 - val_loss: 0.5374 - val_acc: 0.8590\n",
      "Epoch 462/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7478 - acc: 0.7231 - val_loss: 0.5380 - val_acc: 0.8590\n",
      "Epoch 463/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7358 - acc: 0.7231 - val_loss: 0.5381 - val_acc: 0.8590\n",
      "Epoch 464/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7414 - acc: 0.7231 - val_loss: 0.5381 - val_acc: 0.8590\n",
      "Epoch 465/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7350 - acc: 0.7231 - val_loss: 0.5385 - val_acc: 0.8590\n",
      "Epoch 466/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7388 - acc: 0.7231 - val_loss: 0.5381 - val_acc: 0.8590\n",
      "Epoch 467/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7370 - acc: 0.7231 - val_loss: 0.5380 - val_acc: 0.8590\n",
      "Epoch 468/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7440 - acc: 0.7231 - val_loss: 0.5383 - val_acc: 0.8590\n",
      "Epoch 469/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7365 - acc: 0.7231 - val_loss: 0.5384 - val_acc: 0.8590\n",
      "Epoch 470/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7392 - acc: 0.7231 - val_loss: 0.5380 - val_acc: 0.8590\n",
      "Epoch 471/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7474 - acc: 0.7231 - val_loss: 0.5380 - val_acc: 0.8590\n",
      "Epoch 472/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7413 - acc: 0.7231 - val_loss: 0.5380 - val_acc: 0.8590\n",
      "Epoch 473/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7454 - acc: 0.7231 - val_loss: 0.5379 - val_acc: 0.8590\n",
      "Epoch 474/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7413 - acc: 0.7231 - val_loss: 0.5384 - val_acc: 0.8590\n",
      "Epoch 475/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7390 - acc: 0.7231 - val_loss: 0.5384 - val_acc: 0.8590\n",
      "Epoch 476/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7347 - acc: 0.7231 - val_loss: 0.5383 - val_acc: 0.8590\n",
      "Epoch 477/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7372 - acc: 0.7231 - val_loss: 0.5378 - val_acc: 0.8590\n",
      "Epoch 478/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7478 - acc: 0.7231 - val_loss: 0.5378 - val_acc: 0.8590\n",
      "Epoch 479/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7347 - acc: 0.7231 - val_loss: 0.5377 - val_acc: 0.8590\n",
      "Epoch 480/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7411 - acc: 0.7231 - val_loss: 0.5378 - val_acc: 0.8590\n",
      "Epoch 481/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7422 - acc: 0.7231 - val_loss: 0.5378 - val_acc: 0.8590\n",
      "Epoch 482/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7355 - acc: 0.7231 - val_loss: 0.5380 - val_acc: 0.8590\n",
      "Epoch 483/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7378 - acc: 0.7231 - val_loss: 0.5379 - val_acc: 0.8590\n",
      "Epoch 484/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7399 - acc: 0.7231 - val_loss: 0.5374 - val_acc: 0.8590\n",
      "Epoch 485/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7437 - acc: 0.7231 - val_loss: 0.5379 - val_acc: 0.8590\n",
      "Epoch 486/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7434 - acc: 0.7231 - val_loss: 0.5381 - val_acc: 0.8590\n",
      "Epoch 487/500\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7367 - acc: 0.7231 - val_loss: 0.5380 - val_acc: 0.8590\n",
      "Epoch 488/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7415 - acc: 0.7231 - val_loss: 0.5377 - val_acc: 0.8590\n",
      "Epoch 489/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7393 - acc: 0.7231 - val_loss: 0.5384 - val_acc: 0.8590\n",
      "Epoch 490/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7341 - acc: 0.7231 - val_loss: 0.5385 - val_acc: 0.8590\n",
      "Epoch 491/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7414 - acc: 0.7231 - val_loss: 0.5380 - val_acc: 0.8590\n",
      "Epoch 492/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7445 - acc: 0.7231 - val_loss: 0.5377 - val_acc: 0.8590\n",
      "Epoch 493/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7339 - acc: 0.7231 - val_loss: 0.5372 - val_acc: 0.8590\n",
      "Epoch 494/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7404 - acc: 0.7231 - val_loss: 0.5373 - val_acc: 0.8590\n",
      "Epoch 495/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7413 - acc: 0.7231 - val_loss: 0.5379 - val_acc: 0.8590\n",
      "Epoch 496/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7373 - acc: 0.7231 - val_loss: 0.5377 - val_acc: 0.8590\n",
      "Epoch 497/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7396 - acc: 0.7231 - val_loss: 0.5378 - val_acc: 0.8590\n",
      "Epoch 498/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7371 - acc: 0.7231 - val_loss: 0.5382 - val_acc: 0.8590\n",
      "Epoch 499/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7425 - acc: 0.7231 - val_loss: 0.5379 - val_acc: 0.8590\n",
      "Epoch 500/500\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7413 - acc: 0.7231 - val_loss: 0.5382 - val_acc: 0.8590\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs=500, batch_size=64, \n",
    "          verbose=True, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['acc'], label='acc')\n",
    "plt.plot(history.history['val_acc'], label='val_acc')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 1ms/step - loss: 0.7288 - acc: 0.7231\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.5382 - acc: 0.8590\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.7288063764572144, 0.7230989933013916],\n",
       " [0.5382176637649536, 0.8589743375778198])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_train, y_train), model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distribution of classes: [ 98. 504.  95.]\n",
      "acc of model: 0.8589743589743589\n",
      "train\n",
      "-1 0 98 0.0\n",
      "0 504 504 1.0\n",
      "1 0 95 0.0\n",
      "test\n",
      "-1 0 2 0.0\n",
      "0 67 67 1.0\n",
      "1 0 9 0.0\n",
      "[(1, 1), (1, 1), (1, 1), (2, 1), (1, 1), (2, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (2, 1), (1, 1), (1, 1), (1, 1), (2, 1), (0, 1), (2, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (0, 1), (1, 1), (1, 1), (1, 1), (1, 1), (2, 1), (1, 1), (1, 1), (1, 1), (1, 1), (2, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (2, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (2, 1), (1, 1)]\n"
     ]
    }
   ],
   "source": [
    "p_test = model.predict(x_test)\n",
    "p_train = model.predict(x_train)\n",
    "print('distribution of classes:', np.sum(y_train, axis=0))\n",
    "print('acc of model:', np.mean(np.argmax(y_test, axis=1) == np.argmax(p_test, axis=1), axis=0))\n",
    "y_v = np.argmax(y_train, axis=1)\n",
    "p_v = np.argmax(p_train, axis=1)\n",
    "\n",
    "# we will check if at least we got the signs correctly\n",
    "\n",
    "def get_misses_per_class(y, p):\n",
    "    y_v = np.argmax(y, axis=1)\n",
    "    p_v = np.argmax(p, axis=1)\n",
    "\n",
    "    y_s = y_v - (classes - 2)\n",
    "    p_s = p_v - (classes - 2)\n",
    "\n",
    "    misses = {c - (classes-2) : 0 for c in range(classes) }\n",
    "    total = {c - (classes-2): 0 for c in range(classes) }\n",
    "\n",
    "    for i in range(len(y_s)):\n",
    "        misses[y_s[i]] += (y_s[i] == p_s[i])\n",
    "        total[y_s[i]] += 1\n",
    "\n",
    "    for k in total:\n",
    "        print(k, misses[k], total[k], misses[k]/total[k])\n",
    "\n",
    "\n",
    "print('train')\n",
    "get_misses_per_class(y_train, p_train)\n",
    "print('test')\n",
    "get_misses_per_class(y_test, p_test)\n",
    "print(list(zip(np.argmax(y_test, axis=-1), np.argmax(p_test, axis=-1))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not very impressive, as the majority of the time we are just predicting do not do anything. Also, our prediction for upward movements almost never got it right.\n",
    "\n",
    "Now, it is your turn to try to improve our stock prediction using LSTM's or GRUs. \n",
    "\n",
    "Another good datapoint is the following. In most of the cases, a good classifier needs to beat the previous day prediction as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of training set: 0.599713055954089\n",
      "accuracy of test set: 0.7435897435897436\n",
      "train\n",
      "-1 21 98 0.21428571428571427\n",
      "0 381 504 0.7559523809523809\n",
      "1 16 95 0.16842105263157894\n",
      "test\n",
      "-1 0 2 0.0\n",
      "0 58 67 0.8656716417910447\n",
      "1 0 9 0.0\n"
     ]
    }
   ],
   "source": [
    "acc_previous_day = 0\n",
    "movement_right = 0\n",
    "\n",
    "p_train[1:] = y_train[0:-1]\n",
    "p_test[0] = y_train[-1]\n",
    "p_test[1:] = y_test[0:-1]\n",
    "\n",
    "print('accuracy of training set:', np.mean(np.argmax(y_train, axis=-1) == np.argmax(p_train, axis=-1), axis=0))\n",
    "print('accuracy of test set:', np.mean(np.argmax(y_test, axis=-1) == np.argmax(p_test, axis=-1), axis=0))\n",
    "print('train')\n",
    "get_misses_per_class(y_train, p_train)\n",
    "print('test')\n",
    "get_misses_per_class(y_test, p_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 2 1 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 2 1]\n"
     ]
    }
   ],
   "source": [
    "print(np.argmax(y_train[:20], axis=-1))\n",
    "print(np.argmax(p_train[:20], axis=-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. IMDB Text Classification\n",
    "\n",
    "In this next lab, you will create a text classification using LSTMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import preprocessing\n",
    "from keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load imdb dataset and print a few samples to check.\n",
    "#\n",
    "# IMDB: sentence (x) -> positive/negative (y)\n",
    "#\n",
    "# “The food was really good”                             -> pos\n",
    "# “The chicken crossed the road because it was uncooked” -> neg\n",
    "\n",
    "num_words = 10000\n",
    "maxlen = 100\n",
    "embedded_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "17465344/17464789 [==============================] - 4s 0us/step\n",
      "17473536/17464789 [==============================] - 4s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=num_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
      "1646592/1641221 [==============================] - 1s 0us/step\n",
      "1654784/1641221 [==============================] - 1s 0us/step\n",
      "you\n"
     ]
    }
   ],
   "source": [
    "d = imdb.get_word_index()\n",
    "for w in d:\n",
    "    if d[w] == 22:\n",
    "        print(w)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25000,), (25000,), (25000,), (25000,))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 14,\n",
       " 22,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 973,\n",
       " 1622,\n",
       " 1385,\n",
       " 65,\n",
       " 458,\n",
       " 4468,\n",
       " 66,\n",
       " 3941,\n",
       " 4,\n",
       " 173,\n",
       " 36,\n",
       " 256,\n",
       " 5,\n",
       " 25,\n",
       " 100,\n",
       " 43,\n",
       " 838,\n",
       " 112,\n",
       " 50,\n",
       " 670,\n",
       " 2,\n",
       " 9,\n",
       " 35,\n",
       " 480,\n",
       " 284,\n",
       " 5,\n",
       " 150,\n",
       " 4,\n",
       " 172,\n",
       " 112,\n",
       " 167,\n",
       " 2,\n",
       " 336,\n",
       " 385,\n",
       " 39,\n",
       " 4,\n",
       " 172,\n",
       " 4536,\n",
       " 1111,\n",
       " 17,\n",
       " 546,\n",
       " 38,\n",
       " 13,\n",
       " 447,\n",
       " 4,\n",
       " 192,\n",
       " 50,\n",
       " 16,\n",
       " 6,\n",
       " 147,\n",
       " 2025,\n",
       " 19,\n",
       " 14,\n",
       " 22,\n",
       " 4,\n",
       " 1920,\n",
       " 4613,\n",
       " 469,\n",
       " 4,\n",
       " 22,\n",
       " 71,\n",
       " 87,\n",
       " 12,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 38,\n",
       " 76,\n",
       " 15,\n",
       " 13,\n",
       " 1247,\n",
       " 4,\n",
       " 22,\n",
       " 17,\n",
       " 515,\n",
       " 17,\n",
       " 12,\n",
       " 16,\n",
       " 626,\n",
       " 18,\n",
       " 2,\n",
       " 5,\n",
       " 62,\n",
       " 386,\n",
       " 12,\n",
       " 8,\n",
       " 316,\n",
       " 8,\n",
       " 106,\n",
       " 5,\n",
       " 4,\n",
       " 2223,\n",
       " 5244,\n",
       " 16,\n",
       " 480,\n",
       " 66,\n",
       " 3785,\n",
       " 33,\n",
       " 4,\n",
       " 130,\n",
       " 12,\n",
       " 16,\n",
       " 38,\n",
       " 619,\n",
       " 5,\n",
       " 25,\n",
       " 124,\n",
       " 51,\n",
       " 36,\n",
       " 135,\n",
       " 48,\n",
       " 25,\n",
       " 1415,\n",
       " 33,\n",
       " 6,\n",
       " 22,\n",
       " 12,\n",
       " 215,\n",
       " 28,\n",
       " 77,\n",
       " 52,\n",
       " 5,\n",
       " 14,\n",
       " 407,\n",
       " 16,\n",
       " 82,\n",
       " 2,\n",
       " 8,\n",
       " 4,\n",
       " 107,\n",
       " 117,\n",
       " 5952,\n",
       " 15,\n",
       " 256,\n",
       " 4,\n",
       " 2,\n",
       " 7,\n",
       " 3766,\n",
       " 5,\n",
       " 723,\n",
       " 36,\n",
       " 71,\n",
       " 43,\n",
       " 530,\n",
       " 476,\n",
       " 26,\n",
       " 400,\n",
       " 317,\n",
       " 46,\n",
       " 7,\n",
       " 4,\n",
       " 2,\n",
       " 1029,\n",
       " 13,\n",
       " 104,\n",
       " 88,\n",
       " 4,\n",
       " 381,\n",
       " 15,\n",
       " 297,\n",
       " 98,\n",
       " 32,\n",
       " 2071,\n",
       " 56,\n",
       " 26,\n",
       " 141,\n",
       " 6,\n",
       " 194,\n",
       " 7486,\n",
       " 18,\n",
       " 4,\n",
       " 226,\n",
       " 22,\n",
       " 21,\n",
       " 134,\n",
       " 476,\n",
       " 26,\n",
       " 480,\n",
       " 5,\n",
       " 144,\n",
       " 30,\n",
       " 5535,\n",
       " 18,\n",
       " 51,\n",
       " 36,\n",
       " 28,\n",
       " 224,\n",
       " 92,\n",
       " 25,\n",
       " 104,\n",
       " 4,\n",
       " 226,\n",
       " 65,\n",
       " 16,\n",
       " 38,\n",
       " 1334,\n",
       " 88,\n",
       " 12,\n",
       " 16,\n",
       " 283,\n",
       " 5,\n",
       " 16,\n",
       " 4472,\n",
       " 113,\n",
       " 103,\n",
       " 32,\n",
       " 15,\n",
       " 16,\n",
       " 5345,\n",
       " 19,\n",
       " 178,\n",
       " 32]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x_train has a size (training_size, ). Because the sentences have variable size, we cannot represent this in matrix format.\n",
    "\n",
    "The first step is to make the column size constant. We do that by \"padding\" the sentences. If the sentences are bigger, we clip them. If they are smaller, we insert a \"NO_WORD\" token to the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25000, 100), (25000, 100))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "x_train = pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = pad_sequences(x_test, maxlen=maxlen)\n",
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1415,   33,    6,   22,   12,  215,   28,   77,   52,    5,   14,\n",
       "        407,   16,   82,    2,    8,    4,  107,  117, 5952,   15,  256,\n",
       "          4,    2,    7, 3766,    5,  723,   36,   71,   43,  530,  476,\n",
       "         26,  400,  317,   46,    7,    4,    2, 1029,   13,  104,   88,\n",
       "          4,  381,   15,  297,   98,   32, 2071,   56,   26,  141,    6,\n",
       "        194, 7486,   18,    4,  226,   22,   21,  134,  476,   26,  480,\n",
       "          5,  144,   30, 5535,   18,   51,   36,   28,  224,   92,   25,\n",
       "        104,    4,  226,   65,   16,   38, 1334,   88,   12,   16,  283,\n",
       "          5,   16, 4472,  113,  103,   32,   15,   16, 5345,   19,  178,\n",
       "         32])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 100, 16)           160000    \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 1601      \n",
      "=================================================================\n",
      "Total params: 161,601\n",
      "Trainable params: 161,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def CreateModel(i_shape):\n",
    "    x_i = keras.layers.Input(i_shape)\n",
    "    x = keras.layers.Embedding(num_words, embedded_size,\n",
    "                               input_length=maxlen)(x_i)\n",
    "    x = keras.layers.Flatten()(x)\n",
    "    x = keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    return keras.models.Model(x_i, x)\n",
    "\n",
    "model = CreateModel(x_train.shape[1:])\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.6181 - acc: 0.6776 - val_loss: 0.4476 - val_acc: 0.8144\n",
      "Epoch 2/20\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3381 - acc: 0.8672 - val_loss: 0.3400 - val_acc: 0.8506\n",
      "Epoch 3/20\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2376 - acc: 0.9131 - val_loss: 0.3273 - val_acc: 0.8514\n",
      "Epoch 4/20\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1767 - acc: 0.9432 - val_loss: 0.3346 - val_acc: 0.8514\n",
      "Epoch 5/20\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1273 - acc: 0.9675 - val_loss: 0.3498 - val_acc: 0.8498\n",
      "Epoch 6/20\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0883 - acc: 0.9833 - val_loss: 0.3648 - val_acc: 0.8464\n",
      "Epoch 7/20\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0595 - acc: 0.9925 - val_loss: 0.3856 - val_acc: 0.8436\n",
      "Epoch 8/20\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0396 - acc: 0.9973 - val_loss: 0.4039 - val_acc: 0.8426\n",
      "Epoch 9/20\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0268 - acc: 0.9991 - val_loss: 0.4249 - val_acc: 0.8406\n",
      "Epoch 10/20\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0187 - acc: 0.9998 - val_loss: 0.4447 - val_acc: 0.8394\n",
      "Epoch 11/20\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0133 - acc: 0.9997 - val_loss: 0.4632 - val_acc: 0.8392\n",
      "Epoch 12/20\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0098 - acc: 0.9999 - val_loss: 0.4818 - val_acc: 0.8400\n",
      "Epoch 13/20\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0073 - acc: 1.0000 - val_loss: 0.5003 - val_acc: 0.8376\n",
      "Epoch 14/20\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0055 - acc: 1.0000 - val_loss: 0.5162 - val_acc: 0.8388\n",
      "Epoch 15/20\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0043 - acc: 1.0000 - val_loss: 0.5324 - val_acc: 0.8372\n",
      "Epoch 16/20\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.5479 - val_acc: 0.8368\n",
      "Epoch 17/20\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.5641 - val_acc: 0.8372\n",
      "Epoch 18/20\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.5788 - val_acc: 0.8372\n",
      "Epoch 19/20\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.5947 - val_acc: 0.8362\n",
      "Epoch 20/20\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.6084 - val_acc: 0.8352\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18b5be372e0>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    x_train, y_train, epochs=20, batch_size=64,\n",
    "    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 823us/step - loss: 0.6015 - acc: 0.8365\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8365200161933899"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_result = model.evaluate(x_test, y_test)\n",
    "eval_result[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What's the current accuracy for this model? **0.8365200161933899**\n",
    "- Try to add a preloaded embedded from Glove from this model, see the\n",
    "suggestion in https://blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html\n",
    "- Question: why does this model may help you get better accuracy?\n",
    "- **Answer: using pre-trained embeddings is relevant for natural processing tasks were little training data is available (functionally the embeddings act as an injection of outside information which might prove useful for your model).**\n",
    "- Try using an LSTM instead of the models above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Glove pre-trained word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Only the TensorFlow backend supports string inputs.\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import tensorflow.data as tf_data\n",
    "import keras\n",
    "from keras import layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://www.cs.cmu.edu/afs/cs.cmu.edu/project/theo-20/www/data/news20.tar.gz\n",
      "17334272/17329808 [==============================] - 31s 2us/step\n",
      "17342464/17329808 [==============================] - 31s 2us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import get_file\n",
    "\n",
    "data_path = get_file(\n",
    "    \"news20.tar.gz\",\n",
    "    \"http://www.cs.cmu.edu/afs/cs.cmu.edu/project/theo-20/www/data/news20.tar.gz\",\n",
    "    untar=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of directories: 20\n",
      "Directory names: ['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n",
      "Number of files in comp.graphics: 1000\n",
      "Some example filenames: ['37261', '37913', '37914', '37915', '37916']\n"
     ]
    }
   ],
   "source": [
    "data_dir = pathlib.Path(data_path).parent / \"20_newsgroup\"\n",
    "dirnames = os.listdir(data_dir)\n",
    "print(\"Number of directories:\", len(dirnames))\n",
    "print(\"Directory names:\", dirnames)\n",
    "\n",
    "fnames = os.listdir(data_dir / \"comp.graphics\")\n",
    "print(\"Number of files in comp.graphics:\", len(fnames))\n",
    "print(\"Some example filenames:\", fnames[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Newsgroups: comp.graphics\n",
      "Path: cantaloupe.srv.cs.cmu.edu!das-news.harvard.edu!noc.near.net!howland.reston.ans.net!agate!dog.ee.lbl.gov!network.ucsd.edu!usc!rpi!nason110.its.rpi.edu!mabusj\n",
      "From: mabusj@nason110.its.rpi.edu (Jasen M. Mabus)\n",
      "Subject: Looking for Brain in CAD\n",
      "Message-ID: <c285m+p@rpi.edu>\n",
      "Nntp-Posting-Host: nason110.its.rpi.edu\n",
      "Reply-To: mabusj@rpi.edu\n",
      "Organization: Rensselaer Polytechnic Institute, Troy, NY.\n",
      "Date: Thu, 29 Apr 1993 23:27:20 GMT\n",
      "Lines: 7\n",
      "\n",
      "Jasen Mabus\n",
      "RPI student\n",
      "\n",
      "\tI am looking for a hman brain in any CAD (.dxf,.cad,.iges,.cgm,etc.) or picture (.gif,.jpg,.ras,etc.) format for an animation demonstration. If any has or knows of a location please reply by e-mail to mabusj@rpi.edu.\n",
      "\n",
      "Thank you in advance,\n",
      "Jasen Mabus  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(open(data_dir / \"comp.graphics\" / \"38987\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing alt.atheism, 1000 files found\n",
      "Processing comp.graphics, 1000 files found\n",
      "Processing comp.os.ms-windows.misc, 1000 files found\n",
      "Processing comp.sys.ibm.pc.hardware, 1000 files found\n",
      "Processing comp.sys.mac.hardware, 1000 files found\n",
      "Processing comp.windows.x, 1000 files found\n",
      "Processing misc.forsale, 1000 files found\n",
      "Processing rec.autos, 1000 files found\n",
      "Processing rec.motorcycles, 1000 files found\n",
      "Processing rec.sport.baseball, 1000 files found\n",
      "Processing rec.sport.hockey, 1000 files found\n",
      "Processing sci.crypt, 1000 files found\n",
      "Processing sci.electronics, 1000 files found\n",
      "Processing sci.med, 1000 files found\n",
      "Processing sci.space, 1000 files found\n",
      "Processing soc.religion.christian, 997 files found\n",
      "Processing talk.politics.guns, 1000 files found\n",
      "Processing talk.politics.mideast, 1000 files found\n",
      "Processing talk.politics.misc, 1000 files found\n",
      "Processing talk.religion.misc, 1000 files found\n",
      "Classes: ['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n",
      "Number of samples: 19997\n"
     ]
    }
   ],
   "source": [
    "samples = []\n",
    "labels = []\n",
    "class_names = []\n",
    "class_index = 0\n",
    "for dirname in sorted(os.listdir(data_dir)):\n",
    "    class_names.append(dirname)\n",
    "    dirpath = data_dir / dirname\n",
    "    fnames = os.listdir(dirpath)\n",
    "    print(\"Processing %s, %d files found\" % (dirname, len(fnames)))\n",
    "    for fname in fnames:\n",
    "        fpath = dirpath / fname\n",
    "        f = open(fpath, encoding=\"latin-1\")\n",
    "        content = f.read()\n",
    "        lines = content.split(\"\\n\")\n",
    "        lines = lines[10:]\n",
    "        content = \"\\n\".join(lines)\n",
    "        samples.append(content)\n",
    "        labels.append(class_index)\n",
    "    class_index += 1\n",
    "\n",
    "print(\"Classes:\", class_names)\n",
    "print(\"Number of samples:\", len(samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the data\n",
    "seed = 1337\n",
    "rng = np.random.RandomState(seed)\n",
    "rng.shuffle(samples)\n",
    "rng = np.random.RandomState(seed)\n",
    "rng.shuffle(labels)\n",
    "\n",
    "# Extract a training & validation split\n",
    "validation_split = 0.2\n",
    "num_validation_samples = int(validation_split * len(samples))\n",
    "train_samples = samples[:-num_validation_samples]\n",
    "val_samples = samples[-num_validation_samples:]\n",
    "train_labels = labels[:-num_validation_samples]\n",
    "val_labels = labels[-num_validation_samples:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '[UNK]', 'the', 'to', 'of']"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "# from tensorflow import tf_data\n",
    "\n",
    "vectorizer = layers.TextVectorization(max_tokens=20000, output_sequence_length=200)\n",
    "text_ds = tf_data.Dataset.from_tensor_slices(train_samples).batch(128)\n",
    "vectorizer.adapt(text_ds)\n",
    "\n",
    "vectorizer.get_vocabulary()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   2, 3456, 1682,   15,    2, 5776], dtype=int64)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = vectorizer([[\"the cat sat on the mat\"]])\n",
    "output.numpy()[0, :6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc = vectorizer.get_vocabulary()\n",
    "word_index = dict(zip(voc, range(len(voc))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3456, 1682, 15, 2, 5776]"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = [\"the\", \"cat\", \"sat\", \"on\", \"the\", \"mat\"]\n",
    "[word_index[w] for w in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "path_to_glove_file = \"glove.6B/glove.6B.100d.txt\"\n",
    "\n",
    "embeddings_index = {}\n",
    "with open(path_to_glove_file, encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        word, coefs = line.split(maxsplit=1)\n",
    "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "print(\"Found %s word vectors.\" % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 18019 words (1981 misses)\n"
     ]
    }
   ],
   "source": [
    "num_tokens = len(voc) + 2\n",
    "embedding_dim = 100\n",
    "hits = 0\n",
    "misses = 0\n",
    "\n",
    "# Prepare embedding matrix\n",
    "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # Words not found in embedding index will be all-zeros.\n",
    "        # This includes the representation for \"padding\" and \"OOV\"\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        hits += 1\n",
    "    else:\n",
    "        misses += 1\n",
    "print(\"Converted %d words (%d misses)\" % (hits, misses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Embedding\n",
    "\n",
    "embedding_layer = Embedding(\n",
    "    num_tokens,\n",
    "    embedding_dim,\n",
    "    trainable=False,\n",
    ")\n",
    "embedding_layer.build((1,))\n",
    "embedding_layer.set_weights([embedding_matrix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_15 (InputLayer)        [(None, None)]            0         \n",
      "_________________________________________________________________\n",
      "embedding_10 (Embedding)     (None, None, 100)         2000200   \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, None, 128)         64128     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, None, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, None, 128)         82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, None, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, None, 128)         82048     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 20)                2580      \n",
      "=================================================================\n",
      "Total params: 2,247,516\n",
      "Trainable params: 247,316\n",
      "Non-trainable params: 2,000,200\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "int_sequences_input = keras.Input(shape=(None,), dtype=\"int32\")\n",
    "embedded_sequences = embedding_layer(int_sequences_input)\n",
    "x = layers.Conv1D(128, 5, activation=\"relu\")(embedded_sequences)\n",
    "x = layers.MaxPooling1D(5)(x)\n",
    "x = layers.Conv1D(128, 5, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling1D(5)(x)\n",
    "x = layers.Conv1D(128, 5, activation=\"relu\")(x)\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "x = layers.Dense(128, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "preds = layers.Dense(len(class_names), activation=\"softmax\")(x)\n",
    "model = keras.Model(int_sequences_input, preds)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = vectorizer(np.array([[s] for s in train_samples])).numpy()\n",
    "x_val = vectorizer(np.array([[s] for s in val_samples])).numpy()\n",
    "\n",
    "y_train = np.array(train_labels)\n",
    "y_val = np.array(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "125/125 [==============================] - 6s 8ms/step - loss: 2.6559 - acc: 0.1373 - val_loss: 2.1287 - val_acc: 0.2711\n",
      "Epoch 2/100\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 1.9604 - acc: 0.3200 - val_loss: 1.8584 - val_acc: 0.3351\n",
      "Epoch 3/100\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 1.5588 - acc: 0.4667 - val_loss: 1.3470 - val_acc: 0.5284\n",
      "Epoch 4/100\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 1.2975 - acc: 0.5522 - val_loss: 1.1317 - val_acc: 0.6157\n",
      "Epoch 5/100\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 1.1258 - acc: 0.6138 - val_loss: 1.0829 - val_acc: 0.6272\n",
      "Epoch 6/100\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.9902 - acc: 0.6589 - val_loss: 1.0061 - val_acc: 0.6552\n",
      "Epoch 7/100\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.8657 - acc: 0.7015 - val_loss: 1.0007 - val_acc: 0.6752\n",
      "Epoch 8/100\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.7700 - acc: 0.7307 - val_loss: 0.9359 - val_acc: 0.6884\n",
      "Epoch 9/100\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.6617 - acc: 0.7660 - val_loss: 1.0259 - val_acc: 0.6797\n",
      "Epoch 10/100\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.5909 - acc: 0.7938 - val_loss: 1.2318 - val_acc: 0.6209\n",
      "Epoch 11/100\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.4996 - acc: 0.8255 - val_loss: 1.1083 - val_acc: 0.6829\n",
      "Epoch 12/100\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.4568 - acc: 0.8404 - val_loss: 1.0772 - val_acc: 0.6837\n",
      "Epoch 13/100\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.3847 - acc: 0.8662 - val_loss: 1.0605 - val_acc: 0.7009\n",
      "Epoch 14/100\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.3458 - acc: 0.8819 - val_loss: 1.4464 - val_acc: 0.6492\n",
      "Epoch 15/100\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.3048 - acc: 0.8979 - val_loss: 1.1025 - val_acc: 0.7194\n",
      "Epoch 16/100\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.2625 - acc: 0.9122 - val_loss: 1.3119 - val_acc: 0.6967\n",
      "Epoch 17/100\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.2385 - acc: 0.9198 - val_loss: 1.1677 - val_acc: 0.7222\n",
      "Epoch 18/100\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.2131 - acc: 0.9264 - val_loss: 1.3139 - val_acc: 0.7089\n",
      "Epoch 19/100\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.2005 - acc: 0.9317 - val_loss: 1.2512 - val_acc: 0.7174\n",
      "Epoch 20/100\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.1785 - acc: 0.9407 - val_loss: 1.3582 - val_acc: 0.7014\n",
      "Epoch 21/100\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.1745 - acc: 0.9412 - val_loss: 1.5474 - val_acc: 0.7047\n",
      "Epoch 22/100\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.1673 - acc: 0.9421 - val_loss: 1.5188 - val_acc: 0.7149\n",
      "Epoch 23/100\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.1544 - acc: 0.9466 - val_loss: 1.5741 - val_acc: 0.6982\n",
      "Epoch 24/100\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.1457 - acc: 0.9507 - val_loss: 1.7193 - val_acc: 0.6899\n",
      "Epoch 25/100\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.1434 - acc: 0.9507 - val_loss: 2.1359 - val_acc: 0.6642\n",
      "Epoch 26/100\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.1427 - acc: 0.9496 - val_loss: 1.4796 - val_acc: 0.7127\n",
      "Epoch 27/100\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.1323 - acc: 0.9526 - val_loss: 1.6022 - val_acc: 0.7002\n",
      "Epoch 00027: early stopping\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\", optimizer=\"rmsprop\", metrics=[\"acc\"]\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_acc', patience=10, min_delta=0.001, mode='max', verbose=1)\n",
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=100, \n",
    "                    batch_size=128,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    callbacks=[early_stopping])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now Use LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_7 (Embedding)     (None, 200, 128)          2560000   \n",
      "                                                                 \n",
      " lstm_7 (LSTM)               (None, 200, 64)           49408     \n",
      "                                                                 \n",
      " lstm_8 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 20)                1300      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,647,892\n",
      "Trainable params: 2,647,892\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Assuming you have the maximum sequence length after vectorization\n",
    "max_features = 20000  # This is the size of the vocabulary in the vectorizer\n",
    "max_len = x_train.shape[1]  # The length of sequences processed after vectorization\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Embedding(input_dim=max_features, output_dim=128, input_length=max_len))\n",
    "model.add(layers.LSTM(64, return_sequences=True))\n",
    "model.add(layers.LSTM(64))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(len(np.unique(y_train)), activation='softmax'))  # Assuming classification task\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "125/125 [==============================] - 5s 41ms/step - loss: 2.6923 - accuracy: 0.0974 - val_loss: 2.6045 - val_accuracy: 0.0970\n",
      "Epoch 2/100\n",
      "125/125 [==============================] - 5s 41ms/step - loss: 2.6576 - accuracy: 0.0998 - val_loss: 2.6008 - val_accuracy: 0.1008\n",
      "Epoch 3/100\n",
      "125/125 [==============================] - 5s 43ms/step - loss: 2.5756 - accuracy: 0.1080 - val_loss: 2.5115 - val_accuracy: 0.1273\n",
      "Epoch 4/100\n",
      "125/125 [==============================] - 5s 43ms/step - loss: 2.6925 - accuracy: 0.0979 - val_loss: 2.8452 - val_accuracy: 0.0738\n",
      "Epoch 5/100\n",
      "125/125 [==============================] - 6s 45ms/step - loss: 2.7972 - accuracy: 0.0843 - val_loss: 2.6458 - val_accuracy: 0.1053\n",
      "Epoch 6/100\n",
      "125/125 [==============================] - 6s 49ms/step - loss: 2.6252 - accuracy: 0.1028 - val_loss: 2.6226 - val_accuracy: 0.1043\n",
      "Epoch 7/100\n",
      "125/125 [==============================] - 6s 50ms/step - loss: 2.9550 - accuracy: 0.0643 - val_loss: 2.9963 - val_accuracy: 0.0470\n",
      "Epoch 8/100\n",
      "125/125 [==============================] - 6s 47ms/step - loss: 2.9800 - accuracy: 0.0562 - val_loss: 2.9327 - val_accuracy: 0.0715\n",
      "Epoch 9/100\n",
      "125/125 [==============================] - 5s 43ms/step - loss: 2.8734 - accuracy: 0.0787 - val_loss: 2.7795 - val_accuracy: 0.0850\n",
      "Epoch 10/100\n",
      "125/125 [==============================] - 5s 41ms/step - loss: 2.6644 - accuracy: 0.0931 - val_loss: 2.4818 - val_accuracy: 0.1335\n",
      "Epoch 11/100\n",
      "125/125 [==============================] - 5s 41ms/step - loss: 2.5080 - accuracy: 0.1178 - val_loss: 2.4670 - val_accuracy: 0.1393\n",
      "Epoch 12/100\n",
      "125/125 [==============================] - 5s 41ms/step - loss: 2.4276 - accuracy: 0.1334 - val_loss: 2.4799 - val_accuracy: 0.1320\n",
      "Epoch 13/100\n",
      "125/125 [==============================] - 5s 42ms/step - loss: 2.4052 - accuracy: 0.1328 - val_loss: 2.4198 - val_accuracy: 0.1365\n",
      "Epoch 14/100\n",
      "125/125 [==============================] - 5s 41ms/step - loss: 2.3672 - accuracy: 0.1365 - val_loss: 2.4049 - val_accuracy: 0.1310\n",
      "Epoch 15/100\n",
      "125/125 [==============================] - 5s 41ms/step - loss: 2.3429 - accuracy: 0.1372 - val_loss: 2.3939 - val_accuracy: 0.1335\n",
      "Epoch 16/100\n",
      "125/125 [==============================] - 5s 41ms/step - loss: 2.3048 - accuracy: 0.1529 - val_loss: 2.3968 - val_accuracy: 0.1345\n",
      "Epoch 17/100\n",
      "125/125 [==============================] - 5s 41ms/step - loss: 2.3218 - accuracy: 0.1466 - val_loss: 2.3793 - val_accuracy: 0.1350\n",
      "Epoch 18/100\n",
      "125/125 [==============================] - 5s 41ms/step - loss: 2.2703 - accuracy: 0.1560 - val_loss: 2.3150 - val_accuracy: 0.1595\n",
      "Epoch 19/100\n",
      "125/125 [==============================] - 5s 41ms/step - loss: 2.1969 - accuracy: 0.1758 - val_loss: 2.2880 - val_accuracy: 0.1850\n",
      "Epoch 20/100\n",
      "125/125 [==============================] - 5s 42ms/step - loss: 2.1239 - accuracy: 0.1915 - val_loss: 2.2239 - val_accuracy: 0.1880\n",
      "Epoch 21/100\n",
      "125/125 [==============================] - 5s 42ms/step - loss: 2.0427 - accuracy: 0.2057 - val_loss: 2.2047 - val_accuracy: 0.1943\n",
      "Epoch 22/100\n",
      "125/125 [==============================] - 5s 41ms/step - loss: 1.9926 - accuracy: 0.2148 - val_loss: 2.2356 - val_accuracy: 0.1935\n",
      "Epoch 23/100\n",
      "125/125 [==============================] - 5s 41ms/step - loss: 1.9223 - accuracy: 0.2277 - val_loss: 2.1947 - val_accuracy: 0.2203\n",
      "Epoch 24/100\n",
      "125/125 [==============================] - 5s 43ms/step - loss: 1.8466 - accuracy: 0.2468 - val_loss: 2.1445 - val_accuracy: 0.2281\n",
      "Epoch 25/100\n",
      "125/125 [==============================] - 5s 42ms/step - loss: 1.7730 - accuracy: 0.2653 - val_loss: 2.1145 - val_accuracy: 0.2526\n",
      "Epoch 26/100\n",
      "125/125 [==============================] - 5s 42ms/step - loss: 1.7240 - accuracy: 0.2806 - val_loss: 2.1543 - val_accuracy: 0.2513\n",
      "Epoch 27/100\n",
      "125/125 [==============================] - 5s 41ms/step - loss: 1.6617 - accuracy: 0.2987 - val_loss: 2.1772 - val_accuracy: 0.2688\n",
      "Epoch 28/100\n",
      "125/125 [==============================] - 5s 42ms/step - loss: 1.6170 - accuracy: 0.3127 - val_loss: 2.1969 - val_accuracy: 0.2736\n",
      "Epoch 29/100\n",
      "125/125 [==============================] - 5s 41ms/step - loss: 1.5537 - accuracy: 0.3345 - val_loss: 2.2047 - val_accuracy: 0.2883\n",
      "Epoch 30/100\n",
      "125/125 [==============================] - 5s 41ms/step - loss: 1.4972 - accuracy: 0.3528 - val_loss: 2.3033 - val_accuracy: 0.3113\n",
      "Epoch 31/100\n",
      "125/125 [==============================] - 5s 42ms/step - loss: 1.4700 - accuracy: 0.3580 - val_loss: 2.1777 - val_accuracy: 0.3186\n",
      "Epoch 32/100\n",
      "125/125 [==============================] - 5s 41ms/step - loss: 1.4107 - accuracy: 0.3809 - val_loss: 2.2689 - val_accuracy: 0.3153\n",
      "Epoch 33/100\n",
      "125/125 [==============================] - 5s 41ms/step - loss: 1.3724 - accuracy: 0.3969 - val_loss: 2.3167 - val_accuracy: 0.3023\n",
      "Epoch 34/100\n",
      "125/125 [==============================] - 5s 41ms/step - loss: 1.3594 - accuracy: 0.4020 - val_loss: 2.2608 - val_accuracy: 0.3271\n",
      "Epoch 35/100\n",
      "125/125 [==============================] - 5s 41ms/step - loss: 1.3261 - accuracy: 0.4172 - val_loss: 2.2382 - val_accuracy: 0.3593\n",
      "Epoch 36/100\n",
      "125/125 [==============================] - 5s 41ms/step - loss: 1.2770 - accuracy: 0.4352 - val_loss: 2.2067 - val_accuracy: 0.3653\n",
      "Epoch 37/100\n",
      "125/125 [==============================] - 5s 41ms/step - loss: 1.2212 - accuracy: 0.4553 - val_loss: 2.3594 - val_accuracy: 0.3881\n",
      "Epoch 38/100\n",
      "125/125 [==============================] - 5s 43ms/step - loss: 1.1674 - accuracy: 0.4876 - val_loss: 2.2462 - val_accuracy: 0.4096\n",
      "Epoch 39/100\n",
      "125/125 [==============================] - 5s 43ms/step - loss: 1.1081 - accuracy: 0.5127 - val_loss: 2.3789 - val_accuracy: 0.4136\n",
      "Epoch 40/100\n",
      "125/125 [==============================] - 5s 43ms/step - loss: 1.0908 - accuracy: 0.5184 - val_loss: 2.3579 - val_accuracy: 0.4304\n",
      "Epoch 41/100\n",
      "125/125 [==============================] - 5s 43ms/step - loss: 1.0519 - accuracy: 0.5394 - val_loss: 2.3122 - val_accuracy: 0.4461\n",
      "Epoch 42/100\n",
      "125/125 [==============================] - 5s 42ms/step - loss: 0.9987 - accuracy: 0.5643 - val_loss: 2.2420 - val_accuracy: 0.4549\n",
      "Epoch 43/100\n",
      "125/125 [==============================] - 5s 42ms/step - loss: 0.9300 - accuracy: 0.5915 - val_loss: 2.4173 - val_accuracy: 0.4941\n",
      "Epoch 44/100\n",
      "125/125 [==============================] - 5s 42ms/step - loss: 0.8922 - accuracy: 0.6136 - val_loss: 2.3951 - val_accuracy: 0.4701\n",
      "Epoch 45/100\n",
      "125/125 [==============================] - 5s 41ms/step - loss: 0.8842 - accuracy: 0.6213 - val_loss: 2.3713 - val_accuracy: 0.4776\n",
      "Epoch 46/100\n",
      "125/125 [==============================] - 5s 41ms/step - loss: 0.8511 - accuracy: 0.6395 - val_loss: 2.4520 - val_accuracy: 0.5149\n",
      "Epoch 47/100\n",
      "125/125 [==============================] - 5s 42ms/step - loss: 0.8178 - accuracy: 0.6501 - val_loss: 2.4327 - val_accuracy: 0.5334\n",
      "Epoch 48/100\n",
      "125/125 [==============================] - 5s 41ms/step - loss: 0.7770 - accuracy: 0.6736 - val_loss: 2.4936 - val_accuracy: 0.5309\n",
      "Epoch 49/100\n",
      "125/125 [==============================] - 5s 41ms/step - loss: 0.8385 - accuracy: 0.6534 - val_loss: 2.5059 - val_accuracy: 0.5541\n",
      "Epoch 50/100\n",
      "125/125 [==============================] - 5s 41ms/step - loss: 0.7248 - accuracy: 0.7103 - val_loss: 2.5157 - val_accuracy: 0.5646\n",
      "Epoch 51/100\n",
      "125/125 [==============================] - 5s 42ms/step - loss: 0.7095 - accuracy: 0.7144 - val_loss: 2.4535 - val_accuracy: 0.5719\n",
      "Epoch 52/100\n",
      "125/125 [==============================] - 5s 42ms/step - loss: 0.6396 - accuracy: 0.7451 - val_loss: 2.6421 - val_accuracy: 0.5826\n",
      "Epoch 53/100\n",
      "125/125 [==============================] - 5s 41ms/step - loss: 0.6065 - accuracy: 0.7573 - val_loss: 2.6079 - val_accuracy: 0.5929\n",
      "Epoch 54/100\n",
      "125/125 [==============================] - 5s 42ms/step - loss: 0.5816 - accuracy: 0.7782 - val_loss: 2.6408 - val_accuracy: 0.5799\n",
      "Epoch 55/100\n",
      "125/125 [==============================] - 5s 43ms/step - loss: 0.5788 - accuracy: 0.7823 - val_loss: 2.9916 - val_accuracy: 0.5696\n",
      "Epoch 56/100\n",
      "125/125 [==============================] - 5s 42ms/step - loss: 0.5644 - accuracy: 0.7866 - val_loss: 2.7888 - val_accuracy: 0.5994\n",
      "Epoch 57/100\n",
      "125/125 [==============================] - 5s 43ms/step - loss: 0.5353 - accuracy: 0.8005 - val_loss: 2.7335 - val_accuracy: 0.6139\n",
      "Epoch 58/100\n",
      "125/125 [==============================] - 5s 42ms/step - loss: 0.5070 - accuracy: 0.8115 - val_loss: 2.7746 - val_accuracy: 0.6042\n",
      "Epoch 59/100\n",
      "125/125 [==============================] - 5s 43ms/step - loss: 0.5123 - accuracy: 0.8106 - val_loss: 2.6897 - val_accuracy: 0.6222\n",
      "Epoch 60/100\n",
      "125/125 [==============================] - 6s 47ms/step - loss: 0.4906 - accuracy: 0.8162 - val_loss: 2.8506 - val_accuracy: 0.6152\n",
      "Epoch 61/100\n",
      "125/125 [==============================] - 6s 44ms/step - loss: 0.4661 - accuracy: 0.8272 - val_loss: 2.9228 - val_accuracy: 0.6269\n",
      "Epoch 62/100\n",
      "125/125 [==============================] - 5s 43ms/step - loss: 0.4820 - accuracy: 0.8277 - val_loss: 2.8642 - val_accuracy: 0.6149\n",
      "Epoch 63/100\n",
      "125/125 [==============================] - 5s 43ms/step - loss: 0.4458 - accuracy: 0.8358 - val_loss: 2.8762 - val_accuracy: 0.6329\n",
      "Epoch 64/100\n",
      "125/125 [==============================] - 5s 44ms/step - loss: 0.4333 - accuracy: 0.8425 - val_loss: 2.8954 - val_accuracy: 0.6307\n",
      "Epoch 65/100\n",
      "125/125 [==============================] - 5s 43ms/step - loss: 0.3903 - accuracy: 0.8561 - val_loss: 2.8111 - val_accuracy: 0.6447\n",
      "Epoch 66/100\n",
      "125/125 [==============================] - 5s 42ms/step - loss: 0.3859 - accuracy: 0.8545 - val_loss: 3.0969 - val_accuracy: 0.6397\n",
      "Epoch 67/100\n",
      "125/125 [==============================] - 5s 42ms/step - loss: 0.3668 - accuracy: 0.8624 - val_loss: 3.0392 - val_accuracy: 0.6397\n",
      "Epoch 68/100\n",
      "125/125 [==============================] - 5s 41ms/step - loss: 0.3441 - accuracy: 0.8724 - val_loss: 3.0823 - val_accuracy: 0.6394\n",
      "Epoch 69/100\n",
      "125/125 [==============================] - 5s 42ms/step - loss: 0.3498 - accuracy: 0.8669 - val_loss: 3.0679 - val_accuracy: 0.6544\n",
      "Epoch 70/100\n",
      "125/125 [==============================] - 5s 42ms/step - loss: 0.3460 - accuracy: 0.8708 - val_loss: 2.9991 - val_accuracy: 0.6407\n",
      "Epoch 71/100\n",
      "125/125 [==============================] - 5s 42ms/step - loss: 0.3493 - accuracy: 0.8695 - val_loss: 3.1294 - val_accuracy: 0.6604\n",
      "Epoch 72/100\n",
      "125/125 [==============================] - 5s 42ms/step - loss: 0.3386 - accuracy: 0.8754 - val_loss: 3.1893 - val_accuracy: 0.6522\n",
      "Epoch 73/100\n",
      "125/125 [==============================] - 5s 43ms/step - loss: 0.3172 - accuracy: 0.8779 - val_loss: 3.1169 - val_accuracy: 0.6584\n",
      "Epoch 74/100\n",
      "125/125 [==============================] - 5s 42ms/step - loss: 0.3068 - accuracy: 0.8840 - val_loss: 3.0996 - val_accuracy: 0.6639\n",
      "Epoch 75/100\n",
      "125/125 [==============================] - 5s 42ms/step - loss: 0.2954 - accuracy: 0.8882 - val_loss: 3.1154 - val_accuracy: 0.6609\n",
      "Epoch 76/100\n",
      "125/125 [==============================] - 5s 42ms/step - loss: 0.3024 - accuracy: 0.8851 - val_loss: 3.0186 - val_accuracy: 0.6667\n",
      "Epoch 77/100\n",
      "125/125 [==============================] - 5s 43ms/step - loss: 0.2987 - accuracy: 0.8822 - val_loss: 3.0336 - val_accuracy: 0.6589\n",
      "Epoch 78/100\n",
      "125/125 [==============================] - 5s 44ms/step - loss: 0.2931 - accuracy: 0.8875 - val_loss: 3.2643 - val_accuracy: 0.6619\n",
      "Epoch 79/100\n",
      "125/125 [==============================] - 5s 42ms/step - loss: 0.2800 - accuracy: 0.8897 - val_loss: 3.3503 - val_accuracy: 0.6704\n",
      "Epoch 80/100\n",
      "125/125 [==============================] - 5s 42ms/step - loss: 0.2741 - accuracy: 0.8892 - val_loss: 3.4406 - val_accuracy: 0.6574\n",
      "Epoch 81/100\n",
      "125/125 [==============================] - 5s 43ms/step - loss: 0.2843 - accuracy: 0.8904 - val_loss: 3.5819 - val_accuracy: 0.6679\n",
      "Epoch 82/100\n",
      "125/125 [==============================] - 5s 43ms/step - loss: 0.2832 - accuracy: 0.8885 - val_loss: 3.1464 - val_accuracy: 0.6679\n",
      "Epoch 83/100\n",
      "125/125 [==============================] - 5s 42ms/step - loss: 0.2817 - accuracy: 0.8884 - val_loss: 3.3809 - val_accuracy: 0.6639\n",
      "Epoch 84/100\n",
      "125/125 [==============================] - 5s 44ms/step - loss: 0.2559 - accuracy: 0.8939 - val_loss: 3.5209 - val_accuracy: 0.6657\n",
      "Epoch 85/100\n",
      "125/125 [==============================] - 5s 43ms/step - loss: 0.2541 - accuracy: 0.8964 - val_loss: 3.5819 - val_accuracy: 0.6747\n",
      "Epoch 86/100\n",
      "125/125 [==============================] - 5s 43ms/step - loss: 0.2461 - accuracy: 0.8987 - val_loss: 3.5397 - val_accuracy: 0.6647\n",
      "Epoch 87/100\n",
      "125/125 [==============================] - 5s 43ms/step - loss: 0.2585 - accuracy: 0.8946 - val_loss: 3.3666 - val_accuracy: 0.6574\n",
      "Epoch 88/100\n",
      "125/125 [==============================] - 5s 43ms/step - loss: 0.2771 - accuracy: 0.8914 - val_loss: 3.4769 - val_accuracy: 0.6602\n",
      "Epoch 89/100\n",
      "125/125 [==============================] - 5s 43ms/step - loss: 0.2433 - accuracy: 0.8987 - val_loss: 3.3678 - val_accuracy: 0.6782\n",
      "Epoch 90/100\n",
      "125/125 [==============================] - 5s 43ms/step - loss: 0.2261 - accuracy: 0.9050 - val_loss: 3.6330 - val_accuracy: 0.6779\n",
      "Epoch 91/100\n",
      "125/125 [==============================] - 5s 42ms/step - loss: 0.2254 - accuracy: 0.9057 - val_loss: 3.5138 - val_accuracy: 0.6812\n",
      "Epoch 92/100\n",
      "125/125 [==============================] - 5s 43ms/step - loss: 0.2211 - accuracy: 0.9112 - val_loss: 3.5321 - val_accuracy: 0.6869\n",
      "Epoch 93/100\n",
      "125/125 [==============================] - 5s 42ms/step - loss: 0.2242 - accuracy: 0.9131 - val_loss: 3.5620 - val_accuracy: 0.6954\n",
      "Epoch 94/100\n",
      "125/125 [==============================] - 5s 42ms/step - loss: 0.2088 - accuracy: 0.9196 - val_loss: 3.7354 - val_accuracy: 0.6897\n",
      "Epoch 95/100\n",
      "125/125 [==============================] - 5s 42ms/step - loss: 0.2264 - accuracy: 0.9224 - val_loss: 3.4866 - val_accuracy: 0.6887\n",
      "Epoch 96/100\n",
      "125/125 [==============================] - 5s 43ms/step - loss: 0.2078 - accuracy: 0.9301 - val_loss: 3.3705 - val_accuracy: 0.6919\n",
      "Epoch 97/100\n",
      "125/125 [==============================] - 5s 43ms/step - loss: 0.1893 - accuracy: 0.9370 - val_loss: 3.5900 - val_accuracy: 0.6914\n",
      "Epoch 98/100\n",
      "125/125 [==============================] - 5s 43ms/step - loss: 0.1818 - accuracy: 0.9384 - val_loss: 3.4988 - val_accuracy: 0.6972\n",
      "Epoch 99/100\n",
      "125/125 [==============================] - 5s 43ms/step - loss: 0.1722 - accuracy: 0.9461 - val_loss: 3.4083 - val_accuracy: 0.6957\n",
      "Epoch 100/100\n",
      "125/125 [==============================] - 5s 43ms/step - loss: 0.1601 - accuracy: 0.9484 - val_loss: 3.8037 - val_accuracy: 0.6987\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=10, min_delta=0.001, mode='max', verbose=1)\n",
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=100, \n",
    "                    batch_size=128,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Generate Text from Nietzsche's Writings\n",
    "\n",
    "In this example, you will generate text from Nietzsche's writings.\n",
    "\n",
    "At least 20 epochs are required before the generated text\n",
    "starts sounding coherent.\n",
    "\n",
    "It is recommended to run this script on GPU, as recurrent\n",
    "networks are quite computationally intensive.\n",
    "\n",
    "If you try this script on new data, make sure your corpus\n",
    "has at least ~100k characters. ~1M is better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/text-datasets/nietzsche.txt\n",
      "606208/600901 [==============================] - 1s 1us/step\n",
      "614400/600901 [==============================] - 1s 1us/step\n",
      "corpus length: 600901\n"
     ]
    }
   ],
   "source": [
    "path = keras.utils.get_file(\"nietzsche.txt\",\n",
    "        origin=\"https://s3.amazonaws.com/text-datasets/nietzsche.txt\")\n",
    "\n",
    "text = open(path).read().lower()\n",
    "print(\"corpus length:\", len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 59\n"
     ]
    }
   ],
   "source": [
    "chars = set(text)\n",
    "print('total chars:', len(chars))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb sequences: 200267\n"
     ]
    }
   ],
   "source": [
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "maxlen = 100\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print(\"nb sequences:\", len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization...\n"
     ]
    }
   ],
   "source": [
    "print(\"Vectorization...\")\n",
    "X = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.int8)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.int8)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        X[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 100, 59)]         0         \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (None, 100, 256)          243456    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 100, 256)          0         \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 256)               394752    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 59)                15163     \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 59)                0         \n",
      "=================================================================\n",
      "Total params: 653,371\n",
      "Trainable params: 653,371\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build the model: 2 stacked LSTM\n",
    "print(\"Build model...\")\n",
    "xi = keras.layers.Input((maxlen, len(chars)))\n",
    "x = keras.layers.GRU(256, return_sequences=True)(xi)\n",
    "x = keras.layers.Dropout(0.2)(x)\n",
    "x = keras.layers.GRU(256, return_sequences=False)(x)\n",
    "x = keras.layers.Dropout(0.2)(x)\n",
    "x = keras.layers.Dense(len(chars))(x)\n",
    "x = keras.layers.Activation(\"softmax\")(x)\n",
    "\n",
    "model = keras.models.Model(inputs=xi, outputs=x)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = keras.optimizers.Adam(0.003)\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(a, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    a = (np.log(a + 1e-8) / temperature).astype(np.float64)\n",
    "    a = np.exp(a) / np.sum(np.exp(a))\n",
    "    try:\n",
    "      sample_result = np.argmax(np.random.multinomial(1, a, 1))\n",
    "    except ValueError:\n",
    "      error = 1.0 - np.sum(a)\n",
    "      a[0] += error\n",
    "      sample_result = np.argmax(np.random.multinomial(1, a, 1))\n",
    "    return sample_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1\n",
      "Epoch 1/4\n",
      "196/196 [==============================] - 15s 73ms/step - loss: 2.3580\n",
      "Epoch 2/4\n",
      "196/196 [==============================] - 14s 74ms/step - loss: 1.8701\n",
      "Epoch 3/4\n",
      "196/196 [==============================] - 15s 74ms/step - loss: 1.6946\n",
      "Epoch 4/4\n",
      "196/196 [==============================] - 15s 75ms/step - loss: 1.5920\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: 'wish to give them pleasure (children\n",
      "their parents, pupils their teacher, and well disposed persons '\n",
      "wish to give them pleasure (children\n",
      "their parents, pupils their teacher, and well disposed persons and the subjection of the superficial that the superion of the superiors of the superficial in the supersing the consequences the subjection of the sense is the superficial the supers of the superfici\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: 'wish to give them pleasure (children\n",
      "their parents, pupils their teacher, and well disposed persons '\n",
      "wish to give them pleasure (children\n",
      "their parents, pupils their teacher, and well disposed persons and has and in experience of the sense of the the concianing to the contranyly that every the conscience the belief its spirit as the singless of the super-and love in the super on accurance of the fa\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: 'wish to give them pleasure (children\n",
      "their parents, pupils their teacher, and well disposed persons '\n",
      "wish to give them pleasure (children\n",
      "their parents, pupils their teacher, and well disposed persons only canable srist), being world bechude of adgarting to the drital haud? for thrier those german\n",
      "degreponary and to be asmourden is\n",
      "so jusking its reguld\n",
      "not that god, for the sepreity of point on th\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: 'wish to give them pleasure (children\n",
      "their parents, pupils their teacher, and well disposed persons '\n",
      "wish to give them pleasure (children\n",
      "their parents, pupils their teacher, and well disposed persons austic weranoned auratic\n",
      "usmot--\"detbecates could being wart that instinct shown ather dincelver,\n",
      "reedopnation, to had.\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2\n",
      "Epoch 1/4\n",
      "196/196 [==============================] - 15s 77ms/step - loss: 1.5245\n",
      "Epoch 2/4\n",
      "196/196 [==============================] - 14s 74ms/step - loss: 1.4740\n",
      "Epoch 3/4\n",
      "196/196 [==============================] - 15s 75ms/step - loss: 1.4359\n",
      "Epoch 4/4\n",
      "196/196 [==============================] - 15s 76ms/step - loss: 1.4032\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: 'the\n",
      "heaven of our life. there are few pains so grievous as to have seen,\n",
      "divined, or experienced how'\n",
      "the\n",
      "heaven of our life. there are few pains so grievous as to have seen,\n",
      "divined, or experienced how could and in the present that has the philosopher has been such a serious and schopenhauer say the present to the present that the philosophers which has the same distrust of the subtlety and the sam\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: 'the\n",
      "heaven of our life. there are few pains so grievous as to have seen,\n",
      "divined, or experienced how'\n",
      "the\n",
      "heaven of our life. there are few pains so grievous as to have seen,\n",
      "divined, or experienced how that which is all purion of the states of life is a not into the importance of the spirit which the philosophers and language which many has a states of the contradictory.\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: 'the\n",
      "heaven of our life. there are few pains so grievous as to have seen,\n",
      "divined, or experienced how'\n",
      "the\n",
      "heaven of our life. there are few pains so grievous as to have seen,\n",
      "divined, or experienced how to entine pride, sinicr intoful temmerious effect, they do another vature, which\n",
      "mankerd there are\n",
      "point and the conditions to a contration) of relaarding them nature or civilizity.\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: 'the\n",
      "heaven of our life. there are few pains so grievous as to have seen,\n",
      "divined, or experienced how'\n",
      "the\n",
      "heaven of our life. there are few pains so grievous as to have seen,\n",
      "divined, or experienced how louffice back becumin signitian.\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 3\n",
      "Epoch 1/4\n",
      "196/196 [==============================] - 15s 77ms/step - loss: 1.3787\n",
      "Epoch 2/4\n",
      "196/196 [==============================] - 15s 76ms/step - loss: 1.3526\n",
      "Epoch 3/4\n",
      "196/196 [==============================] - 15s 76ms/step - loss: 1.3349\n",
      "Epoch 4/4\n",
      "196/196 [==============================] - 15s 78ms/step - loss: 1.3173\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: 'll sorts in all ages,\n",
      "and even to philosophers, in the whole phenomenon of the saint, it\n",
      "is undoubte'\n",
      "ll sorts in all ages,\n",
      "and even to philosophers, in the whole phenomenon of the saint, it\n",
      "is undoubted to the states of the struggle who is all the greater sense of the states of the states and the states of the things as a problem of the individuals alleans of the states and the struggle against the\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: 'll sorts in all ages,\n",
      "and even to philosophers, in the whole phenomenon of the saint, it\n",
      "is undoubte'\n",
      "ll sorts in all ages,\n",
      "and even to philosophers, in the whole phenomenon of the saint, it\n",
      "is undoubted and the greated the same time as a person and man and the greater things that it is better of the most spiritualist, and are ential the struggle and of the solution, which has the toursof understand\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: 'll sorts in all ages,\n",
      "and even to philosophers, in the whole phenomenon of the saint, it\n",
      "is undoubte'\n",
      "ll sorts in all ages,\n",
      "and even to philosophers, in the whole phenomenon of the saint, it\n",
      "is undoubted by such\n",
      "men\n",
      "and honoured pabhis of all accernance, as\n",
      "their stupidity and attempt to kant it not becomes\n",
      "to have redicated had not subject: lead) altore, a wordd, appearen ous bepialing ourselves--t\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: 'll sorts in all ages,\n",
      "and even to philosophers, in the whole phenomenon of the saint, it\n",
      "is undoubte'\n",
      "ll sorts in all ages,\n",
      "and even to philosophers, in the whole phenomenon of the saint, it\n",
      "is undoubtedly too notoor\n",
      "berone, and\n",
      "thereby moment rids, that he are before what is the before emotions how dousened never simply as his spotished.\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 4\n",
      "Epoch 1/4\n",
      "196/196 [==============================] - 15s 77ms/step - loss: 1.3007\n",
      "Epoch 2/4\n",
      "196/196 [==============================] - 15s 76ms/step - loss: 1.2822\n",
      "Epoch 3/4\n",
      "196/196 [==============================] - 15s 79ms/step - loss: 1.2739\n",
      "Epoch 4/4\n",
      "196/196 [==============================] - 15s 76ms/step - loss: 1.2606\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: 'elief that there are\n",
      "like things (gleiche dinge): only the trained experience attained\n",
      "through the m'\n",
      "elief that there are\n",
      "like things (gleiche dinge): only the trained experience attained\n",
      "through the moral in the experiences and the results the conception of the english his own are the sense is a subject to the experiences of the english his own interrors and the subject of the english as the subje\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: 'elief that there are\n",
      "like things (gleiche dinge): only the trained experience attained\n",
      "through the m'\n",
      "elief that there are\n",
      "like things (gleiche dinge): only the trained experience attained\n",
      "through the most sinstance of his own imporities and the soluted interronse the understoods the precisely of the \"indusis of the\n",
      "expression \"standing\" of europe, the results and conception \"the origin) and subject\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: 'elief that there are\n",
      "like things (gleiche dinge): only the trained experience attained\n",
      "through the m'\n",
      "elief that there are\n",
      "like things (gleiche dinge): only the trained experience attained\n",
      "through the man of his century\n",
      "and according to men or exediause of justicy when the uref-cheessation has been terrsteope!--what every still to interchure in meass recoining themselves what into so find it were a \n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: 'elief that there are\n",
      "like things (gleiche dinge): only the trained experience attained\n",
      "through the m'\n",
      "elief that there are\n",
      "like things (gleiche dinge): only the trained experience attained\n",
      "through the meltogical immaticial at enomm\n",
      "has but late, under the heiving and extreously that\n",
      "tert but of the by!\n",
      "\n",
      "\n",
      "214 \" who berorby the\n",
      "belief of man.\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 5\n",
      "Epoch 1/4\n",
      "196/196 [==============================] - 15s 76ms/step - loss: 1.2503\n",
      "Epoch 2/4\n",
      "196/196 [==============================] - 15s 76ms/step - loss: 1.2390\n",
      "Epoch 3/4\n",
      "196/196 [==============================] - 15s 76ms/step - loss: 1.2303\n",
      "Epoch 4/4\n",
      "196/196 [==============================] - 15s 76ms/step - loss: 1.2211\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: 'labour of all philosophical workers, and all\n",
      "subjugators of the past--they grasp at the future with '\n",
      "labour of all philosophical workers, and all\n",
      "subjugators of the past--they grasp at the future with all the sense of the sense of the powerful and ancient greeks and interpreted with the soul and instinct of such a stronger and power of the same time and and problems which the same as the same as th\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: 'labour of all philosophical workers, and all\n",
      "subjugators of the past--they grasp at the future with '\n",
      "labour of all philosophical workers, and all\n",
      "subjugators of the past--they grasp at the future with the most reasons that one must not be counteratestaphysical whole delicate morality.\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: 'labour of all philosophical workers, and all\n",
      "subjugators of the past--they grasp at the future with '\n",
      "labour of all philosophical workers, and all\n",
      "subjugators of the past--they grasp at the future with a\n",
      "weakening of europe, and thrious virtue of men, and as a of the \"give\"--approsens to the man who easely, observed, it is a romanticism.\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: 'labour of all philosophical workers, and all\n",
      "subjugators of the past--they grasp at the future with '\n",
      "labour of all philosophical workers, and all\n",
      "subjugators of the past--they grasp at the future with the ears cosrops of heants, which doe volvifial and somethous\n",
      "and bognol and\n",
      "out delight\n",
      "incogention,\n",
      "in which\n",
      "endentionly; and things proof; emaminity.\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 6\n",
      "Epoch 1/4\n",
      "196/196 [==============================] - 15s 76ms/step - loss: 1.2092\n",
      "Epoch 2/4\n",
      "196/196 [==============================] - 15s 78ms/step - loss: 1.2040\n",
      "Epoch 3/4\n",
      "196/196 [==============================] - 16s 79ms/step - loss: 1.1959\n",
      "Epoch 4/4\n",
      "196/196 [==============================] - 15s 77ms/step - loss: 1.1896\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: 'xample, one\n",
      "has no conception (to say nothing of the thing itself!) in germany.\n",
      "the germans lack a c'\n",
      "xample, one\n",
      "has no conception (to say nothing of the thing itself!) in germany.\n",
      "the germans lack a condition of the conscience, that is to say, in the consideration of the conscience process as the fact that the conscience of the subject of the subjects and all the conscience profound schopenhauer's\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: 'xample, one\n",
      "has no conception (to say nothing of the thing itself!) in germany.\n",
      "the germans lack a c'\n",
      "xample, one\n",
      "has no conception (to say nothing of the thing itself!) in germany.\n",
      "the germans lack a cruelty and all the must skepticism what in recomple that which he will always strong infirm the belief in the continual german must be dissecting the consciously consequences of sociation there one ma\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: 'xample, one\n",
      "has no conception (to say nothing of the thing itself!) in germany.\n",
      "the germans lack a c'\n",
      "xample, one\n",
      "has no conception (to say nothing of the thing itself!) in germany.\n",
      "the germans lack a command which they nature distraction.\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: 'xample, one\n",
      "has no conception (to say nothing of the thing itself!) in germany.\n",
      "the germans lack a c'\n",
      "xample, one\n",
      "has no conception (to say nothing of the thing itself!) in germany.\n",
      "the germans lack a chound it require that the edsesticture right called this -xumdies: would be ong such cases the oncibol: ofhe\n",
      "dicty and\n",
      "patter to feeling: \"the c'arped botto?\"--and to\n",
      "suffer formerly,\n",
      "directions of wh\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 7\n",
      "Epoch 1/4\n",
      "196/196 [==============================] - 15s 74ms/step - loss: 1.1833\n",
      "Epoch 2/4\n",
      "196/196 [==============================] - 15s 79ms/step - loss: 1.1758\n",
      "Epoch 3/4\n",
      "196/196 [==============================] - 15s 76ms/step - loss: 1.1744\n",
      "Epoch 4/4\n",
      "196/196 [==============================] - 15s 76ms/step - loss: 1.1683\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: 're,\n",
      "which instinctively employs speech for silence and concealment, and is\n",
      "inexhaustible in evasion '\n",
      "re,\n",
      "which instinctively employs speech for silence and concealment, and is\n",
      "inexhaustible in evasion of the world of the world of the world of the world of the world of such a still means of the world of the world of the world of man that it is a sort of the world of the superson and has all the same\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: 're,\n",
      "which instinctively employs speech for silence and concealment, and is\n",
      "inexhaustible in evasion '\n",
      "re,\n",
      "which instinctively employs speech for silence and concealment, and is\n",
      "inexhaustible in evasion that the same as the loter course of constitution of the most precisely that he history of\n",
      "the more has all the men of the masterious will to power has reverence for the community.\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: 're,\n",
      "which instinctively employs speech for silence and concealment, and is\n",
      "inexhaustible in evasion '\n",
      "re,\n",
      "which instinctively employs speech for silence and concealment, and is\n",
      "inexhaustible in evasion that we have true in \"gnee beings, in which we healt, and any, however it be nevertyatidness of the histire.\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: 're,\n",
      "which instinctively employs speech for silence and concealment, and is\n",
      "inexhaustible in evasion '\n",
      "re,\n",
      "which instinctively employs speech for silence and concealment, and is\n",
      "inexhaustible in evasion is ecourable, even\" and been schulan, obligeality, there if it maturate other sentiment.\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 8\n",
      "Epoch 1/4\n",
      "196/196 [==============================] - 15s 75ms/step - loss: 1.1590\n",
      "Epoch 2/4\n",
      "196/196 [==============================] - 15s 77ms/step - loss: 1.1571\n",
      "Epoch 3/4\n",
      "196/196 [==============================] - 15s 79ms/step - loss: 1.1496\n",
      "Epoch 4/4\n",
      "196/196 [==============================] - 15s 77ms/step - loss: 1.1511\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: 'e great\n",
      "laborious centres of trade and commerce; also the majority of laborious\n",
      "scholars, and the en'\n",
      "e great\n",
      "laborious centres of trade and commerce; also the majority of laborious\n",
      "scholars, and the entire species of morality, in the former age was the promited of the struggle which has been such a stronger and problem of the promited and intellectual and reason and strength, his own problem of the\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: 'e great\n",
      "laborious centres of trade and commerce; also the majority of laborious\n",
      "scholars, and the en'\n",
      "e great\n",
      "laborious centres of trade and commerce; also the majority of laborious\n",
      "scholars, and the entire spirit of ethics, and the spect of the latter stronger and problem is the belief in a virtue of a certain all things.\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: 'e great\n",
      "laborious centres of trade and commerce; also the majority of laborious\n",
      "scholars, and the en'\n",
      "e great\n",
      "laborious centres of trade and commerce; also the majority of laborious\n",
      "scholars, and the endly appearance of the cosms and the other\n",
      "will-rule and stronger maals\n",
      "for reger his progress, powerful; but there is no dinge them, as music ourse the while purs so necersativeling in man that he is \n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: 'e great\n",
      "laborious centres of trade and commerce; also the majority of laborious\n",
      "scholars, and the en'\n",
      "e great\n",
      "laborious centres of trade and commerce; also the majority of laborious\n",
      "scholars, and the entitues of his \"trus.\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 9\n",
      "Epoch 1/4\n",
      "196/196 [==============================] - 15s 76ms/step - loss: 1.1428\n",
      "Epoch 2/4\n",
      "196/196 [==============================] - 15s 76ms/step - loss: 1.1408\n",
      "Epoch 3/4\n",
      "196/196 [==============================] - 15s 76ms/step - loss: 1.1334\n",
      "Epoch 4/4\n",
      "196/196 [==============================] - 15s 76ms/step - loss: 1.1317\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: ' which is the\n",
      "mutual protection and safety from threatening misfortunes, and the\n",
      "welfare of each ind'\n",
      " which is the\n",
      "mutual protection and safety from threatening misfortunes, and the\n",
      "welfare of each individual in the strength of the subject of christianity and extent of the contrast his powerful, the most desires of the subject of schopenhauer's courage the most delights of the subject of strength o\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: ' which is the\n",
      "mutual protection and safety from threatening misfortunes, and the\n",
      "welfare of each ind'\n",
      " which is the\n",
      "mutual protection and safety from threatening misfortunes, and the\n",
      "welfare of each individual surpression had been some believe and into the latter for a long taste the worth of the greater pain of a long the soul of feelings, the most readent, and as the states of morals; there is a s\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: ' which is the\n",
      "mutual protection and safety from threatening misfortunes, and the\n",
      "welfare of each ind'\n",
      " which is the\n",
      "mutual protection and safety from threatening misfortunes, and the\n",
      "welfare of each individual comprehender life, is most interpretation\n",
      "of the present dave ofes, these manifestation (fenlimical sleadune theires\" is conceited he has always surden end must be\n",
      "contented to this will to\n",
      "th\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: ' which is the\n",
      "mutual protection and safety from threatening misfortunes, and the\n",
      "welfare of each ind'\n",
      " which is the\n",
      "mutual protection and safety from threatening misfortunes, and the\n",
      "welfare of each individual.\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 10\n",
      "Epoch 1/4\n",
      "196/196 [==============================] - 15s 75ms/step - loss: 1.1304\n",
      "Epoch 2/4\n",
      "196/196 [==============================] - 15s 76ms/step - loss: 1.1315\n",
      "Epoch 3/4\n",
      "196/196 [==============================] - 15s 76ms/step - loss: 1.1257\n",
      "Epoch 4/4\n",
      "196/196 [==============================] - 15s 76ms/step - loss: 1.1220\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: 'riod applied\n",
      "to actions; it is a gross mistake, therefore, when historians of morals\n",
      "start with ques'\n",
      "riod applied\n",
      "to actions; it is a gross mistake, therefore, when historians of morals\n",
      "start with question and the results has a thoused the interpreted to the higher and profoundly can be a man that the present that the same time, that is to say, the more for its of the powerful man of self deception\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: 'riod applied\n",
      "to actions; it is a gross mistake, therefore, when historians of morals\n",
      "start with ques'\n",
      "riod applied\n",
      "to actions; it is a gross mistake, therefore, when historians of morals\n",
      "start with question, and there is regarded and with a\n",
      "manifested by the philosopher needs of the perpetual conscience which is always individual and instinct of states and the same as the soul and universal know how\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: 'riod applied\n",
      "to actions; it is a gross mistake, therefore, when historians of morals\n",
      "start with ques'\n",
      "riod applied\n",
      "to actions; it is a gross mistake, therefore, when historians of morals\n",
      "start with question be nature, the most were point of regular placed in its doys over himself things of women: it is themselves than that the furare class and dedication; the gradations for\n",
      "suffering, consists in ba\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: 'riod applied\n",
      "to actions; it is a gross mistake, therefore, when historians of morals\n",
      "start with ques'\n",
      "riod applied\n",
      "to actions; it is a gross mistake, therefore, when historians of morals\n",
      "start with quese the responsible effect of\n",
      "persomative afford as to\n",
      "creatles.\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 11\n",
      "Epoch 1/4\n",
      "196/196 [==============================] - 14s 73ms/step - loss: 1.1211\n",
      "Epoch 2/4\n",
      "196/196 [==============================] - 14s 74ms/step - loss: 1.1184\n",
      "Epoch 3/4\n",
      "196/196 [==============================] - 14s 74ms/step - loss: 1.1101\n",
      "Epoch 4/4\n",
      "196/196 [==============================] - 14s 74ms/step - loss: 1.1106\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: 'ns, eras, and past ages, and were by no means eager\n",
      "to know about these matters, that they did not e'\n",
      "ns, eras, and past ages, and were by no means eager\n",
      "to know about these matters, that they did not experience in the same as the same as the same as the same as the same as the same thing in the same time or the strange have not the same thing that it is the same as the strange of this interpreted t\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: 'ns, eras, and past ages, and were by no means eager\n",
      "to know about these matters, that they did not e'\n",
      "ns, eras, and past ages, and were by no means eager\n",
      "to know about these matters, that they did not even of power a sort of self presentive sacrifice of the ascience of this is emotions of the state of the spell of this problem of the same as it is the same thing that is the same thing is a philosoph\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: 'ns, eras, and past ages, and were by no means eager\n",
      "to know about these matters, that they did not e'\n",
      "ns, eras, and past ages, and were by no means eager\n",
      "to know about these matters, that they did not exercises a sociep religious well with the great all form of the\n",
      "problem of morals in philarth,\n",
      "upon the purpose in\n",
      "the\n",
      "spectal conception\n",
      "real distrust of his own perhaps for\n",
      "the process of europe, wh\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: 'ns, eras, and past ages, and were by no means eager\n",
      "to know about these matters, that they did not e'\n",
      "ns, eras, and past ages, and were by no means eager\n",
      "to know about these matters, that they did not eful with this.\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 12\n",
      "Epoch 1/4\n",
      "196/196 [==============================] - 14s 73ms/step - loss: 1.1161\n",
      "Epoch 2/4\n",
      "196/196 [==============================] - 15s 75ms/step - loss: 1.1138\n",
      "Epoch 3/4\n",
      "196/196 [==============================] - 15s 75ms/step - loss: 1.1174\n",
      "Epoch 4/4\n",
      "196/196 [==============================] - 15s 75ms/step - loss: 1.1085\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: 't. modern men, with their obtuseness\n",
      "as regards all christian nomenclature, have no longer the sense'\n",
      "t. modern men, with their obtuseness\n",
      "as regards all christian nomenclature, have no longer the sense of the same kind of the sensations of the same time and consequently the soul of the same kind of states of an art that the consciousness of all the sensations of the same time and consequently the s\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: 't. modern men, with their obtuseness\n",
      "as regards all christian nomenclature, have no longer the sense'\n",
      "t. modern men, with their obtuseness\n",
      "as regards all christian nomenclature, have no longer the sense of the most possible for the contemplation of errors of character passes it seems to himself against such passion is not to fash, they are all these\n",
      "conception of \"beanted\" and the deepest in the mos\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: 't. modern men, with their obtuseness\n",
      "as regards all christian nomenclature, have no longer the sense'\n",
      "t. modern men, with their obtuseness\n",
      "as regards all christian nomenclature, have no longer the sense of the\n",
      "must had\n",
      "anotre,\n",
      "and he of the spoin as though himself.\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: 't. modern men, with their obtuseness\n",
      "as regards all christian nomenclature, have no longer the sense'\n",
      "t. modern men, with their obtuseness\n",
      "as regards all christian nomenclature, have no longer the sense, perhaps to the oldest pass of us is, stringtent formmoricated thought us\n",
      "be hopo? thick, ind period of their power, come.\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 13\n",
      "Epoch 1/4\n",
      "196/196 [==============================] - 15s 75ms/step - loss: 1.1090\n",
      "Epoch 2/4\n",
      "196/196 [==============================] - 15s 75ms/step - loss: 1.1106\n",
      "Epoch 3/4\n",
      "196/196 [==============================] - 15s 75ms/step - loss: 1.1100\n",
      "Epoch 4/4\n",
      "196/196 [==============================] - 15s 75ms/step - loss: 1.1161\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: ' which are very firmly implanted in the general\n",
      "course of conduct: indeed he discovers in himself a '\n",
      " which are very firmly implanted in the general\n",
      "course of conduct: indeed he discovers in himself a hard and spiritual personal intellectual superior to which are all the subject of schopenhauer's philosophy, as a philosophers of all the same thing that which is called and even is a present does not\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: ' which are very firmly implanted in the general\n",
      "course of conduct: indeed he discovers in himself a '\n",
      " which are very firmly implanted in the general\n",
      "course of conduct: indeed he discovers in himself a says said to done! it were all the most potent something of the philosophers of\n",
      "man and there is alone to understand that is to say, but a contrary of every power, who has not the fart who has concern\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: ' which are very firmly implanted in the general\n",
      "course of conduct: indeed he discovers in himself a '\n",
      " which are very firmly implanted in the general\n",
      "course of conduct: indeed he discovers in himself a morning time to whom their ancient\n",
      "great,\n",
      "as the favilies as in\n",
      "being and\n",
      "instincts in maturaction and creations is more amone the delicate, sought, it is regordism is, which he gersal prose well do p\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: ' which are very firmly implanted in the general\n",
      "course of conduct: indeed he discovers in himself a '\n",
      " which are very firmly implanted in the general\n",
      "course of conduct: indeed he discovers in himself a believe, but\n",
      "it is contrady to\n",
      "the palled soud to be\n",
      "completoley (the \"the rality of pain, love, to\n",
      "say, which is the conquert, lover to thives among those well sbid un possession,\n",
      "deniesces of subjec\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 14\n",
      "Epoch 1/4\n",
      "196/196 [==============================] - 14s 73ms/step - loss: 1.1165\n",
      "Epoch 2/4\n",
      "196/196 [==============================] - 14s 72ms/step - loss: 1.1252\n",
      "Epoch 3/4\n",
      "196/196 [==============================] - 14s 73ms/step - loss: 1.1190\n",
      "Epoch 4/4\n",
      "196/196 [==============================] - 14s 72ms/step - loss: 1.1208\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: 'eatest and\n",
      "richest, and putting the shreds into the form of questions from the\n",
      "standpoint of its own'\n",
      "eatest and\n",
      "richest, and putting the shreds into the form of questions from the\n",
      "standpoint of its own personal and improbabity they are also a man who has been something of the more that the contemption of the enditical and sacrificed for the same kind of religious and as a philosophers of the sense \n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: 'eatest and\n",
      "richest, and putting the shreds into the form of questions from the\n",
      "standpoint of its own'\n",
      "eatest and\n",
      "richest, and putting the shreds into the form of questions from the\n",
      "standpoint of its own and to a find which is complete poor to a stigle of mankind as his towards the philosophy of the importance of the remain suffect of the remain it make over of being the most ares out of the result o\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: 'eatest and\n",
      "richest, and putting the shreds into the form of questions from the\n",
      "standpoint of its own'\n",
      "eatest and\n",
      "richest, and putting the shreds into the form of questions from the\n",
      "standpoint of its own whose larguable and extinction of the remorness and in a lover in europe only insprending morality.\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: 'eatest and\n",
      "richest, and putting the shreds into the form of questions from the\n",
      "standpoint of its own'\n",
      "eatest and\n",
      "richest, and putting the shreds into the form of questions from the\n",
      "standpoint of its own,\n",
      "still more endurable, eepetition.\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 15\n",
      "Epoch 1/4\n",
      "196/196 [==============================] - 15s 74ms/step - loss: 1.1292\n",
      "Epoch 2/4\n",
      "196/196 [==============================] - 14s 73ms/step - loss: 1.1413\n",
      "Epoch 3/4\n",
      "196/196 [==============================] - 15s 74ms/step - loss: 1.1300\n",
      "Epoch 4/4\n",
      "196/196 [==============================] - 15s 74ms/step - loss: 1.1332\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: 'g but the tyrannous, even in morals,\n",
      "he loves as he hates, without nuance, to the very depths, to th'\n",
      "g but the tyrannous, even in morals,\n",
      "he loves as he hates, without nuance, to the very depths, to the more than a man of the spirit there is no doubt that the spectation of the moral prejudice and schence of delight, and the subject of self-protection and all the superstitions and emplies in the sam\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: 'g but the tyrannous, even in morals,\n",
      "he loves as he hates, without nuance, to the very depths, to th'\n",
      "g but the tyrannous, even in morals,\n",
      "he loves as he hates, without nuance, to the very depths, to the future, of the forces and and present stands unived and derivity as he is a surply of the moral precisely are reason, and honest to all this is greated the domain of human not believe, in the art of\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: 'g but the tyrannous, even in morals,\n",
      "he loves as he hates, without nuance, to the very depths, to th'\n",
      "g but the tyrannous, even in morals,\n",
      "he loves as he hates, without nuance, to the very depths, to the belief in the result of tendency, to ever the filent keepe will part and reached virable despection, are after the leksic were seems as a religious knowledge of the nabreament: therewands in reality\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: 'g but the tyrannous, even in morals,\n",
      "he loves as he hates, without nuance, to the very depths, to th'\n",
      "g but the tyrannous, even in morals,\n",
      "he loves as he hates, without nuance, to the very depths, to the brain with their fatur, who exactly during looked\n",
      "in the ramid punish, or\n",
      "conditions as then nor--be performeted and or, to which preads--that\n",
      "men and the neared time, not the variety which was alwa\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 16\n",
      "Epoch 1/4\n",
      "196/196 [==============================] - 14s 73ms/step - loss: 1.1412\n",
      "Epoch 2/4\n",
      "196/196 [==============================] - 15s 75ms/step - loss: 1.1399\n",
      "Epoch 3/4\n",
      "196/196 [==============================] - 15s 78ms/step - loss: 1.1411\n",
      "Epoch 4/4\n",
      "196/196 [==============================] - 15s 79ms/step - loss: 1.1343\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: 'ed, it is a sort of logical violation and unnaturalness; but the\n",
      "extravagant pride of man has manage'\n",
      "ed, it is a sort of logical violation and unnaturalness; but the\n",
      "extravagant pride of man has manage of the world of mankind of self-prove and pains are and the superstitious and existence of the sense of the world, and the subject of the world and done--in chatical philosophers and as a philosopher\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: 'ed, it is a sort of logical violation and unnaturalness; but the\n",
      "extravagant pride of man has manage'\n",
      "ed, it is a sort of logical violation and unnaturalness; but the\n",
      "extravagant pride of man has manages men of my really and the philosopher with assertion--and honesty and reference the contemporary really be imposed in the continual predating shame that is to say that the so that it is a man should \n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: 'ed, it is a sort of logical violation and unnaturalness; but the\n",
      "extravagant pride of man has manage'\n",
      "ed, it is a sort of logical violation and unnaturalness; but the\n",
      "extravagant pride of man has manage: the first sintical donome of the tratitidisting.\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: 'ed, it is a sort of logical violation and unnaturalness; but the\n",
      "extravagant pride of man has manage'\n",
      "ed, it is a sort of logical violation and unnaturalness; but the\n",
      "extravagant pride of man has manages man\n",
      "out of his comprehensive;\n",
      "read clusion, among the philosopher, is thinking that ameation, devalos, which acquire the\n",
      "culture false pimpatethation, midleable act has behonce my which _\n",
      "the syrtho\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 17\n",
      "Epoch 1/4\n",
      "196/196 [==============================] - 14s 72ms/step - loss: 1.1375\n",
      "Epoch 2/4\n",
      "196/196 [==============================] - 14s 73ms/step - loss: 1.1345\n",
      "Epoch 3/4\n",
      "196/196 [==============================] - 14s 73ms/step - loss: 1.1512\n",
      "Epoch 4/4\n",
      "196/196 [==============================] - 14s 74ms/step - loss: 1.1772\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: 'e mysterious labour of their souls was to prepare the way\n",
      "for that new synthesis, and tentatively to'\n",
      "e mysterious labour of their souls was to prepare the way\n",
      "for that new synthesis, and tentatively to the other reverse the religious consider the contemption of the things (and no one the sense\" is the art of the most proves of the things, the formed to the moral interpretations of morality (and as \n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: 'e mysterious labour of their souls was to prepare the way\n",
      "for that new synthesis, and tentatively to'\n",
      "e mysterious labour of their souls was to prepare the way\n",
      "for that new synthesis, and tentatively to the morality of it that the shame and the soul ard every and all little constitutes the contemporarily bure to dispersed conscience in the most supposition of the things (and to the more philosophy\" \n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: 'e mysterious labour of their souls was to prepare the way\n",
      "for that new synthesis, and tentatively to'\n",
      "e mysterious labour of their souls was to prepare the way\n",
      "for that new synthesis, and tentatively to requited, in demicto,\n",
      "amvand be discoud, that he fact, praited, the late upical cwoses ids in the philosopher and pow\n",
      "serciously, gathen firnally, rightly, and the property\" and gives, and nature--se\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: 'e mysterious labour of their souls was to prepare the way\n",
      "for that new synthesis, and tentatively to'\n",
      "e mysterious labour of their souls was to prepare the way\n",
      "for that new synthesis, and tentatively to doey therr, and although the lempt i no open ove from morification,\n",
      "astifications (worth arturent,\n",
      "pheloming, precised, as ceacle as the love than the have elt deceptional development the\n",
      "rounds remo\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 18\n",
      "Epoch 1/4\n",
      "196/196 [==============================] - 15s 79ms/step - loss: 1.4745\n",
      "Epoch 2/4\n",
      "196/196 [==============================] - 15s 75ms/step - loss: 1.4697\n",
      "Epoch 3/4\n",
      "196/196 [==============================] - 15s 76ms/step - loss: 1.3980\n",
      "Epoch 4/4\n",
      "196/196 [==============================] - 15s 76ms/step - loss: 1.4275\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: 'ich nothing can be wiser than to take\n",
      "a stick and thrash the witness soundly: one thereby obscures h'\n",
      "ich nothing can be wiser than to take\n",
      "a stick and thrash the witness soundly: one thereby obscures have in the more and his strange that is to the same knowledge of the same to the more destronds of all the sense of the subject of the subject of the more and he langual be made the more destron indis\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: 'ich nothing can be wiser than to take\n",
      "a stick and thrash the witness soundly: one thereby obscures h'\n",
      "ich nothing can be wiser than to take\n",
      "a stick and thrash the witness soundly: one thereby obscures have the subject of the taste of all the subject of the advant go distroubl the subject of the super thing is conditional in the empording of the sense of a his own hand and hen it to make something wh\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: 'ich nothing can be wiser than to take\n",
      "a stick and thrash the witness soundly: one thereby obscures h'\n",
      "ich nothing can be wiser than to take\n",
      "a stick and thrash the witness soundly: one thereby obscures has but was son equblezess atrehto it, bring, in whes itself to the becomis of in general his this paef the belief in the ling as thought it befuldent even the partacuman believ of philosophical men is\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: 'ich nothing can be wiser than to take\n",
      "a stick and thrash the witness soundly: one thereby obscures h'\n",
      "ich nothing can be wiser than to take\n",
      "a stick and thrash the witness soundly: one thereby obscures have be is eedisone, was bring hist meas sciponyis \"ound inpituius\" is up they sadismechopled ogaist\n",
      "it neivel condiquitud ly\n",
      "has new plices owderstand and ho re pusion) (rother yom man ward what wiken\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 19\n",
      "Epoch 1/4\n",
      "196/196 [==============================] - 15s 77ms/step - loss: 1.5476\n",
      "Epoch 2/4\n",
      "196/196 [==============================] - 15s 75ms/step - loss: 1.5479\n",
      "Epoch 3/4\n",
      "196/196 [==============================] - 15s 76ms/step - loss: 2.6359\n",
      "Epoch 4/4\n",
      "196/196 [==============================] - 15s 76ms/step - loss: 2.5239\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: ' extent that the englishman unconsciously hankers for his week--and\n",
      "work-day again:--as a kind of cl'\n",
      " extent that the englishman unconsciously hankers for his week--and\n",
      "work-day again:--as a kind of cleve sed the s and s and the the cound and and and the the a de the sothe the and and ande the and the and out ande ine cand and en the we the ande the in the the the he ald and and the the ser the the\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: ' extent that the englishman unconsciously hankers for his week--and\n",
      "work-day again:--as a kind of cl'\n",
      " extent that the englishman unconsciously hankers for his week--and\n",
      "work-day again:--as a kind of clas duon the  and and andes and ous sout the ionar ou a and be the s ate  ind and the and and and and and an thet and ous worever of therpate rend the sas beet s de the or serned the is of the aange,\n",
      " \n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: ' extent that the englishman unconsciously hankers for his week--and\n",
      "work-day again:--as a kind of cl'\n",
      " extent that the englishman unconsciously hankers for his week--and\n",
      "work-day again:--as a kind of cleiwilwintameibfacsarentxeatd an\n",
      "tce eth.\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: ' extent that the englishman unconsciously hankers for his week--and\n",
      "work-day again:--as a kind of cl'\n",
      " extent that the englishman unconsciously hankers for his week--and\n",
      "work-day again:--as a kind of clais, ad wsevatrmareuandt asouina so a ptol the iels eardthonlmage  moan\"-w fuage,eatvant qa wadinen-and.\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 20\n",
      "Epoch 1/4\n",
      "196/196 [==============================] - 15s 78ms/step - loss: 2.5000\n",
      "Epoch 2/4\n",
      "196/196 [==============================] - 15s 76ms/step - loss: 2.4873\n",
      "Epoch 3/4\n",
      "196/196 [==============================] - 15s 78ms/step - loss: 2.4765\n",
      "Epoch 4/4\n",
      "196/196 [==============================] - 15s 76ms/step - loss: 2.4659\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: 'moral imperative of nature, which is certainly neither \"categorical,\"\n",
      "as old kant wished (consequent'\n",
      "moral imperative of nature, which is certainly neither \"categorical,\"\n",
      "as old kant wished (consequent and the the en the of por and and and and and of tha the woret and and the cous of and fous on wh of the ous and hald the the of the of on the on of the and and and in the s and southe wound the so a\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: 'moral imperative of nature, which is certainly neither \"categorical,\"\n",
      "as old kant wished (consequent'\n",
      "moral imperative of nature, which is certainly neither \"categorical,\"\n",
      "as old kant wished (consequent ing thithe proo to whe ous thes iou f and of wher the was is con on withich suing es the ionen of the oun moditith in of of the ivers the sor her whe dis ind whic chele is ation and mone which an he \n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: 'moral imperative of nature, which is certainly neither \"categorical,\"\n",
      "as old kant wished (consequent'\n",
      "moral imperative of nature, which is certainly neither \"categorical,\"\n",
      "as old kant wished (consequents andue ofc avero he hew an timsear ht cheor o rico k of\n",
      "indtohas give  ortraato iln letilh, whesis ale ld sicivorliok ors nd\" altoa mingriorrpas smigh thied, pr t on zocyectbeshses ovoun seacesh no e\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: 'moral imperative of nature, which is certainly neither \"categorical,\"\n",
      "as old kant wished (consequent'\n",
      "moral imperative of nature, which is certainly neither \"categorical,\"\n",
      "as old kant wished (consequentr'\":han ifof ot ghibithipn of\"lec s_ing\n",
      "redpse deas,\n",
      "of ghet lve venp os ced andand cre unernrced m nt s\n",
      "ppioleus\n",
      " enreld, ovamteroug, ind-on or s nion bghat owhlive -eald tarkpeuh.\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 21\n",
      "Epoch 1/4\n",
      "196/196 [==============================] - 15s 74ms/step - loss: 2.4566\n",
      "Epoch 2/4\n",
      "196/196 [==============================] - 15s 75ms/step - loss: 2.4476\n",
      "Epoch 3/4\n",
      "196/196 [==============================] - 15s 75ms/step - loss: 2.4360\n",
      "Epoch 4/4\n",
      "196/196 [==============================] - 15s 74ms/step - loss: 2.4256\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: 'e unwilling to renounce or to share\n",
      "our responsibilities; to count our prerogatives, and the exercis'\n",
      "e unwilling to renounce or to share\n",
      "our responsibilities; to count our prerogatives, and the exercis the the the the the the and an the pod whe sound the the the the the the the the the wing the the the of the the the hims the and and whe the of whathe whe the whe was the wing and whic the withe the\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: 'e unwilling to renounce or to share\n",
      "our responsibilities; to count our prerogatives, and the exercis'\n",
      "e unwilling to renounce or to share\n",
      "our responsibilities; to count our prerogatives, and the exercisee and ws and the of and pent whathion and in the prrithe the could in whathine so  wom ph the wor the pur the whe win ous is nomald tho ex the so thes the and ind sortitimangally whe and of lut ew an\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: 'e unwilling to renounce or to share\n",
      "our responsibilities; to count our prerogatives, and the exercis'\n",
      "e unwilling to renounce or to share\n",
      "our responsibilities; to count our prerogatives, and the exerciss mathn les thawhle wh the h chetethers, \"elexer,es\" ce rest the mosselseeed aling ss many,\" nivelthisen s ays-eron copfs fatnal exand or,berpree tiensss lo ofope sillythed is enthu ls ce\n",
      "frais mlto e\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: 'e unwilling to renounce or to share\n",
      "our responsibilities; to count our prerogatives, and the exercis'\n",
      "e unwilling to renounce or to share\n",
      "our responsibilities; to count our prerogatives, and the exercisatit th meralelw thoulcom tharimaeghevtly ge pes amly aand nam arvesle vep seo hu yo w  ceutratyess worusulf)\n",
      "\"\n",
      "umerps wwe kmwntbaknit,m whis oltaty.\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 22\n",
      "Epoch 1/4\n",
      "196/196 [==============================] - 14s 74ms/step - loss: 2.4252\n",
      "Epoch 2/4\n",
      "196/196 [==============================] - 15s 75ms/step - loss: 2.4148\n",
      "Epoch 3/4\n",
      "196/196 [==============================] - 15s 75ms/step - loss: 2.4033\n",
      "Epoch 4/4\n",
      "196/196 [==============================] - 14s 74ms/step - loss: 2.3950\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: ' lacking--and are gradually branded as immoral\n",
      "and given over to calumny. the contrary instincts and'\n",
      " lacking--and are gradually branded as immoral\n",
      "and given over to calumny. the contrary instincts and and the and and the sant of the the the santhe and and the gand of the and the for the s mone and and the more and and and the cons the more the can the   he the the the ex the the the the oo he the \n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: ' lacking--and are gradually branded as immoral\n",
      "and given over to calumny. the contrary instincts and'\n",
      " lacking--and are gradually branded as immoral\n",
      "and given over to calumny. the contrary instincts and an and the mong the suthing in of the s int one the the of the ould the\n",
      "peered the wing in are the to the the the the cound and of that exerd the therp as in man of the ous the mand an perand in the \n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: ' lacking--and are gradually branded as immoral\n",
      "and given over to calumny. the contrary instincts and'\n",
      " lacking--and are gradually branded as immoral\n",
      "and given over to calumny. the contrary instincts and, math th to iane f-nm\", whhe ghomoly wet, wgao sunt an ffayin, in ouf linyd-woinaly tra\n",
      "vor act hicm,erobthere couaye thet\n",
      "ion an stetise, whath isr is, cires the oriretat aratize oll was ane-s ghore\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: ' lacking--and are gradually branded as immoral\n",
      "and given over to calumny. the contrary instincts and'\n",
      " lacking--and are gradually branded as immoral\n",
      "and given over to calumny. the contrary instincts and co s\n",
      "risets.\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 23\n",
      "Epoch 1/4\n",
      "196/196 [==============================] - 14s 73ms/step - loss: 2.3930\n",
      "Epoch 2/4\n",
      "196/196 [==============================] - 14s 74ms/step - loss: 2.3769\n",
      "Epoch 3/4\n",
      "196/196 [==============================] - 15s 75ms/step - loss: 2.3661\n",
      "Epoch 4/4\n",
      "196/196 [==============================] - 15s 76ms/step - loss: 2.3555\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: 'y long for\n",
      "introspection, and is accustomed to severe discipline and even severe\n",
      "words. he will say:'\n",
      "y long for\n",
      "introspection, and is accustomed to severe discipline and even severe\n",
      "words. he will say: the contere the sous the the the sere of the of the for the and the ment of the of the whe the the of the exert of the of the fore the the the sof rore of the wormes and and the of the the the the so\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: 'y long for\n",
      "introspection, and is accustomed to severe discipline and even severe\n",
      "words. he will say:'\n",
      "y long for\n",
      "introspection, and is accustomed to severe discipline and even severe\n",
      "words. he will say: he woure pere fee of the the witheren th of the ensos the fore the wthe exe them of in whe wis the soro everits in the ext whe and boral of of the listhent in the ent of thing the sor the of whe worn\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: 'y long for\n",
      "introspection, and is accustomed to severe discipline and even severe\n",
      "words. he will say:'\n",
      "y long for\n",
      "introspection, and is accustomed to severe discipline and even severe\n",
      "words. he will say: ithe anttion wiln the enslany arity and\n",
      "em a whubte \" \n",
      "evt ne:proand hab as the and of his thantum looulverl of to her, thifgheree thee hindac  erpiofgrat ow po gre.\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: 'y long for\n",
      "introspection, and is accustomed to severe discipline and even severe\n",
      "words. he will say:'\n",
      "y long for\n",
      "introspection, and is accustomed to severe discipline and even severe\n",
      "words. he will say: wistyebesin of\n",
      "wition foblycm addted eno bha tyopume itbesen\n",
      "mtyiing\n",
      "abem becrmns ov\n",
      " and siorf if oomcimy is censalip the of tnowitsetf, ther go susimeryiqwe sadvex indenk\n",
      "averectie inbersting  otsu\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 24\n",
      "Epoch 1/4\n",
      "196/196 [==============================] - 14s 73ms/step - loss: 2.3424\n",
      "Epoch 2/4\n",
      "196/196 [==============================] - 14s 73ms/step - loss: 2.3307\n",
      "Epoch 3/4\n",
      "196/196 [==============================] - 15s 75ms/step - loss: 2.3271\n",
      "Epoch 4/4\n",
      "196/196 [==============================] - 15s 75ms/step - loss: 2.3222\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: 'as ill as the latter supposes. both have a\n",
      "totally false idea of each other. the iniquities of the m'\n",
      "as ill as the latter supposes. both have a\n",
      "totally false idea of each other. the iniquities of the mand and the and the and the the the mont the and and the pres the and and the forthe the the ared and and the for the press and the and the soment and the the san the fore the more the and the fort th\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: 'as ill as the latter supposes. both have a\n",
      "totally false idea of each other. the iniquities of the m'\n",
      "as ill as the latter supposes. both have a\n",
      "totally false idea of each other. the iniquities of the mal the of the and co  ferely the somestrof the whe whe to hing, ith and ous in the chacing the cords als and lose of the mere and heres to he woul and ithing wavise and the withe, in whe to alle to su\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: 'as ill as the latter supposes. both have a\n",
      "totally false idea of each other. the iniquities of the m'\n",
      "as ill as the latter supposes. both have a\n",
      "totally false idea of each other. the iniquities of the mand preerith his of the tre botn r tint ofeaseswan; he and every-of the dese of in the oue wise an a\n",
      "dievithe daprens, seligel-- fhe bofs uhto the ort everite, his dover picede) am povsicatevy ou teit\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: 'as ill as the latter supposes. both have a\n",
      "totally false idea of each other. the iniquities of the m'\n",
      "as ill as the latter supposes. both have a\n",
      "totally false idea of each other. the iniquities of the mencerums of thon\n",
      "hathe, ituabituce as\" bingf\n",
      "perapevone besenfs, and hie-s blings,\n",
      "whesticolaainay,h he thaw hed evaf menpeespatcaenwand dot prhamqwned.\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 25\n",
      "Epoch 1/4\n",
      "196/196 [==============================] - 15s 76ms/step - loss: 2.3032\n",
      "Epoch 2/4\n",
      "196/196 [==============================] - 15s 76ms/step - loss: 2.2983\n",
      "Epoch 3/4\n",
      "196/196 [==============================] - 15s 76ms/step - loss: 2.3026\n",
      "Epoch 4/4\n",
      "196/196 [==============================] - 15s 77ms/step - loss: 2.3046\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: 's probably the case with everyone, whether waking or\n",
      "sleeping. uncontrolled and entangled as it is, '\n",
      "s probably the case with everyone, whether waking or\n",
      "sleeping. uncontrolled and entangled as it is, and and the prest and prest of the wher have and and the of the more the preth the hat of the what all the wors the of the were and he where the sould and he and of hat and and and the which an and an\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: 's probably the case with everyone, whether waking or\n",
      "sleeping. uncontrolled and entangled as it is, '\n",
      "s probably the case with everyone, whether waking or\n",
      "sleeping. uncontrolled and entangled as it is, have the serther as and phat the and of the in sof hathe the serfily a der the instore pare it and cay hors of the beling of the forlizheren, of the highinger lusit the whe sanse bo the man the he all\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: 's probably the case with everyone, whether waking or\n",
      "sleeping. uncontrolled and entangled as it is, '\n",
      "s probably the case with everyone, whether waking or\n",
      "sleeping. uncontrolled and entangled as it is, panitewn,\n",
      "it wakibled the hactionseas the in\n",
      "soing the beituprhente en of nasimeteeve f inc\n",
      "\n",
      "noferthlly\n",
      "in ofse;, thear our mes wh thedgly mg borll\n",
      "ther actokler nake, tr\n",
      "and the rocau acselfan)\n",
      "as: i\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: 's probably the case with everyone, whether waking or\n",
      "sleeping. uncontrolled and entangled as it is, '\n",
      "s probably the case with everyone, whether waking or\n",
      "sleeping. uncontrolled and entangled as it is, ampret, of\n",
      "ag of' eafhe of soas to-wald phiwbutircartures an- honiscatfoubf cenpatrooind\n",
      "alfey\n",
      "takifth\n",
      "hence\n",
      "one ind des\n",
      "pilhister-inle.\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 26\n",
      "Epoch 1/4\n",
      "196/196 [==============================] - 16s 79ms/step - loss: 2.3048\n",
      "Epoch 2/4\n",
      "196/196 [==============================] - 15s 77ms/step - loss: 2.3175\n",
      "Epoch 3/4\n",
      "196/196 [==============================] - 15s 76ms/step - loss: 2.3060\n",
      "Epoch 4/4\n",
      "196/196 [==============================] - 15s 78ms/step - loss: 2.4020\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: 'ain sense even the\n",
      "self-mounting of morality--let that be the name for the long-secret\n",
      "labour which '\n",
      "ain sense even the\n",
      "self-mounting of morality--let that be the name for the long-secret\n",
      "labour which in the he the ser wis the pre the pres the sere fore of the sore fore the relithe an in the sent the sore the the sere and the mere sor the the on the son the the oner the and and the mere pere and th\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: 'ain sense even the\n",
      "self-mounting of morality--let that be the name for the long-secret\n",
      "labour which '\n",
      "ain sense even the\n",
      "self-mounting of morality--let that be the name for the long-secret\n",
      "labour which wher as in the she allest of the pre it ind prog of the ris the sone is ind ind tored the susereden the borit in hoghe ingere to the las the bellenof worthe thing aber the suming and of exant sualling\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: 'ain sense even the\n",
      "self-mounting of morality--let that be the name for the long-secret\n",
      "labour which '\n",
      "ain sense even the\n",
      "self-mounting of morality--let that be the name for the long-secret\n",
      "labour which invire exo sestiupl, a duce tord of therdilit--cerem cooppncocinl inrt exensuale ms whe exering for e\n",
      "be do) thas into, fhathisam (hers, des.\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: 'ain sense even the\n",
      "self-mounting of morality--let that be the name for the long-secret\n",
      "labour which '\n",
      "ain sense even the\n",
      "self-mounting of morality--let that be the name for the long-secret\n",
      "labour which oedts entncaseck,\n",
      "bejeaings of hs to\n",
      " at deng erce,,n chers, osen toyem , sors whipes neous atga icle sre-ask, albelvednore for  \n",
      "aders muesumyen,\n",
      "s.\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 27\n",
      "Epoch 1/4\n",
      "196/196 [==============================] - 15s 77ms/step - loss: 2.3486\n",
      "Epoch 2/4\n",
      "196/196 [==============================] - 15s 78ms/step - loss: 2.3105\n",
      "Epoch 3/4\n",
      "196/196 [==============================] - 15s 77ms/step - loss: 2.2786\n",
      "Epoch 4/4\n",
      "196/196 [==============================] - 15s 77ms/step - loss: 2.2669\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: ' que des folies,\n",
      "qui vous feront grand plaisir\"--the motherliest and wisest remark, by\n",
      "the way, that'\n",
      " que des folies,\n",
      "qui vous feront grand plaisir\"--the motherliest and wisest remark, by\n",
      "the way, that the and of the prest and and the sould the sered and sould and and and the somention the sered and and the sention of the seation and and the soust and of the sece of the sere and sous and the sonto \n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: ' que des folies,\n",
      "qui vous feront grand plaisir\"--the motherliest and wisest remark, by\n",
      "the way, that'\n",
      " que des folies,\n",
      "qui vous feront grand plaisir\"--the motherliest and wisest remark, by\n",
      "the way, that and as sofle in to he done on the condut it the endent of the bres and and as of the to the mest and the polloth or the bewhaterre such ould is of and ex the pere and comsing of to the\n",
      "pouth of me ma\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: ' que des folies,\n",
      "qui vous feront grand plaisir\"--the motherliest and wisest remark, by\n",
      "the way, that'\n",
      " que des folies,\n",
      "qui vous feront grand plaisir\"--the motherliest and wisest remark, by\n",
      "the way, that n my meething onw the fact incens of that his eves bedlensow is of bhars sainrer-the conband thau sust, to son te here, they.\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: ' que des folies,\n",
      "qui vous feront grand plaisir\"--the motherliest and wisest remark, by\n",
      "the way, that'\n",
      " que des folies,\n",
      "qui vous feront grand plaisir\"--the motherliest and wisest remark, by\n",
      "the way, thatslanof and fpung sang lr of chas of ton whe hatn ych-thingu.\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 28\n",
      "Epoch 1/4\n",
      "196/196 [==============================] - 15s 75ms/step - loss: 2.2705\n",
      "Epoch 2/4\n",
      "196/196 [==============================] - 14s 73ms/step - loss: 2.3320\n",
      "Epoch 3/4\n",
      "196/196 [==============================] - 15s 77ms/step - loss: 2.3099\n",
      "Epoch 4/4\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 2.2708\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: 'of learning brought\n",
      "with it, we may begin to bear still farther onward the banner of\n",
      "enlightenment--'\n",
      "of learning brought\n",
      "with it, we may begin to bear still farther onward the banner of\n",
      "enlightenment--of the such the such in and and the mome and whe whe whe he whe the some of the concenta the for and and the wich in the seres and concere of the whe what the such man the prest and the whe and the th\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: 'of learning brought\n",
      "with it, we may begin to bear still farther onward the banner of\n",
      "enlightenment--'\n",
      "of learning brought\n",
      "with it, we may begin to bear still farther onward the banner of\n",
      "enlightenment--exever the foris a d menece have could the sins of in the conce, a d deres fomusould the core in ever and and of se whe porelficalizes the mas bact man is and the sang date and the thare the all theas\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: 'of learning brought\n",
      "with it, we may begin to bear still farther onward the banner of\n",
      "enlightenment--'\n",
      "of learning brought\n",
      "with it, we may begin to bear still farther onward the banner of\n",
      "enlightenment--ive; sh-the sould heumce, thire of the.\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: 'of learning brought\n",
      "with it, we may begin to bear still farther onward the banner of\n",
      "enlightenment--'\n",
      "of learning brought\n",
      "with it, we may begin to bear still farther onward the banner of\n",
      "enlightenment--they tche tegsom felig-scufment bovout, wind, as' eof oof bomerin re that ense exorne.\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 29\n",
      "Epoch 1/4\n",
      "196/196 [==============================] - 15s 75ms/step - loss: 2.2413\n",
      "Epoch 2/4\n",
      "196/196 [==============================] - 16s 80ms/step - loss: 2.2311\n",
      "Epoch 3/4\n",
      " 75/196 [==========>...................] - ETA: 2:26 - loss: 2.2154"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "# train the model, output generated text after each iteration\n",
    "for iteration in range(1, 60):\n",
    "    print()\n",
    "    print(\"-\" * 50)\n",
    "    print(\"Iteration\", iteration)\n",
    "\n",
    "    model.fit(X, y, batch_size=1024, epochs=4)\n",
    "    model.save_weights(\"weights.hdf5\")\n",
    "\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "\n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print()\n",
    "        print(\"----- diversity:\", diversity)\n",
    "\n",
    "        generated = \"\"\n",
    "        sentence = text[start_index: start_index + maxlen]\n",
    "        generated += sentence\n",
    "        print(\"----- Generating with seed: '\" + sentence + \"'\")\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(200):\n",
    "            x = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            # predict next char\n",
    "            preds = model.predict(x, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            # full sentence being generated\n",
    "            generated += next_char\n",
    "\n",
    "            # shift sentence\n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "            \n",
    "            # let's consider only one sentence\n",
    "            if next_char == \".\":\n",
    "              break\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pick up one set of data samples from linux kernel source code (https://github.com/torvalds/linux)\n",
    "- Modify the model to be trained in the corpus\n",
    "- Present the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 128746\n"
     ]
    }
   ],
   "source": [
    "file_path = \"signal.c\"\n",
    "\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    text = file.read().lower()\n",
    "    \n",
    "print(\"corpus length:\", len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 70\n"
     ]
    }
   ],
   "source": [
    "chars = set(text)\n",
    "print('total chars:', len(chars))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb sequences: 42882\n"
     ]
    }
   ],
   "source": [
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "maxlen = 100\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print(\"nb sequences:\", len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization...\n"
     ]
    }
   ],
   "source": [
    "print(\"Vectorization...\")\n",
    "X = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.int8)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.int8)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        X[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Model: \"model_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_14 (InputLayer)        [(None, 100, 70)]         0         \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (None, 100, 256)          251904    \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 100, 256)          0         \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 256)               394752    \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 70)                17990     \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 70)                0         \n",
      "=================================================================\n",
      "Total params: 664,646\n",
      "Trainable params: 664,646\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build the model: 2 stacked LSTM\n",
    "print(\"Build model...\")\n",
    "xi = keras.layers.Input((maxlen, len(chars)))\n",
    "x = keras.layers.GRU(256, return_sequences=True)(xi)\n",
    "x = keras.layers.Dropout(0.2)(x)\n",
    "x = keras.layers.GRU(256, return_sequences=False)(x)\n",
    "x = keras.layers.Dropout(0.2)(x)\n",
    "x = keras.layers.Dense(len(chars))(x)\n",
    "x = keras.layers.Activation(\"softmax\")(x)\n",
    "\n",
    "model = keras.models.Model(inputs=xi, outputs=x)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = keras.optimizers.Adam(0.003)\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(a, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    a = (np.log(a + 1e-8) / temperature).astype(np.float64)\n",
    "    a = np.exp(a) / np.sum(np.exp(a))\n",
    "    try:\n",
    "      sample_result = np.argmax(np.random.multinomial(1, a, 1))\n",
    "    except ValueError:\n",
    "      error = 1.0 - np.sum(a)\n",
    "      a[0] += error\n",
    "      sample_result = np.argmax(np.random.multinomial(1, a, 1))\n",
    "    return sample_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1\n",
      "Epoch 1/4\n",
      "42/42 [==============================] - 7s 76ms/step - loss: 3.3370\n",
      "Epoch 2/4\n",
      "42/42 [==============================] - 3s 76ms/step - loss: 2.4660\n",
      "Epoch 3/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 2.1176\n",
      "Epoch 4/4\n",
      "42/42 [==============================] - 3s 76ms/step - loss: 1.8395\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: 'set(si_pid);\n",
      "\tcheck_offset(si_uid);\n",
      "\tcheck_offset(si_value);\n",
      "\n",
      "\t/* sigchld */\n",
      "\tcheck_offset(si_pid);\n",
      "'\n",
      "set(si_pid);\n",
      "\tcheck_offset(si_uid);\n",
      "\tcheck_offset(si_value);\n",
      "\n",
      "\t/* sigchld */\n",
      "\tcheck_offset(si_pid);\n",
      "\t\tif (!signal_sig_info(sig, &sig, &new, &uss);\n",
      "\t\tif (!signal();\n",
      "\t\tif (!info->si_signal();\n",
      "\t\tif (!signal_signal();\n",
      "\t\tif (!sig);\n",
      "\t\tif (!signal->signal->signal->signal->siglock);\n",
      "\t\t\t\tif (!signal_siginfo(\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: 'set(si_pid);\n",
      "\tcheck_offset(si_uid);\n",
      "\tcheck_offset(si_value);\n",
      "\n",
      "\t/* sigchld */\n",
      "\tcheck_offset(si_pid);\n",
      "'\n",
      "set(si_pid);\n",
      "\tcheck_offset(si_uid);\n",
      "\tcheck_offset(si_value);\n",
      "\n",
      "\t/* sigchld */\n",
      "\tcheck_offset(si_pid);\n",
      "\t\tcase = sig, &skill))\n",
      "\t\treturn -enulled pinding, sig, sig, &thig;\n",
      "\tstruct kernt);\n",
      "\t\treturn -egreun signal(sig, &sigset))\n",
      "\t\treturn nel = flore != sig))\n",
      "\t\t\tcore == sig))\n",
      "\t\t\tif (!conding);\n",
      "\t\t/*\n",
      "\t * from\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: 'set(si_pid);\n",
      "\tcheck_offset(si_uid);\n",
      "\tcheck_offset(si_value);\n",
      "\n",
      "\t/* sigchld */\n",
      "\tcheck_offset(si_pid);\n",
      "'\n",
      "set(si_pid);\n",
      "\tcheck_offset(si_uid);\n",
      "\tcheck_offset(si_value);\n",
      "\n",
      "\t/* sigchld */\n",
      "\tcheck_offset(si_pid);\n",
      "}\n",
      "\n",
      "/*\n",
      "\t * to jobctu set 't rendileracer the preculecedsion't int ker.\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: 'set(si_pid);\n",
      "\tcheck_offset(si_uid);\n",
      "\tcheck_offset(si_value);\n",
      "\n",
      "\t/* sigchld */\n",
      "\tcheck_offset(si_pid);\n",
      "'\n",
      "set(si_pid);\n",
      "\tcheck_offset(si_uid);\n",
      "\tcheck_offset(si_value);\n",
      "\n",
      "\t/* sigchld */\n",
      "\tcheck_offset(si_pid);\n",
      "\tin fas- crel;\n",
      "\t(pid = fseg(c, sigt, = jaskq->cysk));\n",
      "\trcer;\n",
      "\t}\n",
      "entudl_clr_anc dsize, pid)= (isq->ptrum->srocul_k;\n",
      "}\n",
      "\t\tfause =*mer.\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2\n",
      "Epoch 1/4\n",
      "42/42 [==============================] - 3s 77ms/step - loss: 1.6230\n",
      "Epoch 2/4\n",
      "42/42 [==============================] - 3s 76ms/step - loss: 1.4523\n",
      "Epoch 3/4\n",
      "42/42 [==============================] - 3s 76ms/step - loss: 1.3234\n",
      "Epoch 4/4\n",
      "42/42 [==============================] - 3s 76ms/step - loss: 1.2163\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: 'returns:\n",
      " * %true if @mask is set, %false if made noop because @task was dying.\n",
      " */\n",
      "bool task_set_jo'\n",
      "returns:\n",
      " * %true if @mask is set, %false if made noop because @task was dying.\n",
      " */\n",
      "bool task_set_jobctl_pending(current) {\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t * compat_sigset_t *set, int signals to set to set_t */\n",
      "\t\t\t\tif (sigset_t *_set_task()))\n",
      "\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: 'returns:\n",
      " * %true if @mask is set, %false if made noop because @task was dying.\n",
      " */\n",
      "bool task_set_jo'\n",
      "returns:\n",
      " * %true if @mask is set, %false if made noop because @task was dying.\n",
      " */\n",
      "bool task_set_jobctl_pid_notify(ptr, &signal sigset_t *_user *)))\n",
      "\t\t\t\t\tret = -earvar;\n",
      "\t\tto->si_addr = pending);\n",
      "\tvoid __user *urrent->sighand->siglock);\n",
      "\t\t\t\tsigaction config_compat_siginfo(&info);\n",
      "\t\t\tif (uss, utset);\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: 'returns:\n",
      " * %true if @mask is set, %false if made noop because @task was dying.\n",
      " */\n",
      "bool task_set_jo'\n",
      "returns:\n",
      " * %true if @mask is set, %false if made noop because @task was dying.\n",
      " */\n",
      "bool task_set_jobctl_pending_erent = current->signal | signr;\n",
      "\n",
      "\t/* 0 infor thas matk ace stop dobled be recauge forled        thas haid.\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: 'returns:\n",
      " * %true if @mask is set, %false if made noop because @task was dying.\n",
      " */\n",
      "bool task_set_jo'\n",
      "returns:\n",
      " * %true if @mask is set, %false if made noop because @task was dying.\n",
      " */\n",
      "bool task_set_jobctl_pending(&arth, ist)\n",
      "\t\tret |  jobctl signals = ingoret, int;\n",
      "\n",
      "\tcksatind porinitidyctrue;\n",
      "\t\tpaclited(&new_saghas_k,+, |cld_to *set) {\n",
      "\t\tclsst_comptae(inet(&news);\n",
      "\tinfo.\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 3\n",
      "Epoch 1/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 1.1206\n",
      "Epoch 2/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 1.0439\n",
      "Epoch 3/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 0.9719\n",
      "Epoch 4/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 0.9071\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: 'ue_prealloc) &&\n",
      "\t\t\t(info->si_code == si_timer) &&\n",
      "\t\t\t(info->si_sys_private);\n",
      "\n",
      "\t\t__sigqueue_free(firs'\n",
      "ue_prealloc) &&\n",
      "\t\t\t(info->si_code == si_timer) &&\n",
      "\t\t\t(info->si_sys_private);\n",
      "\n",
      "\t\t__sigqueue_free(first_ptr(t, jobctl_stop_count int sig, struct task_struct *t)\n",
      "{\n",
      "\tint error = -esrch;\n",
      "\n",
      "\tif (unlikely(!(t) {\n",
      "\t\t\tsigandsets(&tsk->sighand->siglock);\n",
      "\n",
      "\t/*\n",
      "\t * signals must be called and the signal in the sig\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: 'ue_prealloc) &&\n",
      "\t\t\t(info->si_code == si_timer) &&\n",
      "\t\t\t(info->si_sys_private);\n",
      "\n",
      "\t\t__sigqueue_free(firs'\n",
      "ue_prealloc) &&\n",
      "\t\t\t(info->si_code == si_timer) &&\n",
      "\t\t\t(info->si_sys_private);\n",
      "\n",
      "\t\t__sigqueue_free(firse, &info);\n",
      "\tinfo.\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: 'ue_prealloc) &&\n",
      "\t\t\t(info->si_code == si_timer) &&\n",
      "\t\t\t(info->si_sys_private);\n",
      "\n",
      "\t\t__sigqueue_free(firs'\n",
      "ue_prealloc) &&\n",
      "\t\t\t(info->si_code == si_timer) &&\n",
      "\t\t\t(info->si_sys_private);\n",
      "\n",
      "\t\t__sigqueue_free(firs_sk_specp, tsk->parent, &flags) {\n",
      "\t\tready  = syscall_define4(&ng;\n",
      "\t\tuss.\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: 'ue_prealloc) &&\n",
      "\t\t\t(info->si_code == si_timer) &&\n",
      "\t\t\t(info->si_sys_private);\n",
      "\n",
      "\t\t__sigqueue_free(firs'\n",
      "ue_prealloc) &&\n",
      "\t\t\t(info->si_code == si_timer) &&\n",
      "\t\t\t(info->si_sys_private);\n",
      "\n",
      "\t\t__sigqueue_free(firs_size_m *w)) {\n",
      "\t\t\tspin_unlock(};\n",
      "}\n",
      "\n",
      "stact_a *.\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 4\n",
      "Epoch 1/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 0.8519\n",
      "Epoch 2/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 0.8029\n",
      "Epoch 3/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 0.7510\n",
      "Epoch 4/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 0.7116\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: 'ng(&t->pending, &t->blocked) ||\n",
      "\t    pending(&t->signal->shared_pending, &t->blocked) ||\n",
      "\t    cgroup'\n",
      "ng(&t->pending, &t->blocked) ||\n",
      "\t    pending(&t->signal->shared_pending, &t->blocked) ||\n",
      "\t    cgroup_ener_exit_signals(&nsignal, sig))\n",
      "\t\t\t\tlock_trace_signal(sig, info, &info);\n",
      "\tinfo.\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: 'ng(&t->pending, &t->blocked) ||\n",
      "\t    pending(&t->signal->shared_pending, &t->blocked) ||\n",
      "\t    cgroup'\n",
      "ng(&t->pending, &t->blocked) ||\n",
      "\t    pending(&t->signal->shared_pending, &t->blocked) ||\n",
      "\t    cgroup_exit_signals(&signal)) {\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t! sig_kernel_once(&info);\n",
      "\tinfo.\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: 'ng(&t->pending, &t->blocked) ||\n",
      "\t    pending(&t->signal->shared_pending, &t->blocked) ||\n",
      "\t    cgroup'\n",
      "ng(&t->pending, &t->blocked) ||\n",
      "\t    pending(&t->signal->shared_pending, &t->blocked) ||\n",
      "\t    cgroup_unlock -|signo, signr, info, pid);\n",
      "}\n",
      "\n",
      "/*\n",
      " * sys_stop_anot be preetent ig thaszed signals\n",
      " *  @onse: the pid for infor oand shore is bits is no intoreap.\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: 'ng(&t->pending, &t->blocked) ||\n",
      "\t    pending(&t->signal->shared_pending, &t->blocked) ||\n",
      "\t    cgroup'\n",
      "ng(&t->pending, &t->blocked) ||\n",
      "\t    pending(&t->signal->shared_pending, &t->blocked) ||\n",
      "\t    cgroup_loce(sig, &info, p, pidt_perm));\n",
      "\n",
      "\t\tfor = 0;\n",
      "\n",
      "\t\t\t\t\tif (copy_frucuser(sig)))\n",
      "\t\t\tenror __user *task)\n",
      "\t\t\t\tgrturn kill_pending(&new_block)\n",
      "{\n",
      "\t\tblocked = do_compat_sigset(&&nst, euct task_sigpending())\n",
      "{\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 5\n",
      "Epoch 1/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 0.6772\n",
      "Epoch 2/4\n",
      "42/42 [==============================] - 3s 74ms/step - loss: 0.6347\n",
      "Epoch 3/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 0.6027\n",
      "Epoch 4/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 0.5710\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: ' in the completion of group stop.  the states\n",
      "\t * for the two don't interact with each other.  notif'\n",
      " in the completion of group stop.  the states\n",
      "\t * for the two don't interact with each other.  notify the signal and precause the signal we den'rec the sig? &o ptrace_sigpending -ecest restore_parane.\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: ' in the completion of group stop.  the states\n",
      "\t * for the two don't interact with each other.  notif'\n",
      " in the completion of group stop.  the states\n",
      "\t * for the two don't interact with each other.  notify the signal and pid notify - sig this is a release the signal be delevered - info it in this task is not blocked, notify the signal and ptrace_task_flags and be sent\n",
      " */\n",
      "\tif (!si_uid = from_kuid_mung\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: ' in the completion of group stop.  the states\n",
      "\t * for the two don't interact with each other.  notif'\n",
      " in the completion of group stop.  the states\n",
      "\t * for the two don't interact with each other.  notify\n",
      "\t *  \" signol\n",
      "\t * wake up always afreezer be sigprefmem_se do_tgid_ngwing signals and the list for be cokely on listed handling signals to be deliveeded, %true jobctl_stop_stopped for stop signal_ex\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: ' in the completion of group stop.  the states\n",
      "\t * for the two don't interact with each other.  notif'\n",
      " in the completion of group stop.  the states\n",
      "\t * for the two don't interact with each other.  notif sthe decauled.\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 6\n",
      "Epoch 1/4\n",
      "42/42 [==============================] - 3s 76ms/step - loss: 0.5404\n",
      "Epoch 2/4\n",
      "42/42 [==============================] - 3s 76ms/step - loss: 0.5192\n",
      "Epoch 3/4\n",
      "42/42 [==============================] - 3s 76ms/step - loss: 0.4970\n",
      "Epoch 4/4\n",
      "42/42 [==============================] - 3s 76ms/step - loss: 0.4781\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: 'op, so we must release it now.\n",
      "\t\t * to preserve proper semantics, we must do this before\n",
      "\t\t * any si'\n",
      "op, so we must release it now.\n",
      "\t\t * to preserve proper semantics, we must do this before\n",
      "\t\t * any signal is a sillable for gil's and be called to the code do_signal_stop_signal signal to be wern re thand signal is and after this signal %signals.\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: 'op, so we must release it now.\n",
      "\t\t * to preserve proper semantics, we must do this before\n",
      "\t\t * any si'\n",
      "op, so we must release it now.\n",
      "\t\t * to preserve proper semantics, we must do this before\n",
      "\t\t * any siginfo is returned to signal is and were rest and be wake up and be check to sig_kernel_only(t, signal, sizeof(struct task_struct *target, jobctl trap\n",
      "\t\treturn -einval;\n",
      "\n",
      "\tif (sig <= signal_stop_consume\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: 'op, so we must release it now.\n",
      "\t\t * to preserve proper semantics, we must do this before\n",
      "\t\t * any si'\n",
      "op, so we must release it now.\n",
      "\t\t * to preserve proper semantics, we must do this before\n",
      "\t\t * any signal the signal be are arring stop signals group stop_court because trapped.\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: 'op, so we must release it now.\n",
      "\t\t * to preserve proper semantics, we must do this before\n",
      "\t\t * any si'\n",
      "op, so we must release it now.\n",
      "\t\t * to preserve proper semantics, we must do this before\n",
      "\t\t * any signal is and any group stop to blocked set and\n",
      "\t * this is a called up and shored and ptracer the signal to user\n",
      "\t * act ase before that be ars\n",
      " * the astraces be fromsb tosb is alled the exit is only \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 7\n",
      "Epoch 1/4\n",
      "42/42 [==============================] - 3s 77ms/step - loss: 0.4560\n",
      "Epoch 2/4\n",
      "42/42 [==============================] - 3s 76ms/step - loss: 0.4391\n",
      "Epoch 3/4\n",
      "42/42 [==============================] - 3s 77ms/step - loss: 0.4247\n",
      "Epoch 4/4\n",
      "42/42 [==============================] - 3s 76ms/step - loss: 0.4071\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: '& sig == sigchld &&\n",
      "\t    (psig->action[sigchld-1].sa.sa_handler == sig_ign ||\n",
      "\t     (psig->action[si'\n",
      "& sig == sigchld &&\n",
      "\t    (psig->action[sigchld-1].sa.sa_handler == sig_ign ||\n",
      "\t     (psig->action[signr);\n",
      "\t\tptrace_sig_info(&info);\n",
      "}\n",
      "export_symbol_group(tsk->parent, signal_statestack_locked))\n",
      "\t\treturn task_pliptly(current->struct task_struct *t)\n",
      "{\n",
      "\tif (for_ad_ret(t, signr);\n",
      "\t\tptrace_sig_info(&info\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: '& sig == sigchld &&\n",
      "\t    (psig->action[sigchld-1].sa.sa_handler == sig_ign ||\n",
      "\t     (psig->action[si'\n",
      "& sig == sigchld &&\n",
      "\t    (psig->action[sigchld-1].sa.sa_handler == sig_ign ||\n",
      "\t     (psig->action[sigkill;\n",
      "\treturn ret;\n",
      "\n",
      "\tpare_task_ptrace_state(task_info, bed;\n",
      "\n",
      "\t/* afy or signal is actial or signals is bats in the group astrocl_signal_struct *signal is action is unlikely(task)\n",
      "{\n",
      "\tint err;\n",
      "\n",
      "\t/* not\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: '& sig == sigchld &&\n",
      "\t    (psig->action[sigchld-1].sa.sa_handler == sig_ign ||\n",
      "\t     (psig->action[si'\n",
      "& sig == sigchld &&\n",
      "\t    (psig->action[sigchld-1].sa.sa_handler == sig_ign ||\n",
      "\t     (psig->action[signr) ||\n",
      "\t\t    __pdefiee_trapno;\n",
      "\t\tbreak;\n",
      "\tcase sil_syg:\n",
      "\t\tret = false;\n",
      "\n",
      "\t/*\n",
      "\t * miest the  sen this signals are nun thises unders and to trecervend with __user *task)\n",
      "{\n",
      "\t/* nemestar can in group stop \n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: '& sig == sigchld &&\n",
      "\t    (psig->action[sigchld-1].sa.sa_handler == sig_ign ||\n",
      "\t     (psig->action[si'\n",
      "& sig == sigchld &&\n",
      "\t    (psig->action[sigchld-1].sa.sa_handler == sig_ign ||\n",
      "\t     (psig->action[sighrespererm->si_set,_uthen;\n",
      "\t\tif (siginfo_layout(from->si_istending);\n",
      "\t} else if (tsk->faral_irchave_hrap);\n",
      "\n",
      "\treturn kill_prrent_fiag(vnt;\n",
      "\t}\n",
      "\n",
      "\tif (info->si_signo = sigdonfo = &->action[signr)\n",
      "\t\t\tclea\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 8\n",
      "Epoch 1/4\n",
      "42/42 [==============================] - 3s 76ms/step - loss: 0.3985\n",
      "Epoch 2/4\n",
      "42/42 [==============================] - 3s 76ms/step - loss: 0.3834\n",
      "Epoch 3/4\n",
      "42/42 [==============================] - 3s 76ms/step - loss: 0.3770\n",
      "Epoch 4/4\n",
      "42/42 [==============================] - 3s 76ms/step - loss: 0.3617\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: 'signal; otherwise, %sigtrap.\n",
      " *\n",
      " * when !pt_seized, it's used only for group stop trap with stop sig'\n",
      "signal; otherwise, %sigtrap.\n",
      " *\n",
      " * when !pt_seized, it's used only for group stop trap with stop signal_returned by sigcont which siginfo_blocked, sigmask(sigstop));\n",
      "\tspin_unlock_irq(&current->sighand->siglock);\n",
      "\n",
      "\t\t/* only callers from dasa.\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: 'signal; otherwise, %sigtrap.\n",
      " *\n",
      " * when !pt_seized, it's used only for group stop trap with stop sig'\n",
      "signal; otherwise, %sigtrap.\n",
      " *\n",
      " * when !pt_seized, it's used only for group stop trap with stop signal_begs all of the signal be called with *\n",
      "\t\t * notifie and we ret cal be cred and preemption is not pidting signals werner to new be reperaulinated, we mask syscall.\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: 'signal; otherwise, %sigtrap.\n",
      " *\n",
      " * when !pt_seized, it's used only for group stop trap with stop sig'\n",
      "signal; otherwise, %sigtrap.\n",
      " *\n",
      " * when !pt_seized, it's used only for group stop trap with stop signal_begproclock\n",
      ".\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: 'signal; otherwise, %sigtrap.\n",
      " *\n",
      " * when !pt_seized, it's used only for group stop trap with stop sig'\n",
      "signal; otherwise, %sigtrap.\n",
      " *\n",
      " * when !pt_seized, it's used only for group stop trap with stop signal.\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 9\n",
      "Epoch 1/4\n",
      "42/42 [==============================] - 3s 76ms/step - loss: 0.3529\n",
      "Epoch 2/4\n",
      "42/42 [==============================] - 3s 77ms/step - loss: 0.3484\n",
      "Epoch 3/4\n",
      "42/42 [==============================] - 3s 76ms/step - loss: 0.3432\n",
      "Epoch 4/4\n",
      "42/42 [==============================] - 3s 76ms/step - loss: 0.3339\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: 'ne void print_dropped_signal(int sig)\n",
      "{\n",
      "\tstatic define_ratelimit_state(ratelimit_state, 5 * hz, 10);'\n",
      "ne void print_dropped_signal(int sig)\n",
      "{\n",
      "\tstatic define_ratelimit_state(ratelimit_state, 5 * hz, 10);\n",
      "\t\treturn kill_preer(t, signr)))\n",
      "\t\tcger_toret(sigpending, compat_stack_t __user *)))\n",
      "\t\treturn -efault;\n",
      "\t\tunsigned info->si_code = si_user;\n",
      "\t\treturn -efault;\n",
      "\t\tunsigned info->si_code = si_user;\n",
      "\t\tret |\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: 'ne void print_dropped_signal(int sig)\n",
      "{\n",
      "\tstatic define_ratelimit_state(ratelimit_state, 5 * hz, 10);'\n",
      "ne void print_dropped_signal(int sig)\n",
      "{\n",
      "\tstatic define_ratelimit_state(ratelimit_state, 5 * hz, 10);\n",
      "\t\tpending->list_errno;\n",
      "\tinfo.\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: 'ne void print_dropped_signal(int sig)\n",
      "{\n",
      "\tstatic define_ratelimit_state(ratelimit_state, 5 * hz, 10);'\n",
      "ne void print_dropped_signal(int sig)\n",
      "{\n",
      "\tstatic define_ratelimit_state(ratelimit_state, 5 * hz, 10);\n",
      "\t\tskinclocudd(t, jobctl_stop_pending);\n",
      "\t\tfaust sig = info->si_signo;\n",
      "\tsigset_t und;\n",
      "\tstruct signal_state(task, sigpending));\n",
      "\n",
      "/*\n",
      " * tese in the starcted which is returned hore is parent type is param\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: 'ne void print_dropped_signal(int sig)\n",
      "{\n",
      "\tstatic define_ratelimit_state(ratelimit_state, 5 * hz, 10);'\n",
      "ne void print_dropped_signal(int sig)\n",
      "{\n",
      "\tstatic define_ratelimit_state(ratelimit_state, 5 * hz, 10);\n",
      "\terror = -esroco;\n",
      "\tvoid kabue;\n",
      "\t\t/*\n",
      "\t\t\t * notifo shallcal with\n",
      "\t * does the call\n",
      "\t * the ged if ything\n",
      "\t\t * saze to \"ksignal came signal.\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 10\n",
      "Epoch 1/4\n",
      "42/42 [==============================] - 3s 76ms/step - loss: 0.3275\n",
      "Epoch 2/4\n",
      "42/42 [==============================] - 3s 77ms/step - loss: 0.3231\n",
      "Epoch 3/4\n",
      "42/42 [==============================] - 3s 77ms/step - loss: 0.3123\n",
      "Epoch 4/4\n",
      "42/42 [==============================] - 3s 76ms/step - loss: 0.3034\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: '\n",
      "\t\treturn false;\n",
      "\n",
      "\tif (sig == sigkill)\n",
      "\t\treturn true;\n",
      "\n",
      "\tif (task_is_stopped_or_traced(p))\n",
      "\t\treturn f'\n",
      "\n",
      "\t\treturn false;\n",
      "\n",
      "\tif (sig == sigkill)\n",
      "\t\treturn true;\n",
      "\n",
      "\tif (task_is_stopped_or_traced(p))\n",
      "\t\treturn false;\n",
      "\t\tbreak;\n",
      "\tcase sil_signal_pending(sig, info, pid_t, pid, int, sig,\n",
      "\t\tsiginfo_t __user *, uset,\n",
      "\tstruct task_struct *t)\n",
      "{\n",
      "\tunt = signr = ptrace_stop(current, handler_current))\n",
      "{\n",
      "\tunt = signr = pt\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: '\n",
      "\t\treturn false;\n",
      "\n",
      "\tif (sig == sigkill)\n",
      "\t\treturn true;\n",
      "\n",
      "\tif (task_is_stopped_or_traced(p))\n",
      "\t\treturn f'\n",
      "\n",
      "\t\treturn false;\n",
      "\n",
      "\tif (sig == sigkill)\n",
      "\t\treturn true;\n",
      "\n",
      "\tif (task_is_stopped_or_traced(p))\n",
      "\t\treturn false;\n",
      "\t\tbreak;\n",
      "\tcase sil_signal_pending(sig, &info, pid_t))\n",
      "\t\treturn -einval;\n",
      "}\n",
      "\n",
      "int compat_struct *tsk in the enclest_restore_sigmask();\n",
      "\t\tto->si_perf_data = archeck_offset(si_perf_dala))) {\n",
      "\t\t\t\tlock\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: '\n",
      "\t\treturn false;\n",
      "\n",
      "\tif (sig == sigkill)\n",
      "\t\treturn true;\n",
      "\n",
      "\tif (task_is_stopped_or_traced(p))\n",
      "\t\treturn f'\n",
      "\n",
      "\t\treturn false;\n",
      "\n",
      "\tif (sig == sigkill)\n",
      "\t\treturn true;\n",
      "\n",
      "\tif (task_is_stopped_or_traced(p))\n",
      "\t\treturn false;\n",
      "\t} else if (get_onver(pid));\n",
      "}\n",
      "\n",
      "/* for this falling this signal handler */\n",
      "\thread_lock(&tasklist_lock);\n",
      "\terror = -const compat_compat_sigset(&new_sa.\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: '\n",
      "\t\treturn false;\n",
      "\n",
      "\tif (sig == sigkill)\n",
      "\t\treturn true;\n",
      "\n",
      "\tif (task_is_stopped_or_traced(p))\n",
      "\t\treturn f'\n",
      "\n",
      "\t\treturn false;\n",
      "\n",
      "\tif (sig == sigkill)\n",
      "\t\treturn true;\n",
      "\n",
      "\tif (task_is_stopped_or_traced(p))\n",
      "\t\treturn false;\n",
      "\t\tbool } ensigned info.\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 11\n",
      "Epoch 1/4\n",
      "42/42 [==============================] - 3s 78ms/step - loss: 0.2999\n",
      "Epoch 2/4\n",
      "42/42 [==============================] - 3s 77ms/step - loss: 0.2940\n",
      "Epoch 3/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 0.2842\n",
      "Epoch 4/4\n",
      "42/42 [==============================] - 3s 76ms/step - loss: 0.2853\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: ' pid namespace init? */\n",
      "\tbool force = false;\n",
      "\n",
      "\tif (info == send_sig_noinfo) {\n",
      "\t\t/* force if sent fro'\n",
      " pid namespace init? */\n",
      "\tbool force = false;\n",
      "\n",
      "\tif (info == send_sig_noinfo) {\n",
      "\t\t/* force if sent from  the called and whech adds on ptracer.\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: ' pid namespace init? */\n",
      "\tbool force = false;\n",
      "\n",
      "\tif (info == send_sig_noinfo) {\n",
      "\t\t/* force if sent fro'\n",
      " pid namespace init? */\n",
      "\tbool force = false;\n",
      "\n",
      "\tif (info == send_sig_noinfo) {\n",
      "\t\t/* force if sent from  the clearedeling the signal, which adds or\n",
      "\t\t * domand in the group stop is always wing to be whech\n",
      "\t\t * out ofls it doesn't handle action\n",
      "\t\t * ofls is do_notify_parent_cldstop(struct task_struct *\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: ' pid namespace init? */\n",
      "\tbool force = false;\n",
      "\n",
      "\tif (info == send_sig_noinfo) {\n",
      "\t\t/* force if sent fro'\n",
      " pid namespace init? */\n",
      "\tbool force = false;\n",
      "\n",
      "\tif (info == send_sig_noinfo) {\n",
      "\t\t/* force if sent from deais same pid notimers\n",
      " * we dentern the only valid for don't compat signal we deng this cld_stopped, ers and to be sent\n",
      "\t * notify task_clear_jobctl_pending, config_oldsi_info.\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: ' pid namespace init? */\n",
      "\tbool force = false;\n",
      "\n",
      "\tif (info == send_sig_noinfo) {\n",
      "\t\t/* force if sent fro'\n",
      " pid namespace init? */\n",
      "\tbool force = false;\n",
      "\n",
      "\tif (info == send_sig_noinfo) {\n",
      "\t\t/* force if sent from are called the fins henduto\n",
      "\t\t * collinged not this flag muptise for the case struct task_struct *sighand->siglo\"king\n",
      "\t * cuerently clearede that wish notialy.\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 12\n",
      "Epoch 1/4\n",
      "42/42 [==============================] - 3s 77ms/step - loss: 0.2869\n",
      "Epoch 2/4\n",
      "42/42 [==============================] - 3s 76ms/step - loss: 0.2868\n",
      "Epoch 3/4\n",
      "42/42 [==============================] - 3s 76ms/step - loss: 0.2829\n",
      "Epoch 4/4\n",
      "42/42 [==============================] - 3s 77ms/step - loss: 0.2750\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: ' const siginfo_t __user *from)\n",
      "{\n",
      "\tif (copy_from_user(to, from, sizeof(struct kernel_siginfo)))\n",
      "\t\tret'\n",
      " const siginfo_t __user *from)\n",
      "{\n",
      "\tif (copy_from_user(to, from, sizeof(struct kernel_siginfo)))\n",
      "\t\treturn -efault;\n",
      "\tint error;\n",
      "\tstack_t __user *umsate & (sig? && (si_code <= nset))\n",
      "\t\t\tif (!signr)\n",
      "\t\t\tclear_thread_froze((t, &flags);\n",
      "\t\treturn -efault;\n",
      "\treturn 0;\n",
      "}\n",
      "\n",
      "static int __inco the clear_thread_flag\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: ' const siginfo_t __user *from)\n",
      "{\n",
      "\tif (copy_from_user(to, from, sizeof(struct kernel_siginfo)))\n",
      "\t\tret'\n",
      " const siginfo_t __user *from)\n",
      "{\n",
      "\tif (copy_from_user(to, from, sizeof(struct kernel_siginfo)))\n",
      "\t\treturn -efault;\n",
      "\n",
      "\tif (!task_isquruerablenk();\n",
      "\t\t\tq->info.\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: ' const siginfo_t __user *from)\n",
      "{\n",
      "\tif (copy_from_user(to, from, sizeof(struct kernel_siginfo)))\n",
      "\t\tret'\n",
      " const siginfo_t __user *from)\n",
      "{\n",
      "\tif (copy_from_user(to, from, sizeof(struct kernel_siginfo)))\n",
      "\t\treturn -efault;\n",
      "\tent = task_pid_info));\n",
      "/*\n",
      "#ifdef config_compat\n",
      "compat_syscall_define1(ksig->info.\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: ' const siginfo_t __user *from)\n",
      "{\n",
      "\tif (copy_from_user(to, from, sizeof(struct kernel_siginfo)))\n",
      "\t\tret'\n",
      " const siginfo_t __user *from)\n",
      "{\n",
      "\tif (copy_from_user(to, from, sizeof(struct kernel_siginfo)))\n",
      "\t\treturn -efault;\n",
      "\tint error;\n",
      "\t\tto->si_pid = 0;\n",
      "\tswikch (siginfo_lacount_si_pid_faults(struct mask))\n",
      "\t\t/*\n",
      "\t\t * if got >sa_thread\n",
      " * the pid must be cullecped, we must release the siglock held, will cate it\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 13\n",
      "Epoch 1/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 0.2630\n",
      "Epoch 2/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 0.2650\n",
      "Epoch 3/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 0.2713\n",
      "Epoch 4/4\n",
      "42/42 [==============================] - 3s 76ms/step - loss: 0.2614\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: 'source info.\n",
      "\t */\n",
      "\tif ((info->si_code >= 0 || info->si_code == si_tkill) &&\n",
      "\t    (task_pid_vnr(curre'\n",
      "source info.\n",
      "\t */\n",
      "\tif ((info->si_code >= 0 || info->si_code == si_tkill) &&\n",
      "\t    (task_pid_vnr(current) != pid);\n",
      "}\n",
      "\n",
      "/*\n",
      " * the underr no signal that the send and we re task and the signal that to setion.\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: 'source info.\n",
      "\t */\n",
      "\tif ((info->si_code >= 0 || info->si_code == si_tkill) &&\n",
      "\t    (task_pid_vnr(curre'\n",
      "source info.\n",
      "\t */\n",
      "\tif ((info->si_code >= 0 || info->si_code == si_tkill) &&\n",
      "\t    (task_pid_vnr(current) != pfd_signal_signal();\n",
      "\tif (sigsetsize >= 0);\n",
      "\n",
      "\t/* this flags and the called and do signal get and should be vaiked by sigpend is always find a ptracer\n",
      " * @t: ptracer't in or oramestor\n",
      " * extifie\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: 'source info.\n",
      "\t */\n",
      "\tif ((info->si_code >= 0 || info->si_code == si_tkill) &&\n",
      "\t    (task_pid_vnr(curre'\n",
      "source info.\n",
      "\t */\n",
      "\tif ((info->si_code >= 0 || info->si_code == si_tkill) &&\n",
      "\t    (task_pid_vnr(current) != ptrace_for)))\n",
      "\t\tcont;\n",
      "\n",
      "\t/* signal we are goon the signal on the sacred __send_signal(its ? &nother != ptrace_unding && pid_mask(sigmask);\n",
      "\t\tka-->sig[1];\n",
      "\t\tready |= signal->sig[0] &~ blocked->si\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: 'source info.\n",
      "\t */\n",
      "\tif ((info->si_code >= 0 || info->si_code == si_tkill) &&\n",
      "\t    (task_pid_vnr(curre'\n",
      "source info.\n",
      "\t */\n",
      "\tif ((info->si_code >= 0 || info->si_code == si_tkill) &&\n",
      "\t    (task_pid_vnr(current) !xfpt_pided);\n",
      "\t}\n",
      "\tqueue_free((info);\n",
      "\tcred->uuir);\n",
      "\t\ttask->jobctl &= ~mcal__nall, pid_t pid);\n",
      "\tfor_oact_mask(syscall, signal, sigkill)\n",
      "\t\treturn -einval;\n",
      "\n",
      "\tspin_lock_irqsave(&tsk->sighand->siglock)\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 14\n",
      "Epoch 1/4\n",
      "42/42 [==============================] - 3s 80ms/step - loss: 0.2574\n",
      "Epoch 2/4\n",
      "42/42 [==============================] - 3s 79ms/step - loss: 0.2502\n",
      "Epoch 3/4\n",
      "42/42 [==============================] - 3s 79ms/step - loss: 0.2566\n",
      "Epoch 4/4\n",
      "42/42 [==============================] - 3s 81ms/step - loss: 0.2431\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: '**\n",
      " * task_set_jobctl_pending - set jobctl pending bits\n",
      " * @task: target task\n",
      " * @mask: pending bits'\n",
      "**\n",
      " * task_set_jobctl_pending - set jobctl pending bits\n",
      " * @task: target task\n",
      " * @mask: pending bits ared.\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: '**\n",
      " * task_set_jobctl_pending - set jobctl pending bits\n",
      " * @task: target task\n",
      " * @mask: pending bits'\n",
      "**\n",
      " * task_set_jobctl_pending - set jobctl pending bits\n",
      " * @task: target task\n",
      " * @mask: pending bits are that will be frecause blocked, handler has %will be freads check to sig_ign\n",
      " * conetion to sation the really and portsyncherr is no \"\n",
      "\t\t\t\t     onfigs;\n",
      "\tstruct sigqueue *q)\n",
      "}\n",
      "\n",
      "/**\n",
      " * signals on th\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: '**\n",
      " * task_set_jobctl_pending - set jobctl pending bits\n",
      " * @task: target task\n",
      " * @mask: pending bits'\n",
      "**\n",
      " * task_set_jobctl_pending - set jobctl pending bits\n",
      " * @task: target task\n",
      " * @mask: pending bits ous.\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: '**\n",
      " * task_set_jobctl_pending - set jobctl pending bits\n",
      " * @task: target task\n",
      " * @mask: pending bits'\n",
      "**\n",
      " * task_set_jobctl_pending - set jobctl pending bits\n",
      " * @task: target task\n",
      " * @mask: pending bits aredent to sig_kernel.\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 15\n",
      "Epoch 1/4\n",
      "42/42 [==============================] - 3s 81ms/step - loss: 0.2419\n",
      "Epoch 2/4\n",
      "42/42 [==============================] - 3s 81ms/step - loss: 0.2407\n",
      "Epoch 3/4\n",
      "42/42 [==============================] - 3s 82ms/step - loss: 0.2451\n",
      "Epoch 4/4\n",
      "42/42 [==============================] - 3s 82ms/step - loss: 0.2443\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: 'ompat_size_t, sigsetsize)\n",
      "{\n",
      "\tsigset_t s;\n",
      "\tstruct timespec64 t;\n",
      "\tkernel_siginfo_t info;\n",
      "\tlong ret;\n",
      "\n",
      "\t'\n",
      "ompat_size_t, sigsetsize)\n",
      "{\n",
      "\tsigset_t s;\n",
      "\tstruct timespec64 t;\n",
      "\tkernel_siginfo_t info;\n",
      "\tlong ret;\n",
      "\n",
      "\tptrace_sig_and(pid);\n",
      "\t\t\t\tgoto reld;\n",
      "\t\tto->si_pid = from->si_pid;\n",
      "\t\tto->si_uid = from->si_uid;;\n",
      "\t\tto->si_uid = from->si_uid;\n",
      "\t\tto->si_int     from->si_pid;\n",
      "\t\tto->si_uid = from->si_uid;\n",
      "\t\tto->si_uid = f\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: 'ompat_size_t, sigsetsize)\n",
      "{\n",
      "\tsigset_t s;\n",
      "\tstruct timespec64 t;\n",
      "\tkernel_siginfo_t info;\n",
      "\tlong ret;\n",
      "\n",
      "\t'\n",
      "ompat_size_t, sigsetsize)\n",
      "{\n",
      "\tsigset_t s;\n",
      "\tstruct timespec64 t;\n",
      "\tkernel_siginfo_t info;\n",
      "\tlong ret;\n",
      "\n",
      "\tspin_unlock_irqrestore(&t->signal->flags & signal_code)\n",
      "{\n",
      "\tstruct sigqueue *q)\n",
      "{\n",
      "\tinfo.\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: 'ompat_size_t, sigsetsize)\n",
      "{\n",
      "\tsigset_t s;\n",
      "\tstruct timespec64 t;\n",
      "\tkernel_siginfo_t info;\n",
      "\tlong ret;\n",
      "\n",
      "\t'\n",
      "ompat_size_t, sigsetsize)\n",
      "{\n",
      "\tsigset_t s;\n",
      "\tstruct timespec64 t;\n",
      "\tkernel_siginfo_t info;\n",
      "\tlong ret;\n",
      "\n",
      "\tpo_define3(ret, unsigned cld_stopped, &set, null);\n",
      "\t\treturn thread_group_exit (&new_set, nsig, size, toute)\n",
      "\t\t\t\treturn -efault;\n",
      "\t\tunsigned long meas;\n",
      "\t\tif (task_action(sig, act ? &nst be arch{\n",
      "\t\tunloc\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: 'ompat_size_t, sigsetsize)\n",
      "{\n",
      "\tsigset_t s;\n",
      "\tstruct timespec64 t;\n",
      "\tkernel_siginfo_t info;\n",
      "\tlong ret;\n",
      "\n",
      "\t'\n",
      "ompat_size_t, sigsetsize)\n",
      "{\n",
      "\tsigset_t s;\n",
      "\tstruct timespec64 t;\n",
      "\tkernel_siginfo_t info;\n",
      "\tlong ret;\n",
      "\n",
      "\tp/*\n",
      " * if geturned hoid wase_up_addr_morkstack hall stop.\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 16\n",
      "Epoch 1/4\n",
      "42/42 [==============================] - 3s 81ms/step - loss: 0.2442\n",
      "Epoch 2/4\n",
      "42/42 [==============================] - 3s 80ms/step - loss: 0.2408\n",
      "Epoch 3/4\n",
      "42/42 [==============================] - 3s 82ms/step - loss: 0.2324\n",
      "Epoch 4/4\n",
      "42/42 [==============================] - 3s 81ms/step - loss: 0.2370\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: 'flags);\n",
      "}\n",
      "#endif\n",
      "\n",
      "void ignore_signals(struct task_struct *t)\n",
      "{\n",
      "\tint i;\n",
      "\n",
      "\tfor (i = 0; i < _nsig; ++i)'\n",
      "flags);\n",
      "}\n",
      "#endif\n",
      "\n",
      "void ignore_signals(struct task_struct *t)\n",
      "{\n",
      "\tint i;\n",
      "\n",
      "\tfor (i = 0; i < _nsig; ++i)\n",
      "\t\tto ret;\n",
      "\n",
      "\tptrace_sig_non_signal(sig, pending, &t->pending);\n",
      "\t\tfor_user(handler_task_sighand(struct task_struct *tsk, trapno.\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: 'flags);\n",
      "}\n",
      "#endif\n",
      "\n",
      "void ignore_signals(struct task_struct *t)\n",
      "{\n",
      "\tint i;\n",
      "\n",
      "\tfor (i = 0; i < _nsig; ++i)'\n",
      "flags);\n",
      "}\n",
      "#endif\n",
      "\n",
      "void ignore_signals(struct task_struct *t)\n",
      "{\n",
      "\tint i;\n",
      "\n",
      "\tfor (i = 0; i < _nsig; ++i)\n",
      "\t\tto ret;\n",
      "\n",
      "\tptrace_sig_non_sig_mask | jobctl_trap_freeze) {\n",
      "\t\tif (siginfo_lock(&tasklist_lock);\n",
      "\t\t\treturn -efault;\n",
      "\t}\n",
      "\n",
      "\tret = do_sigaction(sig, act ? &ns force != sizeof(sigset_t))\n",
      "\t\treturn -einval;\n",
      "\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: 'flags);\n",
      "}\n",
      "#endif\n",
      "\n",
      "void ignore_signals(struct task_struct *t)\n",
      "{\n",
      "\tint i;\n",
      "\n",
      "\tfor (i = 0; i < _nsig; ++i)'\n",
      "flags);\n",
      "}\n",
      "#endif\n",
      "\n",
      "void ignore_signals(struct task_struct *t)\n",
      "{\n",
      "\tint i;\n",
      "\n",
      "\tfor (i = 0; i < _nsig; ++i)\n",
      "{\n",
      "\tstruct sigqueue *q(ini, enul))) {\n",
      "\t\t\tif (copy_from_user(&from, ufsignal, wey {\n",
      "\t\t\telse if (si_code <= sig_sicadd_signal(&tsk->signal->struct kt;\n",
      "\t}\n",
      "\n",
      "\tclear_siginfo(info, current));\n",
      "\tif (sigsetsize\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: 'flags);\n",
      "}\n",
      "#endif\n",
      "\n",
      "void ignore_signals(struct task_struct *t)\n",
      "{\n",
      "\tint i;\n",
      "\n",
      "\tfor (i = 0; i < _nsig; ++i)'\n",
      "flags);\n",
      "}\n",
      "#endif\n",
      "\n",
      "void ignore_signals(struct task_struct *t)\n",
      "{\n",
      "\tint i;\n",
      "\n",
      "\tfor (i = 0; i < _nsig; ++i)\n",
      "\t\tto ret;\n",
      "\n",
      "\tspin_unlock_irqrestore(&t->sighand->siglock, we net act->sa_mask))\n",
      "\t\t\tret = -efault;\n",
      "\t} else {\n",
      "\t\tpinfo___uid3_siginfo(info, &info);\n",
      "\tinfo.\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 17\n",
      "Epoch 1/4\n",
      "42/42 [==============================] - 4s 82ms/step - loss: 0.2374\n",
      "Epoch 2/4\n",
      "42/42 [==============================] - 3s 83ms/step - loss: 0.2331\n",
      "Epoch 3/4\n",
      "42/42 [==============================] - 3s 81ms/step - loss: 0.2385\n",
      "Epoch 4/4\n",
      "42/42 [==============================] - 3s 80ms/step - loss: 0.2309\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: 'ndled.  that doesn't matter because its only purpose\n",
      "\t\t * is to alert stop-signal processing code wh'\n",
      "ndled.  that doesn't matter because its only purpose\n",
      "\t\t * is to alert stop-signal processing code where process.\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: 'ndled.  that doesn't matter because its only purpose\n",
      "\t\t * is to alert stop-signal processing code wh'\n",
      "ndled.  that doesn't matter because its only purpose\n",
      "\t\t * is to alert stop-signal processing code wher conping is notifies the exit is not vilipid by task is incout doing notifies the exit confing is jobctl_trapping mask | jobctl_stop_consume;\n",
      "\n",
      "\t\t * is allowed signals in a %32.\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: 'ndled.  that doesn't matter because its only purpose\n",
      "\t\t * is to alert stop-signal processing code wh'\n",
      "ndled.  that doesn't matter because its only purpose\n",
      "\t\t * is to alert stop-signal processing code where ik.\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: 'ndled.  that doesn't matter because its only purpose\n",
      "\t\t * is to alert stop-signal processing code wh'\n",
      "ndled.  that doesn't matter because its only purpose\n",
      "\t\t * is to alert stop-signal processing code whis preemption.\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 18\n",
      "Epoch 1/4\n",
      "42/42 [==============================] - 3s 81ms/step - loss: 0.2286\n",
      "Epoch 2/4\n",
      "42/42 [==============================] - 3s 81ms/step - loss: 0.2400\n",
      "Epoch 3/4\n",
      "42/42 [==============================] - 3s 81ms/step - loss: 0.2413\n",
      "Epoch 4/4\n",
      "42/42 [==============================] - 3s 81ms/step - loss: 0.2494\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: ' blocked->sig[1];\n",
      "\t\tready |= signal->sig[0] &~ blocked->sig[0];\n",
      "\t\tbreak;\n",
      "\n",
      "\tcase 1: ready  = signal->'\n",
      " blocked->sig[1];\n",
      "\t\tready |= signal->sig[0] &~ blocked->sig[0];\n",
      "\t\tbreak;\n",
      "\n",
      "\tcase 1: ready  = signal->sig[1] &~ blocked->sig[1];\n",
      "\t\tread_unlock(&tasklist_lock);\n",
      "\t\treturn current->blocked;\n",
      "\n",
      "\t\t/*\n",
      "\t\t * if we we signal action tasklist_lock\n",
      " * be uspend and we re the ptracer\n",
      "\t\t * of signal we detarged has c\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: ' blocked->sig[1];\n",
      "\t\tready |= signal->sig[0] &~ blocked->sig[0];\n",
      "\t\tbreak;\n",
      "\n",
      "\tcase 1: ready  = signal->'\n",
      " blocked->sig[1];\n",
      "\t\tready |= signal->sig[0] &~ blocked->sig[0];\n",
      "\t\tbreak;\n",
      "\n",
      "\tcase 1: ready  = signal->sig[1] &~ blocked->sig[1];\n",
      "\t\tread_unlock(&tasklist_lock);\n",
      "\t\treturn copy_siginfo_from_user(tgred->signal;\n",
      "\tint error;\n",
      "\t\tq->unsigne = config_posix_timers\n",
      "\t\t */\n",
      "\t\t\tif (unlikely(get_stop_consigneomemsions\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: ' blocked->sig[1];\n",
      "\t\tready |= signal->sig[0] &~ blocked->sig[0];\n",
      "\t\tbreak;\n",
      "\n",
      "\tcase 1: ready  = signal->'\n",
      " blocked->sig[1];\n",
      "\t\tready |= signal->sig[0] &~ blocked->sig[0];\n",
      "\t\tbreak;\n",
      "\n",
      "\tcase 1: ready  = signal->sig[1] &~ blocked)\n",
      "\t\t\twake_up_ags(t, jobctl_trap_stop);\n",
      "\t\tto->si_perf_data = from->si_perf_exit_signals, &act->sa_flags) ||\n",
      "\t\t    __get_user(mask);\n",
      "\t\t\tsigdelset(signal, sig);\n",
      "\tsigandset_t);\n",
      "\n",
      "\treturn s\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: ' blocked->sig[1];\n",
      "\t\tready |= signal->sig[0] &~ blocked->sig[0];\n",
      "\t\tbreak;\n",
      "\n",
      "\tcase 1: ready  = signal->'\n",
      " blocked->sig[1];\n",
      "\t\tready |= signal->sig[0] &~ blocked->sig[0];\n",
      "\t\tbreak;\n",
      "\n",
      "\tcase 1: ready  = signal->sig[1] rrom->nar_mask);\n",
      "\t\t\tretvor = accroc);\n",
      "#ifdef (from->si_pid = task_pid_nr_ns(t);\n",
      "\t\trefurce_pot_sigaction(sig, &info);\n",
      "\tif (unlikely(ret))\n",
      "\t\t\treturn sigprocess trap;\n",
      "\tint proce_signal(sig, t, typ\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 19\n",
      "Epoch 1/4\n",
      "42/42 [==============================] - 4s 82ms/step - loss: 0.2443\n",
      "Epoch 2/4\n",
      "42/42 [==============================] - 3s 82ms/step - loss: 0.2341\n",
      "Epoch 3/4\n",
      "42/42 [==============================] - 3s 81ms/step - loss: 0.2403\n",
      "Epoch 4/4\n",
      "42/42 [==============================] - 3s 81ms/step - loss: 0.2388\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: 'rn kill_something_info(sig, &info, pid);\n",
      "}\n",
      "\n",
      "/*\n",
      " * verify that the signaler and signalee either are i'\n",
      "rn kill_something_info(sig, &info, pid);\n",
      "}\n",
      "\n",
      "/*\n",
      " * verify that the signaler and signalee either are inlock\n",
      " */\n",
      "int sig <= sig = sigkill)\n",
      "\t\treturn -efault;\n",
      "\n",
      "\treturn pid_type type;\n",
      "\n",
      "\t\tif (onsigned long messace_signal();\n",
      "\t\t\t\twake_up_compat(from->si_addr);\n",
      "\t\tto->si_perf_dala = from->si_perf_flags;\n",
      "\t\tbrea\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: 'rn kill_something_info(sig, &info, pid);\n",
      "}\n",
      "\n",
      "/*\n",
      " * verify that the signaler and signalee either are i'\n",
      "rn kill_something_info(sig, &info, pid);\n",
      "}\n",
      "\n",
      "/*\n",
      " * verify that the signaler and signalee either are instead.\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: 'rn kill_something_info(sig, &info, pid);\n",
      "}\n",
      "\n",
      "/*\n",
      " * verify that the signaler and signalee either are i'\n",
      "rn kill_something_info(sig, &info, pid);\n",
      "}\n",
      "\n",
      "/*\n",
      " * verify that the signaler and signalee either are insteping to notify task astalled do_notify_parent_cldstop(signal, mask)\n",
      "\t\t\tsigdending, && sig == sigsegv)\n",
      "\t\tfrom->si_pid = 0;\n",
      "\t\tif (t) {\n",
      "\t\t\tif (current->struct task_struct *t)\n",
      "{\n",
      "\tstruct pt_ad_restore_\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: 'rn kill_something_info(sig, &info, pid);\n",
      "}\n",
      "\n",
      "/*\n",
      " * verify that the signaler and signalee either are i'\n",
      "rn kill_something_info(sig, &info, pid);\n",
      "}\n",
      "\n",
      "/*\n",
      " * verify that the signaler and signalee either are inly before the pid of the task in process.\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 20\n",
      "Epoch 1/4\n",
      "42/42 [==============================] - 3s 80ms/step - loss: 0.2283\n",
      "Epoch 2/4\n",
      "42/42 [==============================] - 3s 81ms/step - loss: 0.2290\n",
      "Epoch 3/4\n",
      "42/42 [==============================] - 3s 80ms/step - loss: 0.2229\n",
      "Epoch 4/4\n",
      "42/42 [==============================] - 3s 81ms/step - loss: 0.2269\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: 't_user_stack_pointer(),\n",
      "\t\t\t     compat_minsigstksz);\n",
      "\tif (ret >= 0 && uoss_ptr)  {\n",
      "\t\tcompat_stack_t '\n",
      "t_user_stack_pointer(),\n",
      "\t\t\t     compat_minsigstksz);\n",
      "\tif (ret >= 0 && uoss_ptr)  {\n",
      "\t\tcompat_stack_t __user *umsignal(sig, int code, void __user *addr);\n",
      "\tcget_signal(sig, &info, uinfo);\n",
      "\tif (unlikely(get_ond_sig_info(info.\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: 't_user_stack_pointer(),\n",
      "\t\t\t     compat_minsigstksz);\n",
      "\tif (ret >= 0 && uoss_ptr)  {\n",
      "\t\tcompat_stack_t '\n",
      "t_user_stack_pointer(),\n",
      "\t\t\t     compat_minsigstksz);\n",
      "\tif (ret >= 0 && uoss_ptr)  {\n",
      "\t\tcompat_stack_t __user *umsig->signal->group_exetsing = 0;\n",
      "\n",
      "\t\t/* dif be called with @task->sighand->siglock held.\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: 't_user_stack_pointer(),\n",
      "\t\t\t     compat_minsigstksz);\n",
      "\tif (ret >= 0 && uoss_ptr)  {\n",
      "\t\tcompat_stack_t '\n",
      "t_user_stack_pointer(),\n",
      "\t\t\t     compat_minsigstksz);\n",
      "\tif (ret >= 0 && uoss_ptr)  {\n",
      "\t\tcompat_stack_t __user *umsig->sig || 0;\n",
      "\t}\n",
      "}\n",
      "\n",
      "static int do_copped_signal(sig);\n",
      "\tconfig_kask(&info->si_signo;\n",
      "\tstruct sigqueue *q);\n",
      "}\n",
      "\n",
      "static int __int set_t __user *, nset,\n",
      "\t\told_set_t __user *handler;\n",
      "\n",
      "\tnow_blocke\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: 't_user_stack_pointer(),\n",
      "\t\t\t     compat_minsigstksz);\n",
      "\tif (ret >= 0 && uoss_ptr)  {\n",
      "\t\tcompat_stack_t '\n",
      "t_user_stack_pointer(),\n",
      "\t\t\t     compat_minsigstksz);\n",
      "\tif (ret >= 0 && uoss_ptr)  {\n",
      "\t\tcompat_stack_t __user *unlikely(sig->group_exet_trapno;\n",
      "\tif (!(there && info->si_code == si_tking);\n",
      "\twase wil_ptr:\n",
      "\tcase sil_fault_default(tsk->sighand->siglock, &flags, &old_ka.\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 21\n",
      "Epoch 1/4\n",
      "42/42 [==============================] - 4s 81ms/step - loss: 0.2204\n",
      "Epoch 2/4\n",
      "42/42 [==============================] - 3s 81ms/step - loss: 0.2153\n",
      "Epoch 3/4\n",
      "42/42 [==============================] - 3s 80ms/step - loss: 0.2194\n",
      "Epoch 4/4\n",
      "42/42 [==============================] - 3s 80ms/step - loss: 0.2285\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: '>si_code == si_timer) &&\n",
      "\t\t\t(info->si_sys_private);\n",
      "\n",
      "\t\t__sigqueue_free(first);\n",
      "\t} else {\n",
      "\t\t/*\n",
      "\t\t * o'\n",
      ">si_code == si_timer) &&\n",
      "\t\t\t(info->si_sys_private);\n",
      "\n",
      "\t\t__sigqueue_free(first);\n",
      "\t} else {\n",
      "\t\t/*\n",
      "\t\t * oflace the for stopped/\n",
      "\t\tcurrent->jobctl || !p_t))\n",
      "\t\t\treturn -efault;\n",
      "\t\tsigdelsetmask(&new_set, sigmask(sigkill);\n",
      "\t\treturn -efault;\n",
      "\t}\n",
      "\n",
      "\tret = do_sigaction(sig, &info);\n",
      "}\n",
      "\n",
      "/*\n",
      " * if config_compat\n",
      "compa\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: '>si_code == si_timer) &&\n",
      "\t\t\t(info->si_sys_private);\n",
      "\n",
      "\t\t__sigqueue_free(first);\n",
      "\t} else {\n",
      "\t\t/*\n",
      "\t\t * o'\n",
      ">si_code == si_timer) &&\n",
      "\t\t\t(info->si_sys_private);\n",
      "\n",
      "\t\t__sigqueue_free(first);\n",
      "\t} else {\n",
      "\t\t/*\n",
      "\t\t * ofly callers flag nets are mort in the queue signal is achivees the signal\n",
      "\t *                    ptrace_archatess_pending, but nove kidlock\n",
      "\t\t * was van will have before thing this falat of signal be \n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: '>si_code == si_timer) &&\n",
      "\t\t\t(info->si_sys_private);\n",
      "\n",
      "\t\t__sigqueue_free(first);\n",
      "\t} else {\n",
      "\t\t/*\n",
      "\t\t * o'\n",
      ">si_code == si_timer) &&\n",
      "\t\t\t(info->si_sys_private);\n",
      "\n",
      "\t\t__sigqueue_free(first);\n",
      "\t} else {\n",
      "\t\t/*\n",
      "\t\t * oflace and anot can preting if notify -ecompletif (t->sighand->siglock heldis\n",
      "\n",
      " * @tsk->sighand check->flugh a signal has punforce iting archore that is signal we default and phent->flags | jobctl_stop\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: '>si_code == si_timer) &&\n",
      "\t\t\t(info->si_sys_private);\n",
      "\n",
      "\t\t__sigqueue_free(first);\n",
      "\t} else {\n",
      "\t\t/*\n",
      "\t\t * o'\n",
      ">si_code == si_timer) &&\n",
      "\t\t\t(info->si_sys_private);\n",
      "\n",
      "\t\t__sigqueue_free(first);\n",
      "\t} else {\n",
      "\t\t/*\n",
      "\t\t * oflave pending signal has not doing the call is not vinimi, siginfo not punting in asy constild by sp.\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 22\n",
      "Epoch 1/4\n",
      "42/42 [==============================] - 3s 78ms/step - loss: 0.2349\n",
      "Epoch 2/4\n",
      "42/42 [==============================] - 3s 78ms/step - loss: 0.2358\n",
      "Epoch 3/4\n",
      "42/42 [==============================] - 3s 78ms/step - loss: 0.2281\n",
      "Epoch 4/4\n",
      "42/42 [==============================] - 3s 77ms/step - loss: 0.2354\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: 'n(true);\n",
      "\n",
      "\t/*\n",
      "\t * we are back.  now reacquire the siglock before touching\n",
      "\t * last_siginfo, so that '\n",
      "n(true);\n",
      "\n",
      "\t/*\n",
      "\t * we are back.  now reacquire the siglock before touching\n",
      "\t * last_siginfo, so that we ald to exignr)\n",
      "\t\tpending->signal.\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: 'n(true);\n",
      "\n",
      "\t/*\n",
      "\t * we are back.  now reacquire the siglock before touching\n",
      "\t * last_siginfo, so that '\n",
      "n(true);\n",
      "\n",
      "\t/*\n",
      "\t * we are back.  now reacquire the siglock before touching\n",
      "\t * last_siginfo, so that we ald the really trap in thit the signal mask is no  < if the signal we are go out in the stack_t *lock.\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: 'n(true);\n",
      "\n",
      "\t/*\n",
      "\t * we are back.  now reacquire the siglock before touching\n",
      "\t * last_siginfo, so that '\n",
      "n(true);\n",
      "\n",
      "\t/*\n",
      "\t * we are back.  now reacquire the siglock before touching\n",
      "\t * last_siginfo, so that we als ot is the signal.\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: 'n(true);\n",
      "\n",
      "\t/*\n",
      "\t * we are back.  now reacquire the siglock before touching\n",
      "\t * last_siginfo, so that '\n",
      "n(true);\n",
      "\n",
      "\t/*\n",
      "\t * we are back.  now reacquire the siglock before touching\n",
      "\t * last_siginfo, so that we ald the real parent ig is achinged unblocked, hevear and recant will %d.\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 23\n",
      "Epoch 1/4\n",
      "42/42 [==============================] - 3s 78ms/step - loss: 0.2347\n",
      "Epoch 2/4\n",
      "42/42 [==============================] - 3s 78ms/step - loss: 0.2297\n",
      "Epoch 3/4\n",
      "42/42 [==============================] - 3s 76ms/step - loss: 0.2266\n",
      "Epoch 4/4\n",
      "42/42 [==============================] - 3s 77ms/step - loss: 0.2238\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: 'th it\n",
      "\t * executing another processor and just now entering stopped state.\n",
      "\t * by using wake_up_stat'\n",
      "th it\n",
      "\t * executing another processor and just now entering stopped state.\n",
      "\t * by using wake_up_state, info, sigkill | jobctl_trap_freezer if the signal we denamess, we allow the signal on the scalled process.\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: 'th it\n",
      "\t * executing another processor and just now entering stopped state.\n",
      "\t * by using wake_up_stat'\n",
      "th it\n",
      "\t * executing another processor and just now entering stopped state.\n",
      "\t * by using wake_up_state, int signals mask is no the queue signal.\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: 'th it\n",
      "\t * executing another processor and just now entering stopped state.\n",
      "\t * by using wake_up_stat'\n",
      "th it\n",
      "\t * executing another processor and just now entering stopped state.\n",
      "\t * by using wake_up_state, anstable be called with @task->sighand->siglock held.\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: 'th it\n",
      "\t * executing another processor and just now entering stopped state.\n",
      "\t * by using wake_up_stat'\n",
      "th it\n",
      "\t * executing another processor and just now entering stopped state.\n",
      "\t * by using wake_up_state].\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 24\n",
      "Epoch 1/4\n",
      "42/42 [==============================] - 3s 76ms/step - loss: 0.2157\n",
      "Epoch 2/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 0.2178\n",
      "Epoch 3/4\n",
      "42/42 [==============================] - 3s 76ms/step - loss: 0.2123\n",
      "Epoch 4/4\n",
      "42/42 [==============================] - 3s 76ms/step - loss: 0.2202\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: ' * we don't want to have recursive sigsegv's etc, for example,\n",
      " * that is why we also clear signal_u'\n",
      " * we don't want to have recursive sigsegv's etc, for example,\n",
      " * that is why we also clear signal_unkillable f red as of stopped/\n",
      "\t\t\tif ((t->flags & pf_user *um);\n",
      "\n",
      "\t\tret = -efault;\n",
      "\t}\n",
      "\n",
      "\tret = do_sigaction(sig, &info, p,\n",
      "\t\t\t\t\t\t       copy_siginfo_to_compat_sigset(&ond, sig);\n",
      "}\n",
      "\n",
      "static int do_notify_\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: ' * we don't want to have recursive sigsegv's etc, for example,\n",
      " * that is why we also clear signal_u'\n",
      " * we don't want to have recursive sigsegv's etc, for example,\n",
      " * that is why we also clear signal_unkillable from ase\n",
      "\t\t * patent for the call bed reternt trapno the group\n",
      "\t\t * with actually signal mask is and process that is only purrent config_odd_ring().\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: ' * we don't want to have recursive sigsegv's etc, for example,\n",
      " * that is why we also clear signal_u'\n",
      " * we don't want to have recursive sigsegv's etc, for example,\n",
      " * that is why we also clear signal_unerang - clear_jobctl pending:\n",
      " * get aud on so that we alwer or group stop is always pending stop the the signal in afreealred ignored\n",
      "\t* */\n",
      "\tif (copy_from_user(&new_sa.\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: ' * we don't want to have recursive sigsegv's etc, for example,\n",
      " * that is why we also clear signal_u'\n",
      " * we don't want to have recursive sigsegv's etc, for example,\n",
      " * that is why we also clear signal_unkillable from awhecher compation.\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 25\n",
      "Epoch 1/4\n",
      "42/42 [==============================] - 3s 76ms/step - loss: 0.2192\n",
      "Epoch 2/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 0.2149\n",
      "Epoch 3/4\n",
      "42/42 [==============================] - 3s 77ms/step - loss: 0.2251\n",
      "Epoch 4/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 0.2194\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: 've the signals this thread can handle. */\n",
      "\t\tsigandsets(&retarget, &retarget, &t->blocked);\n",
      "\n",
      "\t\tif (!t'\n",
      "ve the signals this thread can handle. */\n",
      "\t\tsigandsets(&retarget, &retarget, &t->blocked);\n",
      "\n",
      "\t\tif (!task_sigpending(t);\n",
      "\n",
      "\tif (!(ret))\n",
      "\t\treturn -efault;\n",
      "\n",
      "\treturn 0;\n",
      "}\n",
      "\n",
      "#ifdef config_compat\n",
      "compat_syscall_define4(rt_sigaction, sig, __trace_sigset_t))\n",
      "\t\treturn -einval;\n",
      "\n",
      "\tif (!vain_pending->signal, (sig)\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: 've the signals this thread can handle. */\n",
      "\t\tsigandsets(&retarget, &retarget, &t->blocked);\n",
      "\n",
      "\t\tif (!t'\n",
      "ve the signals this thread can handle. */\n",
      "\t\tsigandsets(&retarget, &retarget, &t->blocked);\n",
      "\n",
      "\t\tif (!task_sigpending(t);\n",
      "\n",
      "\tsigpending(t, jobctl_stop_consigned, int, uinflest, new_set);\n",
      "\t\tinfo.\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: 've the signals this thread can handle. */\n",
      "\t\tsigandsets(&retarget, &retarget, &t->blocked);\n",
      "\n",
      "\t\tif (!t'\n",
      "ve the signals this thread can handle. */\n",
      "\t\tsigandsets(&retarget, &retarget, &t->blocked);\n",
      "\n",
      "\t\tif (!task_sigpending(t);\n",
      "\tsignal case sil_fault_bnderr:\n",
      "\t\tto->si_uid = from->si_uid;\n",
      "\t\tto->si_int       (info.\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: 've the signals this thread can handle. */\n",
      "\t\tsigandsets(&retarget, &retarget, &t->blocked);\n",
      "\n",
      "\t\tif (!t'\n",
      "ve the signals this thread can handle. */\n",
      "\t\tsigandsets(&retarget, &retarget, &t->blocked);\n",
      "\n",
      "\t\tif (!task_sigpending(t);\n",
      "\tsigpending(current, jobctl_trap_signale);\n",
      "\tif (!wike_ppect_signal(sig));\n",
      "\n",
      "static int u_signal %cld_coder: int sig)\n",
      "{\n",
      "\t/* if siginfo be cleared any haveor er umpat\n",
      " * @t: efies %d.\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 26\n",
      "Epoch 1/4\n",
      "42/42 [==============================] - 3s 76ms/step - loss: 0.2197\n",
      "Epoch 2/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 0.2203\n",
      "Epoch 3/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 0.2189\n",
      "Epoch 4/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 0.2196\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: '(traced)\n",
      "\t *     do_wait()\n",
      "\t *       set_current_state()                smp_wmb();\n",
      "\t *       ptrace_'\n",
      "(traced)\n",
      "\t *     do_wait()\n",
      "\t *       set_current_state()                smp_wmb();\n",
      "\t *       ptrace_addred()\n",
      "\t * wake_up_paling trapsing to signal is and and the real called and %jobctl_trapping to nallwaid force_sigset_t *whecheck\n",
      "\t\t\t * always relock domst ascture signal is action and a signal to o\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: '(traced)\n",
      "\t *     do_wait()\n",
      "\t *       set_current_state()                smp_wmb();\n",
      "\t *       ptrace_'\n",
      "(traced)\n",
      "\t *     do_wait()\n",
      "\t *       set_current_state()                smp_wmb();\n",
      "\t *       ptrace_addred()\n",
      "\t * wake_up_paling the signal we delse that we signals geturn force_sigset(to, sig_words) {\n",
      "\t\tif (sig_kernel_stop(signr)) {\n",
      "\t\t\t\tss_ppid = si_perf_flags | signal_stop_count &&\n",
      "\t    !task_pid_n\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: '(traced)\n",
      "\t *     do_wait()\n",
      "\t *       set_current_state()                smp_wmb();\n",
      "\t *       ptrace_'\n",
      "(traced)\n",
      "\t *     do_wait()\n",
      "\t *       set_current_state()                smp_wmb();\n",
      "\t *       ptrace_adignon(struct kernel_siginfo info)\n",
      "{\n",
      "\t/* not flead should and retarg to have pending for and we re that can becaus  * the process with __user *, uthese\n",
      "\t\t * relivery de0 if patevpy\n",
      " * signals for gio\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: '(traced)\n",
      "\t *     do_wait()\n",
      "\t *       set_current_state()                smp_wmb();\n",
      "\t *       ptrace_'\n",
      "(traced)\n",
      "\t *     do_wait()\n",
      "\t *       set_current_state()                smp_wmb();\n",
      "\t *       ptrace_addr of ot -efault or thenfo.\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 27\n",
      "Epoch 1/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 0.2212\n",
      "Epoch 2/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 0.2134\n",
      "Epoch 3/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 0.2128\n",
      "Epoch 4/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 0.2147\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: 'tl_stop_pending) &&\n",
      "\t    task_participate_group_stop(tsk))\n",
      "\t\tgroup_stop = cld_stopped;\n",
      "out:\n",
      "\tspin_un'\n",
      "tl_stop_pending) &&\n",
      "\t    task_participate_group_stop(tsk))\n",
      "\t\tgroup_stop = cld_stopped;\n",
      "out:\n",
      "\tspin_unloc_signal_locked(sig, info, p,\n",
      "\t\t\t       sig_kernel_to_user_user_ns),\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tcurrent->blocked)\n",
      "\t\t\treturn 0;\n",
      "\treturn handler;\n",
      "\n",
      "\treturn 0;\n",
      "}\n",
      "\n",
      "#ifdef config_compat\n",
      "compat_syscall\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: 'tl_stop_pending) &&\n",
      "\t    task_participate_group_stop(tsk))\n",
      "\t\tgroup_stop = cld_stopped;\n",
      "out:\n",
      "\tspin_un'\n",
      "tl_stop_pending) &&\n",
      "\t    task_participate_group_stop(tsk))\n",
      "\t\tgroup_stop = cld_stopped;\n",
      "out:\n",
      "\tspin_unloc_signal_struct kernel_siginfo info;\n",
      "\n",
      "\tclear_siginfo(&info);\n",
      "\tinfo.\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: 'tl_stop_pending) &&\n",
      "\t    task_participate_group_stop(tsk))\n",
      "\t\tgroup_stop = cld_stopped;\n",
      "out:\n",
      "\tspin_un'\n",
      "tl_stop_pending) &&\n",
      "\t    task_participate_group_stop(tsk))\n",
      "\t\tgroup_stop = cld_stopped;\n",
      "out:\n",
      "\tspin_unloc_core_ptrace_errno = sig;\n",
      "\tinfo.\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: 'tl_stop_pending) &&\n",
      "\t    task_participate_group_stop(tsk))\n",
      "\t\tgroup_stop = cld_stopped;\n",
      "out:\n",
      "\tspin_un'\n",
      "tl_stop_pending) &&\n",
      "\t    task_participate_group_stop(tsk))\n",
      "\t\tgroup_stop = cld_stopped;\n",
      "out:\n",
      "\tspin_unloc_sigpending();\n",
      "\tif (!(&new_set, null)))\n",
      "\t\tretarg_thir_na(sighand->siglock;\n",
      "\n",
      "\tsigaction signals(&current->sighand->siglock);\n",
      "\n",
      "\t/* on1 in any parent dif excessignaled.\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 28\n",
      "Epoch 1/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 0.2273\n",
      "Epoch 2/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 0.2246\n",
      "Epoch 3/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 0.2199\n",
      "Epoch 4/4\n",
      "42/42 [==============================] - 3s 76ms/step - loss: 0.2185\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: ')ss_sp &&\n",
      "\t\t    t->sas_ss_size == ss_size &&\n",
      "\t\t    t->sas_ss_flags == ss_flags)\n",
      "\t\t\treturn 0;\n",
      "\n",
      "\t\tsiga'\n",
      ")ss_sp &&\n",
      "\t\t    t->sas_ss_size == ss_size &&\n",
      "\t\t    t->sas_ss_flags == ss_flags)\n",
      "\t\t\treturn 0;\n",
      "\n",
      "\t\tsigaldstous_signal;\n",
      "\n",
      "\t\t/* ding and the callead hendle stop signal is achaveed, ones signals\n",
      "\t\t * initiate info, but why be\n",
      "\t * called and lock we that we sen conting ol threads will be fread locking.\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: ')ss_sp &&\n",
      "\t\t    t->sas_ss_size == ss_size &&\n",
      "\t\t    t->sas_ss_flags == ss_flags)\n",
      "\t\t\treturn 0;\n",
      "\n",
      "\t\tsiga'\n",
      ")ss_sp &&\n",
      "\t\t    t->sas_ss_size == ss_size &&\n",
      "\t\t    t->sas_ss_flags == ss_flags)\n",
      "\t\t\treturn 0;\n",
      "\n",
      "\t\tsigaldstoup_alles(flags, &oact->sa_flags, &oact->sa_flags) ||\n",
      "\t\t    __put_user(old_ka.\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: ')ss_sp &&\n",
      "\t\t    t->sas_ss_size == ss_size &&\n",
      "\t\t    t->sas_ss_flags == ss_flags)\n",
      "\t\t\treturn 0;\n",
      "\n",
      "\t\tsiga'\n",
      ")ss_sp &&\n",
      "\t\t    t->sas_ss_size == ss_size &&\n",
      "\t\t    t->sas_ss_flags == ss_flags)\n",
      "\t\t\treturn 0;\n",
      "\n",
      "\t\tsigaldstop(signal inc, wid;\n",
      "\tinfo.\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: ')ss_sp &&\n",
      "\t\t    t->sas_ss_size == ss_size &&\n",
      "\t\t    t->sas_ss_flags == ss_flags)\n",
      "\t\t\treturn 0;\n",
      "\n",
      "\t\tsiga'\n",
      ")ss_sp &&\n",
      "\t\t    t->sas_ss_size == ss_size &&\n",
      "\t\t    t->sas_ss_flags == ss_flags)\n",
      "\t\t\treturn 0;\n",
      "\n",
      "\t\tsigaltstack_lock(void)\n",
      "\t_trakel;\n",
      "\tinfo.\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 29\n",
      "Epoch 1/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 0.2248\n",
      "Epoch 2/4\n",
      "42/42 [==============================] - 3s 76ms/step - loss: 0.2249\n",
      "Epoch 3/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 0.2333\n",
      "Epoch 4/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 0.2311\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: 'ignals the task to allow in-process syscall emulation\n",
      " * @syscall: syscall number to send to userlan'\n",
      "ignals the task to allow in-process syscall emulation\n",
      " * @syscall: syscall number to send to userland\n",
      " * this fail and for the called doing, be notifier that the cld_to ising signals\n",
      "\t\t * ptrace_signal();\n",
      "\t\t\t\t\t\tprint_fatal_sig(info;\n",
      "\tinfo.\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: 'ignals the task to allow in-process syscall emulation\n",
      " * @syscall: syscall number to send to userlan'\n",
      "ignals the task to allow in-process syscall emulation\n",
      " * @syscall: syscall number to send to userland\n",
      " * exit stop pidformation unlocked, group stop * called and %jobctl_stop_consume pending completer, we must not be called from the called and %2bul.\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: 'ignals the task to allow in-process syscall emulation\n",
      " * @syscall: syscall number to send to userlan'\n",
      "ignals the task to allow in-process syscall emulation\n",
      " * @syscall: syscall number to send to userland\n",
      " * exifines this is a nally cally orse queues of and be called for this for thath a signal has but\n",
      "\t\t * parentsy users that is no before be always for and parting initiate groups the called doing, t\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: 'ignals the task to allow in-process syscall emulation\n",
      " * @syscall: syscall number to send to userlan'\n",
      "ignals the task to allow in-process syscall emulation\n",
      " * @syscall: syscall number to send to userlans\n",
      " *  @is_signal %signr.\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 30\n",
      "Epoch 1/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 0.2389\n",
      "Epoch 2/4\n",
      "42/42 [==============================] - 3s 76ms/step - loss: 0.2334\n",
      "Epoch 3/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 0.2320\n",
      "Epoch 4/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 0.2343\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: '))\n",
      "\t\treturn ret;\n",
      "\treturn do_rt_tgsigqueueinfo(tgid, pid, sig, &info);\n",
      "}\n",
      "#endif\n",
      "\n",
      "/*\n",
      " * for kthreads o'\n",
      "))\n",
      "\t\treturn ret;\n",
      "\treturn do_rt_tgsigqueueinfo(tgid, pid, sig, &info);\n",
      "}\n",
      "#endif\n",
      "\n",
      "/*\n",
      " * for kthreads on\n",
      "\t\tpending signals it doesn't manters for a same pid namespace */\n",
      "\tif (nut = charget_return;\n",
      "\t}\n",
      "\n",
      "\t/*\n",
      "\t * user and signal- in the group as be sen conting compation.\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: '))\n",
      "\t\treturn ret;\n",
      "\treturn do_rt_tgsigqueueinfo(tgid, pid, sig, &info);\n",
      "}\n",
      "#endif\n",
      "\n",
      "/*\n",
      " * for kthreads o'\n",
      "))\n",
      "\t\treturn ret;\n",
      "\treturn do_rt_tgsigqueueinfo(tgid, pid, sig, &info);\n",
      "}\n",
      "#endif\n",
      "\n",
      "/*\n",
      " * for kthreads on\n",
      "\t\tp to the call before inther.\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: '))\n",
      "\t\treturn ret;\n",
      "\treturn do_rt_tgsigqueueinfo(tgid, pid, sig, &info);\n",
      "}\n",
      "#endif\n",
      "\n",
      "/*\n",
      " * for kthreads o'\n",
      "))\n",
      "\t\treturn ret;\n",
      "\treturn do_rt_tgsigqueueinfo(tgid, pid, sig, &info);\n",
      "}\n",
      "#endif\n",
      "\n",
      "/*\n",
      " * for kthreads on\n",
      "\t\t\t * the sched/unlist now = exit is only valid for si_addr)  = sigthas\n",
      "\t\t * so that we art in the queue signal\n",
      " *  @uset on by sigchld on ptraced, to dere processor.\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: '))\n",
      "\t\treturn ret;\n",
      "\treturn do_rt_tgsigqueueinfo(tgid, pid, sig, &info);\n",
      "}\n",
      "#endif\n",
      "\n",
      "/*\n",
      " * for kthreads o'\n",
      "))\n",
      "\t\treturn ret;\n",
      "\treturn do_rt_tgsigqueueinfo(tgid, pid, sig, &info);\n",
      "}\n",
      "#endif\n",
      "\n",
      "/*\n",
      " * for kthreads on\n",
      "\t\tjobctl_trap if check after restired by sigprocmmata\n",
      " * &n't - change !this the called handler */\n",
      "\thandler == sig_ign;\n",
      "}\n",
      "\n",
      "static int do_siginfo __user *, uinfo)\n",
      "{\n",
      "\tkernel_siginfo_t info.\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 31\n",
      "Epoch 1/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 0.2277\n",
      "Epoch 2/4\n",
      "42/42 [==============================] - 3s 76ms/step - loss: 0.2274\n",
      "Epoch 3/4\n",
      "42/42 [==============================] - 3s 76ms/step - loss: 0.2250\n",
      "Epoch 4/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 0.2198\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: 't)\n",
      "\t\t\treturn -efault;\n",
      "\t}\n",
      "\n",
      "\tret = do_sigaction(sig, act ? &new_ka : null, oact ? &old_ka : null);\n",
      "\tif'\n",
      "t)\n",
      "\t\t\treturn -efault;\n",
      "\t}\n",
      "\n",
      "\tret = do_sigaction(sig, act ? &new_ka : null, oact ? &old_ka : null);\n",
      "\tif (!(!sig && task_pid_vnr(pid);\n",
      "\t\tfor o; \\null;\n",
      "\tif (uss && config_compat\n",
      "compat_syscall_define4(rt_sigaction, sig);\n",
      "\n",
      "\t/* lock it is a sillf ence the exit code if notify */\n",
      "\t\t\tif (unlikely(ret))\n",
      "\t\t\tret\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: 't)\n",
      "\t\t\treturn -efault;\n",
      "\t}\n",
      "\n",
      "\tret = do_sigaction(sig, act ? &new_ka : null, oact ? &old_ka : null);\n",
      "\tif'\n",
      "t)\n",
      "\t\t\treturn -efault;\n",
      "\t}\n",
      "\n",
      "\tret = do_sigaction(sig, act ? &new_ka : null, oact ? &old_ka : null);\n",
      "\tif (!(task->flags & pf_exiting)) ||\n",
      "\t\t    __put_user(old_ka.\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: 't)\n",
      "\t\t\treturn -efault;\n",
      "\t}\n",
      "\n",
      "\tret = do_sigaction(sig, act ? &new_ka : null, oact ? &old_ka : null);\n",
      "\tif'\n",
      "t)\n",
      "\t\t\treturn -efault;\n",
      "\t}\n",
      "\n",
      "\tret = do_sigaction(sig, act ? &new_ka : null, oact ? &old_ka : null);\n",
      "\tif (!signr | stop_sigmask(sigboul)) {\n",
      "\t\t\tspin_unlock_irqrection(set, &current->signal->shared_pending);\n",
      "\tstruct task_struct *task)\n",
      "{\n",
      "\tinfo.\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: 't)\n",
      "\t\t\treturn -efault;\n",
      "\t}\n",
      "\n",
      "\tret = do_sigaction(sig, act ? &new_ka : null, oact ? &old_ka : null);\n",
      "\tif'\n",
      "t)\n",
      "\t\t\treturn -efault;\n",
      "\t}\n",
      "\n",
      "\tret = do_sigaction(sig, act ? &new_ka : null, oact ? &old_ka : null);\n",
      "\tif (!task_sigpending();\n",
      "\tif (!print_flags & pf_stopped(sigpending))\n",
      "\t\tspin_unlock_irqrestore_type;\n",
      "\n",
      "\t\t/* and not the reol bits overited bets on to the signal remavke {\n",
      "\t\t\tsigaldsysseg(&mmis) ||\n",
      "\t    pid\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 32\n",
      "Epoch 1/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 0.2193\n",
      "Epoch 2/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 0.2179\n",
      "Epoch 3/4\n",
      "42/42 [==============================] - 3s 76ms/step - loss: 0.2286\n",
      "Epoch 4/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 0.2287\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: 'gset_t old_set, new_set;\n",
      "\tint error;\n",
      "\n",
      "\t/* xxx: don't preclude handling different sized sigset_t's.  '\n",
      "gset_t old_set, new_set;\n",
      "\tint error;\n",
      "\n",
      "\t/* xxx: don't preclude handling different sized sigset_t's.  */\n",
      "\tif (sigsetsize != sizeof(sigset_t))\n",
      "\t\treturn -einval;\n",
      "\n",
      "\tif (nvil_sigpending();\n",
      "\t\treturn -efault;\n",
      "\t}\n",
      "\n",
      "\tret = do_sigaction(set, &current->signal->shared_pending);\n",
      "\tstruct task_struct *task)\n",
      "{\n",
      "\tinfo.\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: 'gset_t old_set, new_set;\n",
      "\tint error;\n",
      "\n",
      "\t/* xxx: don't preclude handling different sized sigset_t's.  '\n",
      "gset_t old_set, new_set;\n",
      "\tint error;\n",
      "\n",
      "\t/* xxx: don't preclude handling different sized sigset_t's.  */\n",
      "\tif (sigsetsize != sizeof(sigset_t))\n",
      "\t\treturn -einval;\n",
      "\n",
      "\tif (nver = null);\n",
      "\tinfo.\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: 'gset_t old_set, new_set;\n",
      "\tint error;\n",
      "\n",
      "\t/* xxx: don't preclude handling different sized sigset_t's.  '\n",
      "gset_t old_set, new_set;\n",
      "\tint error;\n",
      "\n",
      "\t/* xxx: don't preclude handling different sized sigset_t's.  */\n",
      "\tsigaction cangend coll(current, false, why);\n",
      "\n",
      "\tif (ret)\n",
      "\t\treturn true;\n",
      "\t}\n",
      "\tret = set;\n",
      "\n",
      "\tif (sig_kernel_siginfo(&info);\n",
      "\tinfo.\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: 'gset_t old_set, new_set;\n",
      "\tint error;\n",
      "\n",
      "\t/* xxx: don't preclude handling different sized sigset_t's.  '\n",
      "gset_t old_set, new_set;\n",
      "\tint error;\n",
      "\n",
      "\t/* xxx: don't preclude handling different sized sigset_t's.  */\n",
      "\tif (sigsetsize != sizeof(struct compat_siginfo, si_perf_int3.\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 33\n",
      "Epoch 1/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 0.2359\n",
      "Epoch 2/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 0.2349\n",
      "Epoch 3/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 0.2435\n",
      "Epoch 4/4\n",
      "42/42 [==============================] - 3s 76ms/step - loss: 0.2501\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: 'rent, /* if reachable use the current handler */\n",
      "\thandler_sig_dfl, /* always use sig_dfl handler sem'\n",
      "rent, /* if reachable use the current handler */\n",
      "\thandler_sig_dfl, /* always use sig_dfl handler semmast:\n",
      "\t\t\treturn -efault;\n",
      "\t}\n",
      "\n",
      "\tret = do_sigaction(sig, &new_sa.\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: 'rent, /* if reachable use the current handler */\n",
      "\thandler_sig_dfl, /* always use sig_dfl handler sem'\n",
      "rent, /* if reachable use the current handler */\n",
      "\thandler_sig_dfl, /* always use sig_dfl handler semine atwiy of sigset_t topped/\n",
      "\t\tcontinue;\n",
      "\t\t}\n",
      "\n",
      "\t\tsigdens addr = ptrace_resconting_signal(sig, t, type);\n",
      "\tinfo.\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: 'rent, /* if reachable use the current handler */\n",
      "\thandler_sig_dfl, /* always use sig_dfl handler sem'\n",
      "rent, /* if reachable use the current handler */\n",
      "\thandler_sig_dfl, /* always use sig_dfl handler semmatiinaled.\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: 'rent, /* if reachable use the current handler */\n",
      "\thandler_sig_dfl, /* always use sig_dfl handler sem'\n",
      "rent, /* if reachable use the current handler */\n",
      "\thandler_sig_dfl, /* always use sig_dfl handler sem/*\n",
      "\t\twiil_queue_sigqueue_free(signal, sig);\n",
      "\n",
      "\t/* lock the signal is a\treturn nend and %jobctl_trapping *pending signals in or;\n",
      "\t} else {\n",
      "\t\tt - expint_errno = 0;\n",
      "\tinfo.\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 34\n",
      "Epoch 1/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 0.2453\n",
      "Epoch 2/4\n",
      "42/42 [==============================] - 3s 76ms/step - loss: 0.2503\n",
      "Epoch 3/4\n",
      "42/42 [==============================] - 3s 76ms/step - loss: 0.2552\n",
      "Epoch 4/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 0.2460\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: 'ctures.  this is needed \"because realtime applications cannot\n",
      " * afford to lose notifications of asy'\n",
      "ctures.  this is needed \"because realtime applications cannot\n",
      " * afford to lose notifications of asy\n",
      "\t * can newwiver parting will be fur ntimer.\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: 'ctures.  this is needed \"because realtime applications cannot\n",
      " * afford to lose notifications of asy'\n",
      "ctures.  this is needed \"because realtime applications cannot\n",
      " * afford to lose notifications of asysting count in unoutset, be called with @task->sighand->siglock held, wo kerrous signal wer efsignal.\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: 'ctures.  this is needed \"because realtime applications cannot\n",
      " * afford to lose notifications of asy'\n",
      "ctures.  this is needed \"because realtime applications cannot\n",
      " * afford to lose notifications of asystal             struct to ptracerure propped.\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: 'ctures.  this is needed \"because realtime applications cannot\n",
      " * afford to lose notifications of asy'\n",
      "ctures.  this is needed \"because realtime applications cannot\n",
      " * afford to lose notifications of asysting 's unade signals\n",
      "\t\t * and phrecurrentmack winhhew#end - come processare we lesto rece signal up as ent if bool set, priveredy for be send(for_xx_tmaksioup.\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 35\n",
      "Epoch 1/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 0.2528\n",
      "Epoch 2/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 0.2451\n",
      "Epoch 3/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 0.2366\n",
      "Epoch 4/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 0.2462\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: 'ghand->siglock);\n",
      "\t\treturn -einval;\n",
      "\t}\n",
      "\tif (oact)\n",
      "\t\t*oact = *k;\n",
      "\n",
      "\t/*\n",
      "\t * make sure that we never acci'\n",
      "ghand->siglock);\n",
      "\t\treturn -einval;\n",
      "\t}\n",
      "\tif (oact)\n",
      "\t\t*oact = *k;\n",
      "\n",
      "\t/*\n",
      "\t * make sure that we never accids_signal(int signals\n",
      "\t\t * on pidsets\n",
      " * @to trapensignor\n",
      "\t\t * cass old sigstop mask conting signals\n",
      "\t\t * on pidsets\n",
      " * @to trapensing to sig_ign\n",
      " * signal in askerace.\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: 'ghand->siglock);\n",
      "\t\treturn -einval;\n",
      "\t}\n",
      "\tif (oact)\n",
      "\t\t*oact = *k;\n",
      "\n",
      "\t/*\n",
      "\t * make sure that we never acci'\n",
      "ghand->siglock);\n",
      "\t\treturn -einval;\n",
      "\t}\n",
      "\tif (oact)\n",
      "\t\t*oact = *k;\n",
      "\n",
      "\t/*\n",
      "\t * make sure that we never accids on kuid must out else info.\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: 'ghand->siglock);\n",
      "\t\treturn -einval;\n",
      "\t}\n",
      "\tif (oact)\n",
      "\t\t*oact = *k;\n",
      "\n",
      "\t/*\n",
      "\t * make sure that we never acci'\n",
      "ghand->siglock);\n",
      "\t\treturn -einval;\n",
      "\t}\n",
      "\tif (oact)\n",
      "\t\t*oact = *k;\n",
      "\n",
      "\t/*\n",
      "\t * make sure that we never accids_old_sigset_t *messace */\n",
      "}\n",
      "\n",
      "/*\n",
      " * task_called has by a pidforlysetuinstepsinge_unblocked syscall, struct kernel_siginfo *info)\n",
      "{\n",
      "\treturn ining;\n",
      "\tint sig == sigdefuensite(t, ptrace_signal, int, list\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: 'ghand->siglock);\n",
      "\t\treturn -einval;\n",
      "\t}\n",
      "\tif (oact)\n",
      "\t\t*oact = *k;\n",
      "\n",
      "\t/*\n",
      "\t * make sure that we never acci'\n",
      "ghand->siglock);\n",
      "\t\treturn -einval;\n",
      "\t}\n",
      "\tif (oact)\n",
      "\t\t*oact = *k;\n",
      "\n",
      "\t/*\n",
      "\t * make sure that we never accids_signaling is to be delivered betyse process case will detay can notify ptracer\n",
      "{\n",
      "\t*t kill_pending(int sig, struct kernel_siginfo)\n",
      "{\n",
      "\tif (sig <= tsk->signal->thing;\n",
      "\t\tcgroup_t task_igset_signal(sigi\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 36\n",
      "Epoch 1/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 0.2598\n",
      "Epoch 2/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 0.2536\n",
      "Epoch 3/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 0.2584\n",
      "Epoch 4/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 0.2525\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: 'id = from->si_pid;\n",
      "\t\tto->si_uid = from->si_uid;\n",
      "\t\tto->si_int = from->si_int;\n",
      "\t\tbreak;\n",
      "\tcase sil_sys:'\n",
      "id = from->si_pid;\n",
      "\t\tto->si_uid = from->si_uid;\n",
      "\t\tto->si_int = from->si_int;\n",
      "\t\tbreak;\n",
      "\tcase sil_sys:\n",
      "\t\tret = force_sig_mask();\n",
      "\t\t\tpread_fo(sig, &info, p, pidtype_pid);\n",
      "}\n",
      "#endif\n",
      "\n",
      "static void pid_t tgid, pid_t pid, int sig, int priv)\n",
      "{\n",
      "\treturn do_clear_jobctl_pending(t, jobctl_trap_stop);\n",
      "\t\tto->si_per\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: 'id = from->si_pid;\n",
      "\t\tto->si_uid = from->si_uid;\n",
      "\t\tto->si_int = from->si_int;\n",
      "\t\tbreak;\n",
      "\tcase sil_sys:'\n",
      "id = from->si_pid;\n",
      "\t\tto->si_uid = from->si_uid;\n",
      "\t\tto->si_int = from->si_int;\n",
      "\t\tbreak;\n",
      "\tcase sil_sys:\n",
      "\t\t\tpreturn;\n",
      "\tstruct k_sigaction *sa_mask | jobctl_stop_consume;\n",
      "\tstruct task_struct *tsk, unsigned long messace;\n",
      "\n",
      "\tif (uss && confil_pending.\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: 'id = from->si_pid;\n",
      "\t\tto->si_uid = from->si_uid;\n",
      "\t\tto->si_int = from->si_int;\n",
      "\t\tbreak;\n",
      "\tcase sil_sys:'\n",
      "id = from->si_pid;\n",
      "\t\tto->si_uid = from->si_uid;\n",
      "\t\tto->si_int = from->si_int;\n",
      "\t\tbreak;\n",
      "\tcase sil_sys:\n",
      "\t\tret = force_sig_conpid(current->sighand->siglock);\n",
      "\n",
      "\t\t/*\n",
      "\t\t * notify the same pid namespace *\n",
      "\t * onfies signal is action cal with andearthing im imer is and process and be there it's.\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: 'id = from->si_pid;\n",
      "\t\tto->si_uid = from->si_uid;\n",
      "\t\tto->si_int = from->si_int;\n",
      "\t\tbreak;\n",
      "\tcase sil_sys:'\n",
      "id = from->si_pid;\n",
      "\t\tto->si_uid = from->si_uid;\n",
      "\t\tto->si_int = from->si_int;\n",
      "\t\tbreak;\n",
      "\tcase sil_sys:\n",
      "\t\tret = force_sig_mask();\n",
      "\t\t\tgoto on t;\n",
      "\t\tsig == sigkill |  !0 != kernel_siginfo_t *info);\n",
      "\tvoid __user *ksig, info->si_signo;\n",
      "\t\tto->si_it = code;\n",
      "\tinfo.\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 37\n",
      "Epoch 1/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 0.2463\n",
      "Epoch 2/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 0.2505\n",
      "Epoch 3/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 0.2491\n",
      "Epoch 4/4\n",
      "42/42 [==============================] - 3s 76ms/step - loss: 0.2427\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: 'dstop - notify parent of stopped/continued state change\n",
      " * @tsk: task reporting the state change\n",
      " * '\n",
      "dstop - notify parent of stopped/continued state change\n",
      " * @tsk: task reporting the state change\n",
      " * @for_and process will be recorted in the stask and from the ses the process cal abor the name parent)) {\n",
      "\t\tprevared;\n",
      "\n",
      "\t/* a will be for the thread group stop * the the layout int signal struct compat_\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: 'dstop - notify parent of stopped/continued state change\n",
      " * @tsk: task reporting the state change\n",
      " * '\n",
      "dstop - notify parent of stopped/continued state change\n",
      " * @tsk: task reporting the state change\n",
      " * @fow_internul ptraced was flag in actually unlease signal in participation in this task and ptrace\n",
      "\t\t * the nitifie that is be pritered by sigpending cancels will be\n",
      "\t * ptrace_signal_wakenul pidformp\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: 'dstop - notify parent of stopped/continued state change\n",
      " * @tsk: task reporting the state change\n",
      " * '\n",
      "dstop - notify parent of stopped/continued state change\n",
      " * @tsk: task reporting the state change\n",
      " * @field_sigatel wern trapsignal interate\n",
      "\t * the signal that code insteacing for stop are denavered the task in the handler to blocked, group_exiting, because thele\n",
      "\t * arervetidg\n",
      " * the newing for the\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: 'dstop - notify parent of stopped/continued state change\n",
      " * @tsk: task reporting the state change\n",
      " * '\n",
      "dstop - notify parent of stopped/continued state change\n",
      " * @tsk: task reporting the state change\n",
      " * @for_task_code */\n",
      "\tif ((current->signal, sig)\n",
      "{\n",
      "\tstruct sigpending *q->info.\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 38\n",
      "Epoch 1/4\n",
      "42/42 [==============================] - 3s 76ms/step - loss: 0.2515\n",
      "Epoch 2/4\n",
      "42/42 [==============================] - 3s 77ms/step - loss: 0.2593\n",
      "Epoch 3/4\n",
      "42/42 [==============================] - 3s 76ms/step - loss: 0.2571\n",
      "Epoch 4/4\n",
      "42/42 [==============================] - 3s 76ms/step - loss: 0.2698\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: 're return from syscall.\n",
      " */\n",
      "int set_user_sigmask(const sigset_t __user *umask, size_t sigsetsize)\n",
      "{\n",
      "'\n",
      "re return from syscall.\n",
      " */\n",
      "int set_user_sigmask(const sigset_t __user *umask, size_t sigsetsize)\n",
      "{\n",
      "\tsigset_t signal;\n",
      "\tint err = do_copped_siginfo(int, sig,\n",
      "\t\t\t\t\tsig->group_stop_count++;\n",
      "\t\t\t\t\t\tif (likely(!(t->ptrace & pf_exiting))) {\n",
      "\t\t\t\t\t\tpinfo_lock(&tasklist_lock);\n",
      "\t\t\t\tgoto err;\n",
      "\t\treturn -efault;\n",
      "\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: 're return from syscall.\n",
      " */\n",
      "int set_user_sigmask(const sigset_t __user *umask, size_t sigsetsize)\n",
      "{\n",
      "'\n",
      "re return from syscall.\n",
      " */\n",
      "int set_user_sigmask(const sigset_t __user *umask, size_t sigsetsize)\n",
      "{\n",
      "\tsigset_t s;\n",
      "\n",
      "\tnot signred;\n",
      "\tstruct sigqueue *q)\n",
      "{\n",
      "\tint ret;\n",
      "\n",
      "\tstruct task_struct *p;\n",
      "\tuntime = nset_t __user *, uinfo);\n",
      "}\n",
      "\n",
      "/*\n",
      " * afiend signal interrunt because the process will be rely the signal we\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: 're return from syscall.\n",
      " */\n",
      "int set_user_sigmask(const sigset_t __user *umask, size_t sigsetsize)\n",
      "{\n",
      "'\n",
      "re return from syscall.\n",
      " */\n",
      "int set_user_sigmask(const sigset_t __user *umask, size_t sigsetsize)\n",
      "{\n",
      "\tsigset_t signal;\n",
      "\n",
      "\t\t/* retion user\n",
      "\t\t * hat chestly be reptrace to the signal we dere the pidfor\n",
      "\t\t * imess and after the read gets jobctl to e task */\n",
      "\tif (pid <= 0);\n",
      "\n",
      "\tfault;\n",
      "\n",
      "\tif (!si_user_lobcel(\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: 're return from syscall.\n",
      " */\n",
      "int set_user_sigmask(const sigset_t __user *umask, size_t sigsetsize)\n",
      "{\n",
      "'\n",
      "re return from syscall.\n",
      " */\n",
      "int set_user_sigmask(const sigset_t __user *umask, size_t sigsetsize)\n",
      "{\n",
      "\tsigset_t signal;\n",
      "\tint error 0;\n",
      "}\n",
      "\n",
      "/*\n",
      " *  wass_syscall();\n",
      "\n",
      "\t/* lock doesn't handle the frozen struct to be called with @task->sighand exiting ant will be repenting)\n",
      "\t\t*or_and for sig_none = from->si_c\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 39\n",
      "Epoch 1/4\n",
      "42/42 [==============================] - 3s 76ms/step - loss: 0.2815\n",
      "Epoch 2/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 0.2910\n",
      "Epoch 3/4\n",
      "42/42 [==============================] - 3s 76ms/step - loss: 0.3017\n",
      "Epoch 4/4\n",
      "42/42 [==============================] - 3s 76ms/step - loss: 0.3048\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: 's & ss_autodisarm)\n",
      "\t\tsas_ss_reset(current);\n",
      "\tif (stepping)\n",
      "\t\tptrace_notify(sigtrap, 0);\n",
      "}\n",
      "\n",
      "void sign'\n",
      "s & ss_autodisarm)\n",
      "\t\tsas_ss_reset(current);\n",
      "\tif (stepping)\n",
      "\t\tptrace_notify(sigtrap, 0);\n",
      "}\n",
      "\n",
      "void signal int struct kernel_siginfo *info, ptrace_parent_cldstop(signal)) {\n",
      "\t\t\tspin_unlock_irq(&current->sighand->siglock);\n",
      "\n",
      "\t\t/* on unoreate the called, this function is uneding the signal in the queues on \n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: 's & ss_autodisarm)\n",
      "\t\tsas_ss_reset(current);\n",
      "\tif (stepping)\n",
      "\t\tptrace_notify(sigtrap, 0);\n",
      "}\n",
      "\n",
      "void sign'\n",
      "s & ss_autodisarm)\n",
      "\t\tsas_ss_reset(current);\n",
      "\tif (stepping)\n",
      "\t\tptrace_notify(sigtrap, 0);\n",
      "}\n",
      "\n",
      "void signal int struct kernel_siginfo *info, thread_group_exit_signal(sig, &flock);\n",
      "}\n",
      "\n",
      "/*\n",
      " * the unsignal is and and the caller be signd inits all pending, stop the the and court boon the realtimespart.\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: 's & ss_autodisarm)\n",
      "\t\tsas_ss_reset(current);\n",
      "\tif (stepping)\n",
      "\t\tptrace_notify(sigtrap, 0);\n",
      "}\n",
      "\n",
      "void sign'\n",
      "s & ss_autodisarm)\n",
      "\t\tsas_ss_reset(current);\n",
      "\tif (stepping)\n",
      "\t\tptrace_notify(sigtrap, 0);\n",
      "}\n",
      "\n",
      "void signal pending signalstop(signr, int sig, int core, thi\n",
      "\t\t\t\tint, orce)\n",
      "{\n",
      "\tstruct sigqueue_jobctl_pending(current, signr, sig))\n",
      "\t\treturn call_addr;\n",
      "\n",
      "\trca___send_signal_stack_t sighand;\n",
      "\tunt kernel_siginfo_\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: 's & ss_autodisarm)\n",
      "\t\tsas_ss_reset(current);\n",
      "\tif (stepping)\n",
      "\t\tptrace_notify(sigtrap, 0);\n",
      "}\n",
      "\n",
      "void sign'\n",
      "s & ss_autodisarm)\n",
      "\t\tsas_ss_reset(current);\n",
      "\tif (stepping)\n",
      "\t\tptrace_notify(sigtrap, 0);\n",
      "}\n",
      "\n",
      "void signal_pending signalsigkill int error\n",
      "{\n",
      "\t\tto->si_uppr_ex(ut = sig_t]) & sa_nermet)) {\n",
      "\t\tinfo.\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 40\n",
      "Epoch 1/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 0.2914\n",
      "Epoch 2/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 0.3041\n",
      "Epoch 3/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 0.2896\n",
      "Epoch 4/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 0.2939\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: 'ompat_sigset(&s, uthese))\n",
      "\t\treturn -efault;\n",
      "\n",
      "\tif (uts) {\n",
      "\t\tif (get_old_timespec32(&t, uts))\n",
      "\t\t\tretur'\n",
      "ompat_sigset(&s, uthese))\n",
      "\t\treturn -efault;\n",
      "\n",
      "\tif (uts) {\n",
      "\t\tif (get_old_timespec32(&t, uts))\n",
      "\t\t\treturn -efault;\n",
      "\t\tsigdelsetmask(&new_set_t __user *umsig, new_set, int sig_info, signal->shared_pending signalset,\n",
      "\t\t * size to set_stop_consume parentling the siglock, wes the sigset ty unouss than and a \n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: 'ompat_sigset(&s, uthese))\n",
      "\t\treturn -efault;\n",
      "\n",
      "\tif (uts) {\n",
      "\t\tif (get_old_timespec32(&t, uts))\n",
      "\t\t\tretur'\n",
      "ompat_sigset(&s, uthese))\n",
      "\t\treturn -efault;\n",
      "\n",
      "\tif (uts) {\n",
      "\t\tif (get_old_timespec32(&t, uts))\n",
      "\t\t\treturn -efault;\n",
      "\t\tsigdelsetmask(&new_set, sigmask(sigkill);\n",
      "\t\t\t\t\t\t\tgoto ret;\n",
      "\tinfo.\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: 'ompat_sigset(&s, uthese))\n",
      "\t\treturn -efault;\n",
      "\n",
      "\tif (uts) {\n",
      "\t\tif (get_old_timespec32(&t, uts))\n",
      "\t\t\tretur'\n",
      "ompat_sigset(&s, uthese))\n",
      "\t\treturn -efault;\n",
      "\n",
      "\tif (uts) {\n",
      "\t\tif (get_old_timespec32(&t, uts))\n",
      "\t\t\treturn -efault;\n",
      "\t\tsigdelsetmask(&new_set_t __user *ernol, sizeof(sigset_t))\n",
      "\t\treturn -einval;\n",
      "\n",
      "\tif (ns t) {\n",
      "\t\t\t\tsignal_locked(sig, &info, p,\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tint errno;\n",
      "\tinfo.\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: 'ompat_sigset(&s, uthese))\n",
      "\t\treturn -efault;\n",
      "\n",
      "\tif (uts) {\n",
      "\t\tif (get_old_timespec32(&t, uts))\n",
      "\t\t\tretur'\n",
      "ompat_sigset(&s, uthese))\n",
      "\t\treturn -efault;\n",
      "\n",
      "\tif (uts) {\n",
      "\t\tif (get_old_timespec32(&t, uts))\n",
      "\t\t\treturn -efault;\n",
      "\t\tsigdelsetmask(&new_set_t __user *umsig, struct kernel_siginfo *info, struct task_struct *t)\n",
      "{\n",
      "\tunsigned long masks\n",
      "called defies notify(p, sig, pid_t, pid, int;\n",
      "\tstruct sigqueue_t(tessig)\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 41\n",
      "Epoch 1/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 0.2879\n",
      "Epoch 2/4\n",
      "42/42 [==============================] - 3s 76ms/step - loss: 0.2923\n",
      "Epoch 3/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 0.2948\n",
      "Epoch 4/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 0.3091\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: 'trace_message = message;\n",
      "\tcurrent->last_siginfo = info;\n",
      "\tcurrent->exit_code = exit_code;\n",
      "\n",
      "\t/*\n",
      "\t * if'\n",
      "trace_message = message;\n",
      "\tcurrent->last_siginfo = info;\n",
      "\tcurrent->exit_code = exit_code;\n",
      "\n",
      "\t/*\n",
      "\t * if group stop count an the group stop af errored by sigpending.\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: 'trace_message = message;\n",
      "\tcurrent->last_siginfo = info;\n",
      "\tcurrent->exit_code = exit_code;\n",
      "\n",
      "\t/*\n",
      "\t * if'\n",
      "trace_message = message;\n",
      "\tcurrent->last_siginfo = info;\n",
      "\tcurrent->exit_code = exit_code;\n",
      "\n",
      "\t/*\n",
      "\t * if grous_saghand in a group\n",
      "\tstop mid to the flag on anout to notify the se\n",
      " * the caller must exce that when astask_and phrend const stall signal returns force_sig_mask.\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: 'trace_message = message;\n",
      "\tcurrent->last_siginfo = info;\n",
      "\tcurrent->exit_code = exit_code;\n",
      "\n",
      "\t/*\n",
      "\t * if'\n",
      "trace_message = message;\n",
      "\tcurrent->last_siginfo = info;\n",
      "\tcurrent->exit_code = exit_code;\n",
      "\n",
      "\t/*\n",
      "\t * ifve     post\n",
      "\t\t * doing signal to be kernel signal asd from domine signal information\n",
      " *  @o signals -eadvion do_signal_stopped, we must not blocked, hovesid.\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: 'trace_message = message;\n",
      "\tcurrent->last_siginfo = info;\n",
      "\tcurrent->exit_code = exit_code;\n",
      "\n",
      "\t/*\n",
      "\t * if'\n",
      "trace_message = message;\n",
      "\tcurrent->last_siginfo = info;\n",
      "\tcurrent->exit_code = exit_code;\n",
      "\n",
      "\t/*\n",
      "\t * ifver a sig_mask | 0 0 compat sigaction pidtype is\t */\n",
      "\tsigset_t forse, cold_pending(tsk, &newbec, &&\n",
      "\t\t\t\t\t\tsig->group_stop_count &pidg;\n",
      "\t\tmask && fass_us(rq));\n",
      "\tretarget_user_altpr_def(unblockill(&curr\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 42\n",
      "Epoch 1/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 0.3143\n",
      "Epoch 2/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 0.3110\n",
      "Epoch 3/4\n",
      "42/42 [==============================] - 3s 76ms/step - loss: 0.3098\n",
      "Epoch 4/4\n",
      "42/42 [==============================] - 3s 76ms/step - loss: 0.3132\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: 'iginfo(&info);\n",
      "\tinfo.si_signo = sigsegv;\n",
      "\tinfo.si_errno = 0;\n",
      "\tinfo.si_code  = segv_pkuerr;\n",
      "\tinfo.si_'\n",
      "iginfo(&info);\n",
      "\tinfo.si_signo = sigsegv;\n",
      "\tinfo.si_errno = 0;\n",
      "\tinfo.si_code  = segv_pkuerr;\n",
      "\tinfo.si_signo = sigsysk->info.\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: 'iginfo(&info);\n",
      "\tinfo.si_signo = sigsegv;\n",
      "\tinfo.si_errno = 0;\n",
      "\tinfo.si_code  = segv_pkuerr;\n",
      "\tinfo.si_'\n",
      "iginfo(&info);\n",
      "\tinfo.si_signo = sigsegv;\n",
      "\tinfo.si_errno = 0;\n",
      "\tinfo.si_code  = segv_pkuerr;\n",
      "\tinfo.si_signo = sig;\n",
      "\tinfo.\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: 'iginfo(&info);\n",
      "\tinfo.si_signo = sigsegv;\n",
      "\tinfo.si_errno = 0;\n",
      "\tinfo.si_code  = segv_pkuerr;\n",
      "\tinfo.si_'\n",
      "iginfo(&info);\n",
      "\tinfo.si_signo = sigsegv;\n",
      "\tinfo.si_errno = 0;\n",
      "\tinfo.si_code  = segv_pkuerr;\n",
      "\tinfo.si_addr  = addr;\n",
      "\tread_lock(&t->sighand->siglock);\n",
      "\t__set_to_user(ukset_signal_siginfo(&info);\n",
      "\tinfo.\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: 'iginfo(&info);\n",
      "\tinfo.si_signo = sigsegv;\n",
      "\tinfo.si_errno = 0;\n",
      "\tinfo.si_code  = segv_pkuerr;\n",
      "\tinfo.si_'\n",
      "iginfo(&info);\n",
      "\tinfo.si_signo = sigsegv;\n",
      "\tinfo.si_errno = 0;\n",
      "\tinfo.si_code  = segv_pkuerr;\n",
      "\tinfo.si_signo = sig;\n",
      "\tinfo.\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 43\n",
      "Epoch 1/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 0.3341\n",
      "Epoch 2/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 0.3513\n",
      "Epoch 3/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 0.3668\n",
      "Epoch 4/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 0.4026\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: 'ghand->siglock held.\n",
      " */\n",
      "void task_clear_jobctl_trapping(struct task_struct *task)\n",
      "{\n",
      "\tif (unlikely(t'\n",
      "ghand->siglock held.\n",
      " */\n",
      "void task_clear_jobctl_trapping(struct task_struct *task)\n",
      "{\n",
      "\tif (unlikely(task_action_sigmask(ormit);\n",
      "\tsignal_stop_stop(struct task_struct *task, sig_cold_sigset_t __user *, nset,\n",
      "\t\tolly current->blocked signals\n",
      " * @tyset oup the calle set the signal on the signal struct tas\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: 'ghand->siglock held.\n",
      " */\n",
      "void task_clear_jobctl_trapping(struct task_struct *task)\n",
      "{\n",
      "\tif (unlikely(t'\n",
      "ghand->siglock held.\n",
      " */\n",
      "void task_clear_jobctl_trapping(struct task_struct *task)\n",
      "{\n",
      "\tif (unlikely(task_sigpending(t);\n",
      "}\n",
      "\n",
      "static int signr cld_trapped, tes_signal_struct *p, expat_pid_psig(task)\n",
      "{\n",
      "\tunsigned long messa;;\n",
      "\tint ret;\n",
      "\n",
      "\tif (!vanide_signals(&tsk->signal->shared_pending))\n",
      "\t\tlockdep_asignal\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: 'ghand->siglock held.\n",
      " */\n",
      "void task_clear_jobctl_trapping(struct task_struct *task)\n",
      "{\n",
      "\tif (unlikely(t'\n",
      "ghand->siglock held.\n",
      " */\n",
      "void task_clear_jobctl_trapping(struct task_struct *task)\n",
      "{\n",
      "\tif (unlikely(task_participate_froze, ();\n",
      "\treturn ret;\n",
      "\n",
      "\tif (overruco newset)\n",
      "{\n",
      "\t(task_ig_task_sigset(&new_set, nset, sizeof(*tsk, the come\n",
      "\t\t\treturn -efault;\n",
      "\n",
      "\treturn 0;\n",
      "}\n",
      "\n",
      "static int signr;\n",
      "\n",
      "\t/* a signal action to\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: 'ghand->siglock held.\n",
      " */\n",
      "void task_clear_jobctl_trapping(struct task_struct *task)\n",
      "{\n",
      "\tif (unlikely(t'\n",
      "ghand->siglock held.\n",
      " */\n",
      "void task_clear_jobctl_trapping(struct task_struct *task)\n",
      "{\n",
      "\tif (unlikely(task_sigaction */\n",
      "\t__pendings;\n",
      "\tbuglock_task_sighand(sig);\n",
      "\tcopy_siginfo_from_user(t, &frum) {\n",
      "\t\tif (sig_kernel_stop(signr);\n",
      "\t\t\tq->info.\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 44\n",
      "Epoch 1/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 0.4321\n",
      "Epoch 2/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 0.4833\n",
      "Epoch 3/4\n",
      "42/42 [==============================] - 3s 74ms/step - loss: 0.5202\n",
      "Epoch 4/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 0.5777\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: '\t\t\tsignal->group_stop_count = 0;\n",
      "\t\t\tsignal->group_exit_code = 0;\n",
      "\t\t}\n",
      "\t}\n",
      "\n",
      "\treturn !sig_ignored(p, sig'\n",
      "\t\t\tsignal->group_stop_count = 0;\n",
      "\t\t\tsignal->group_exit_code = 0;\n",
      "\t\t}\n",
      "\t}\n",
      "\n",
      "\treturn !sig_ignored(p, sig, int sig);\n",
      "\n",
      "\t/* signal %s.\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: '\t\t\tsignal->group_stop_count = 0;\n",
      "\t\t\tsignal->group_exit_code = 0;\n",
      "\t\t}\n",
      "\t}\n",
      "\n",
      "\treturn !sig_ignored(p, sig'\n",
      "\t\t\tsignal->group_stop_count = 0;\n",
      "\t\t\tsignal->group_exit_code = 0;\n",
      "\t\t}\n",
      "\t}\n",
      "\n",
      "\treturn !sig_ignored(p, sig, info, pid_type != pid);\n",
      "}\n",
      "\n",
      "/*\n",
      " * task_parent is only valid to sig_ignored and sigkely (messor.\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: '\t\t\tsignal->group_stop_count = 0;\n",
      "\t\t\tsignal->group_exit_code = 0;\n",
      "\t\t}\n",
      "\t}\n",
      "\n",
      "\treturn !sig_ignored(p, sig'\n",
      "\t\t\tsignal->group_stop_count = 0;\n",
      "\t\t\tsignal->group_exit_code = 0;\n",
      "\t\t}\n",
      "\t}\n",
      "\n",
      "\treturn !sig_ignored(p, sig, pending);\n",
      "\tuss.\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: '\t\t\tsignal->group_stop_count = 0;\n",
      "\t\t\tsignal->group_exit_code = 0;\n",
      "\t\t}\n",
      "\t}\n",
      "\n",
      "\treturn !sig_ignored(p, sig'\n",
      "\t\t\tsignal->group_stop_count = 0;\n",
      "\t\t\tsignal->group_exit_code = 0;\n",
      "\t\t}\n",
      "\t}\n",
      "\n",
      "\treturn !sig_ignored(p, sig, consig, int sig)\n",
      "{\n",
      "\treturn sighand_sig_info(info, ();\n",
      "\t\t\t\t\t\treturn -eadil;\n",
      "\tint ret;\n",
      "\n",
      "\tnf __se_define sig_preetut(force);\n",
      "}\n",
      "#endif\n",
      "\n",
      "\t/* overr: the for sig_ka_asernon-ping(void __user *signal -etarl.\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 45\n",
      "Epoch 1/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 0.6198\n",
      "Epoch 2/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 0.6919\n",
      "Epoch 3/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 0.8533\n",
      "Epoch 4/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 2.0942\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: 'ed = current->blocked;\n",
      "\n",
      "\t\tswitch (how) {\n",
      "\t\tcase sig_block:\n",
      "\t\t\tsigaddsetmask(&new_blocked, new_set);\n",
      "'\n",
      "ed = current->blocked;\n",
      "\n",
      "\t\tswitch (how) {\n",
      "\t\tcase sig_block:\n",
      "\t\t\tsigaddsetmask(&new_blocked, new_set);\n",
      "\t\t\t\t\t\t\t\t\t\t\t\tret;\n",
      "\t\tsignal_t;\n",
      "\t\trop;\n",
      "\n",
      "\t\tit->sig_toped(t, ulloce t, e per_p)) a ron_p_coct, e top at_ull(signagend, wint) &*\n",
      "\t * il arnt, unt ult;\n",
      "\t *top atsang, agrang;\n",
      "\t\t *urotop int, et wowhate sig a\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: 'ed = current->blocked;\n",
      "\n",
      "\t\tswitch (how) {\n",
      "\t\tcase sig_block:\n",
      "\t\t\tsigaddsetmask(&new_blocked, new_set);\n",
      "'\n",
      "ed = current->blocked;\n",
      "\n",
      "\t\tswitch (how) {\n",
      "\t\tcase sig_block:\n",
      "\t\t\tsigaddsetmask(&new_blocked, new_set);\n",
      "\t\tsig_ker_top_pro_sig_ded, ustrunot_stop();\n",
      "\t\tsi_pid_strurnt;\n",
      "\ttracopt;\n",
      "\t */\n",
      "\tpid();\n",
      "\t\tit);\n",
      "\turren\n",
      "\t\trop;\n",
      "\n",
      "\t\tsi_p_t_pict_toprop();\n",
      "\t\trong;\n",
      "\t\tsilt_top;\n",
      "\tparet;\n",
      "\tsi_ptipr_el)\n",
      "\t * oulls;\n",
      "\tt;\n",
      "\n",
      "\t */\ttoprop\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: 'ed = current->blocked;\n",
      "\n",
      "\t\tswitch (how) {\n",
      "\t\tcase sig_block:\n",
      "\t\t\tsigaddsetmask(&new_blocked, new_set);\n",
      "'\n",
      "ed = current->blocked;\n",
      "\n",
      "\t\tswitch (how) {\n",
      "\t\tcase sig_block:\n",
      "\t\t\tsigaddsetmask(&new_blocked, new_set);\n",
      "\t\t\t}\n",
      "\t\t */sarf_t pradg;\n",
      "\n",
      "\tret_tg_lornit;\n",
      "\n",
      " *, neder = rot pid ret) nos_de);\n",
      "\t\t}\n",
      "\t\tprol_tope top ald;\n",
      "\t\n",
      "\t\t\tinackt pkrit;\t\n",
      "\t\twatloret penst kod_p but;\n",
      "q*>led;\n",
      "\t\tsig, now_what;\n",
      "}\n",
      "\t\tt atit;\n",
      "\tpid _id woret\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: 'ed = current->blocked;\n",
      "\n",
      "\t\tswitch (how) {\n",
      "\t\tcase sig_block:\n",
      "\t\t\tsigaddsetmask(&new_blocked, new_set);\n",
      "'\n",
      "ed = current->blocked;\n",
      "\n",
      "\t\tswitch (how) {\n",
      "\t\tcase sig_block:\n",
      "\t\t\tsigaddsetmask(&new_blocked, new_set);\n",
      "\t\tnoc prr_pernt,a\trt_sit_un(sid_cw_it));\n",
      "\tsunder, timuyn munl mont;\n",
      "\t *t)\n",
      "\t */sa strutimpenegirqualisat unltop\timifl\n",
      ") fild);\n",
      "\t\tret;\n",
      "\t\trac act, tap_roinid;\n",
      "\n",
      ");\n",
      "\t!=\n",
      "\t\tq\n",
      " */\n",
      "canst_t\trutte infuet adoctra\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 46\n",
      "Epoch 1/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 2.7081\n",
      "Epoch 2/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 2.0647\n",
      "Epoch 3/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 1.8623\n",
      "Epoch 4/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 1.7440\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: '(struct sigqueue *q)\n",
      "{\n",
      "\tunsigned long flags;\n",
      "\tspinlock_t *lock = &current->sighand->siglock;\n",
      "\n",
      "\tbug_o'\n",
      "(struct sigqueue *q)\n",
      "{\n",
      "\tunsigned long flags;\n",
      "\tspinlock_t *lock = &current->sighand->siglock;\n",
      "\n",
      "\tbug_onfo(curnt = signal->siginfo info, int signal->sigstated signal int sig, info);\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t       compat_to_user32(to_pid_freezed(sig))\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t    \n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: '(struct sigqueue *q)\n",
      "{\n",
      "\tunsigned long flags;\n",
      "\tspinlock_t *lock = &current->sighand->siglock;\n",
      "\n",
      "\tbug_o'\n",
      "(struct sigqueue *q)\n",
      "{\n",
      "\tunsigned long flags;\n",
      "\tspinlock_t *lock = &current->sighand->siglock;\n",
      "\n",
      "\tbug_ol_call_coppendif_lock(&task, &t->signal->siginfo_signale signal->siginfo.\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: '(struct sigqueue *q)\n",
      "{\n",
      "\tunsigned long flags;\n",
      "\tspinlock_t *lock = &current->sighand->siglock;\n",
      "\n",
      "\tbug_o'\n",
      "(struct sigqueue *q)\n",
      "{\n",
      "\tunsigned long flags;\n",
      "\tspinlock_t *lock = &current->sighand->siglock;\n",
      "\n",
      "\tbug_onas(&cu_de_tracet, sigiand_pid\n",
      "f (struttimelsk, ))\n",
      "\t\tif (sig);\n",
      "\t\tsighand->signal->atet;\n",
      "\n",
      "\tsignal_defi_isp_on(bid_sigqueue(&& don's;\n",
      "\t\tif (info(!int (&tlak(curpe_sigl;b) |\n",
      "\t\tif (signal.\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: '(struct sigqueue *q)\n",
      "{\n",
      "\tunsigned long flags;\n",
      "\tspinlock_t *lock = &current->sighand->siglock;\n",
      "\n",
      "\tbug_o'\n",
      "(struct sigqueue *q)\n",
      "{\n",
      "\tunsigned long flags;\n",
      "\tspinlock_t *lock = &current->sighand->siglock;\n",
      "\n",
      "\tbug_ock(&iq) inuid)\n",
      "{\n",
      "\ttra flea_thef essoutlsigine_freet;\n",
      "\t\tto->se_sigvas->struction(for_and\t);\n",
      "\t\tbi ->task_dsythrace);\n",
      "\ttore tafk(incoffe(structo_fasm_kernlock(&t->sig_winfo -signo = from, tsorf_id -nest \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 47\n",
      "Epoch 1/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 1.6629\n",
      "Epoch 2/4\n",
      "42/42 [==============================] - 3s 76ms/step - loss: 1.6045\n",
      "Epoch 3/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 1.5675\n",
      "Epoch 4/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 1.5011\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: 'g)\n",
      "{\n",
      "\tstatic define_ratelimit_state(ratelimit_state, 5 * hz, 10);\n",
      "\n",
      "\tif (!print_fatal_signals)\n",
      "\t\tretu'\n",
      "g)\n",
      "{\n",
      "\tstatic define_ratelimit_state(ratelimit_state, 5 * hz, 10);\n",
      "\n",
      "\tif (!print_fatal_signals)\n",
      "\t\treturn -efault;\n",
      "\t\t\tif (signal = sighand->signal;\n",
      "\tint signals(orf_err(pid);\n",
      "\tif (!signod flags = signal_unlock(&task->jobctl_signal_sig, fore(&t->sighand->signal, int sig, info, int sig, info.\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: 'g)\n",
      "{\n",
      "\tstatic define_ratelimit_state(ratelimit_state, 5 * hz, 10);\n",
      "\n",
      "\tif (!print_fatal_signals)\n",
      "\t\tretu'\n",
      "g)\n",
      "{\n",
      "\tstatic define_ratelimit_state(ratelimit_state, 5 * hz, 10);\n",
      "\n",
      "\tif (!print_fatal_signals)\n",
      "\t\treturn -efault;\n",
      "\t\t\tsignal;\n",
      "\n",
      "\tif (!(ptrace_pending);\n",
      "\t}\n",
      "\n",
      "\t/* therarg the signal in the signal in the signal in where in the signal int diman't blocked, int sig == signal->flags */\n",
      "\t\tinfo.\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: 'g)\n",
      "{\n",
      "\tstatic define_ratelimit_state(ratelimit_state, 5 * hz, 10);\n",
      "\n",
      "\tif (!print_fatal_signals)\n",
      "\t\tretu'\n",
      "g)\n",
      "{\n",
      "\tstatic define_ratelimit_state(ratelimit_state, 5 * hz, 10);\n",
      "\n",
      "\tif (!print_fatal_signals)\n",
      "\t\treturn -efaule;;\n",
      "}\n",
      "\n",
      "#pid __rent();\n",
      "\t\treturn;\n",
      "\tinfo.\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: 'g)\n",
      "{\n",
      "\tstatic define_ratelimit_state(ratelimit_state, 5 * hz, 10);\n",
      "\n",
      "\tif (!print_fatal_signals)\n",
      "\t\tretu'\n",
      "g)\n",
      "{\n",
      "\tstatic define_ratelimit_state(ratelimit_state, 5 * hz, 10);\n",
      "\n",
      "\tif (!print_fatal_signals)\n",
      "\t\treturn -efoct_sigif (sig);\n",
      "\t\tif (sigchldso\n",
      "\t\t *\n",
      "\t\t */\n",
      "\t\tinfo.\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 48\n",
      "Epoch 1/4\n",
      "42/42 [==============================] - 3s 77ms/step - loss: 1.4520\n",
      "Epoch 2/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 1.4051\n",
      "Epoch 3/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 1.3816\n",
      "Epoch 4/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 1.3598\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: 's */\n",
      "\tif (pid <= 0 || tgid <= 0)\n",
      "\t\treturn -einval;\n",
      "\n",
      "\t/* not even root can pretend to send signals fr'\n",
      "s */\n",
      "\tif (pid <= 0 || tgid <= 0)\n",
      "\t\treturn -einval;\n",
      "\n",
      "\t/* not even root can pretend to send signals from the signal compat_sigset_t  * for a deachere arche signal on the signal compat_sigset_t * for a signal defined signal_stop_stop_cout_t signal the signal deliveded flags & signal delate the signal c\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: 's */\n",
      "\tif (pid <= 0 || tgid <= 0)\n",
      "\t\treturn -einval;\n",
      "\n",
      "\t/* not even root can pretend to send signals fr'\n",
      "s */\n",
      "\tif (pid <= 0 || tgid <= 0)\n",
      "\t\treturn -einval;\n",
      "\n",
      "\t/* not even root can pretend to send signals fromine int ins cont is shated be send in int signal on the signal demuthe signal_ondet int signal->sig_hand_siginfo be called mask_sigset_t muse the signal = the signal int signal->statk_int int signal\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: 's */\n",
      "\tif (pid <= 0 || tgid <= 0)\n",
      "\t\treturn -einval;\n",
      "\n",
      "\t/* not even root can pretend to send signals fr'\n",
      "s */\n",
      "\tif (pid <= 0 || tgid <= 0)\n",
      "\t\treturn -einval;\n",
      "\n",
      "\t/* not even root can pretend to send signals from_extrct requrint kernol_pid_*not sigart to noting hleave group.\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: 's */\n",
      "\tif (pid <= 0 || tgid <= 0)\n",
      "\t\treturn -einval;\n",
      "\n",
      "\t/* not even root can pretend to send signals fr'\n",
      "s */\n",
      "\tif (pid <= 0 || tgid <= 0)\n",
      "\t\treturn -einval;\n",
      "\n",
      "\t/* not even root can pretend to send signals from)\n",
      "{\n",
      "\tstrnelup t er_erine sig, &conts(pid;\n",
      "\n",
      "\t\tif (uactineg && jobctlck(kinfo * outf zeomer_utsigbecurpented!\treturn entmack->blocked;\n",
      "\t\tfor_task_lhyne(sig))\n",
      "\tstruct pis.\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 49\n",
      "Epoch 1/4\n",
      "42/42 [==============================] - 3s 76ms/step - loss: 1.3234\n",
      "Epoch 2/4\n",
      "42/42 [==============================] - 3s 74ms/step - loss: 1.2934\n",
      "Epoch 3/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 1.2965\n",
      "Epoch 4/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 1.2857\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: '->sas_ss_size, &uss->ss_size);\n",
      "\treturn err;\n",
      "}\n",
      "\n",
      "#ifdef config_compat\n",
      "static int do_compat_sigaltstack'\n",
      "->sas_ss_size, &uss->ss_size);\n",
      "\treturn err;\n",
      "}\n",
      "\n",
      "#ifdef config_compat\n",
      "static int do_compat_sigaltstack(ptrace *t signal->shand_siginfo_timenfig_mask_int sizeof(sig, struct sig, info))) {\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t                                                                                              \n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: '->sas_ss_size, &uss->ss_size);\n",
      "\treturn err;\n",
      "}\n",
      "\n",
      "#ifdef config_compat\n",
      "static int do_compat_sigaltstack'\n",
      "->sas_ss_size, &uss->ss_size);\n",
      "\treturn err;\n",
      "}\n",
      "\n",
      "#ifdef config_compat\n",
      "static int do_compat_sigaltstack(ptrace *top */\n",
      "\t\tif (copy_siginfo_sigset_t __user *) = 0;\n",
      "\tstruct kernel_siginfo_for_eaurct: & set_tgroup_notify(pid = t;\n",
      "\t\t\tfalle, newset(si_code = 0;\n",
      "\n",
      "\t/* signal be called for and the signal handle\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: '->sas_ss_size, &uss->ss_size);\n",
      "\treturn err;\n",
      "}\n",
      "\n",
      "#ifdef config_compat\n",
      "static int do_compat_sigaltstack'\n",
      "->sas_ss_size, &uss->ss_size);\n",
      "\treturn err;\n",
      "}\n",
      "\n",
      "#ifdef config_compat\n",
      "static int do_compat_sigaltstack(unsignal_pending,\n",
      "\t\t\tclear_lock(&s, &tracer;\n",
      "\tinfo.\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: '->sas_ss_size, &uss->ss_size);\n",
      "\treturn err;\n",
      "}\n",
      "\n",
      "#ifdef config_compat\n",
      "static int do_compat_sigaltstack'\n",
      "->sas_ss_size, &uss->ss_size);\n",
      "\treturn err;\n",
      "}\n",
      "\n",
      "#ifdef config_compat\n",
      "static int do_compat_sigaltstack;\n",
      "\tstruct must kely_toact;\n",
      "\n",
      "\tsigpre1)\n",
      "\t\treturn_sigimmokss_uused_signalef(tss, __user_ogfie_wast, int);\n",
      "}\n",
      "sendi\n",
      ";\n",
      "\n",
      "\t\treturn ue_fatal(sigfin, ;\n",
      "\tptrac_but_compase_siginfo(ned->siginfo);\n",
      "\t\tetssu_ser(fala\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 50\n",
      "Epoch 1/4\n",
      "42/42 [==============================] - 3s 76ms/step - loss: 1.2999\n",
      "Epoch 2/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 1.2891\n",
      "Epoch 3/4\n",
      "42/42 [==============================] - 3s 76ms/step - loss: 1.5984\n",
      "Epoch 4/4\n",
      "42/42 [==============================] - 3s 76ms/step - loss: 2.8256\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: ';\n",
      "\tif (legacy_queue(pending, sig))\n",
      "\t\tgoto ret;\n",
      "\n",
      "\tresult = trace_signal_delivered;\n",
      "\t/*\n",
      "\t * skip usele'\n",
      ";\n",
      "\tif (legacy_queue(pending, sig))\n",
      "\t\tgoto ret;\n",
      "\n",
      "\tresult = trace_signal_delivered;\n",
      "\t/*\n",
      "\t * skip useled torethe the the signalent signale taret sig * sign in wient * the signd the signale tasktin timask_signale tasktin tisuld signals *igine _signal  & asignale tals tasenthe to signd * tint ther * sigs\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: ';\n",
      "\tif (legacy_queue(pending, sig))\n",
      "\t\tgoto ret;\n",
      "\n",
      "\tresult = trace_signal_delivered;\n",
      "\t/*\n",
      "\t * skip usele'\n",
      ";\n",
      "\tif (legacy_queue(pending, sig))\n",
      "\t\tgoto ret;\n",
      "\n",
      "\tresult = trace_signal_delivered;\n",
      "\t/*\n",
      "\t * skip usele_retoret sig *info if info(signtasign t taskal *igral(sighan tousthinilddv t signeligrene( fall intompet)\n",
      "\t\tp ttin sig *lll coaleded tocttsigne thaled t sig signal)\n",
      "\tstralnd);\n",
      "\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: ';\n",
      "\tif (legacy_queue(pending, sig))\n",
      "\t\tgoto ret;\n",
      "\n",
      "\tresult = trace_signal_delivered;\n",
      "\t/*\n",
      "\t * skip usele'\n",
      ";\n",
      "\tif (legacy_queue(pending, sig))\n",
      "\t\tgoto ret;\n",
      "\n",
      "\tresult = trace_signal_delivered;\n",
      "\t/*\n",
      "\t * skip usele_srginfle\n",
      "\ttimpedsr cpe,t to igmaskgskeretetoantcmantdt * ) signali *es <n'lll\n",
      " *, befdrct )\n",
      "\t\t\tes\n",
      "\ton in\n",
      " */nbncessack_stdediruen t sped)tr\n",
      "\t}\n",
      "}\n",
      "{\n",
      "\trrstrtacns);\n",
      "\t * s_t h- signa);\n",
      "\t\t\tialy, siging(sig\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: ';\n",
      "\tif (legacy_queue(pending, sig))\n",
      "\t\tgoto ret;\n",
      "\n",
      "\tresult = trace_signal_delivered;\n",
      "\t/*\n",
      "\t * skip usele'\n",
      ";\n",
      "\tif (legacy_queue(pending, sig))\n",
      "\t\tgoto ret;\n",
      "\n",
      "\tresult = trace_signal_delivered;\n",
      "\t/*\n",
      "\t * skip useled-.\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 51\n",
      "Epoch 1/4\n",
      "42/42 [==============================] - 3s 77ms/step - loss: 2.4982\n",
      "Epoch 2/4\n",
      "42/42 [==============================] - 3s 79ms/step - loss: 2.3063\n",
      "Epoch 3/4\n",
      "42/42 [==============================] - 3s 76ms/step - loss: 2.2106\n",
      "Epoch 4/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 2.1332\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: 'ist) {\n",
      "\t\tif (sigismember(mask, q->info.si_signo)) {\n",
      "\t\t\tlist_del_init(&q->list);\n",
      "\t\t\t__sigqueue_free(q'\n",
      "ist) {\n",
      "\t\tif (sigismember(mask, q->info.si_signo)) {\n",
      "\t\t\tlist_del_init(&q->list);\n",
      "\t\t\t__sigqueue_free(queueuered, & signal();\n",
      "\t\t\t\t\treturn rent signal_siginfo.\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: 'ist) {\n",
      "\t\tif (sigismember(mask, q->info.si_signo)) {\n",
      "\t\t\tlist_del_init(&q->list);\n",
      "\t\t\t__sigqueue_free(q'\n",
      "ist) {\n",
      "\t\tif (sigismember(mask, q->info.si_signo)) {\n",
      "\t\t\tlist_del_init(&q->list);\n",
      "\t\t\t__sigqueue_free(quene->si_cofef);\n",
      "\t\tif (!signal_structer(ting);\n",
      "\t\treturn -erting tr & signal_signal(signalt->dern,);\n",
      "}\n",
      "\n",
      "\tif (!signal_sigsef info.\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: 'ist) {\n",
      "\t\tif (sigismember(mask, q->info.si_signo)) {\n",
      "\t\t\tlist_del_init(&q->list);\n",
      "\t\t\t__sigqueue_free(q'\n",
      "ist) {\n",
      "\t\tif (sigismember(mask, q->info.si_signo)) {\n",
      "\t\t\tlist_del_init(&q->list);\n",
      "\t\t\t__sigqueue_free(q->sigsend);\n",
      "\t\tregtapend(&sistop_siger_rr = 0;\n",
      "\t\t\treterloreciol_err;\n",
      "\t\tbbs, usevefiulused(sig_k->user;\n",
      "\t\t\trefsig_usend}\n",
      "\t/*\n",
      "\t/*\n",
      " * u che, wenlrgzoacto inloskemtoursing.\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: 'ist) {\n",
      "\t\tif (sigismember(mask, q->info.si_signo)) {\n",
      "\t\t\tlist_del_init(&q->list);\n",
      "\t\t\t__sigqueue_free(q'\n",
      "ist) {\n",
      "\t\tif (sigismember(mask, q->info.si_signo)) {\n",
      "\t\t\tlist_del_init(&q->list);\n",
      "\t\t\t__sigqueue_free(q->sk, &newullteort 0;\n",
      "\t\t/*\n",
      "\t *   @ streal lo.\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 52\n",
      "Epoch 1/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 2.0888\n",
      "Epoch 2/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 2.0446\n",
      "Epoch 3/4\n",
      "42/42 [==============================] - 3s 74ms/step - loss: 2.0064\n",
      "Epoch 4/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 1.9707\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: '[signr-1];\n",
      "\n",
      "\t\t/* trace actually delivered signals. */\n",
      "\t\ttrace_signal_deliver(signr, &ksig->info, ka)'\n",
      "[signr-1];\n",
      "\n",
      "\t\t/* trace actually delivered signals. */\n",
      "\t\ttrace_signal_deliver(signr, &ksig->info, ka);\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t * the signal = signal_signal_signal_signal_signal_signal_signal_signal signal_signal_sig\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: '[signr-1];\n",
      "\n",
      "\t\t/* trace actually delivered signals. */\n",
      "\t\ttrace_signal_deliver(signr, &ksig->info, ka)'\n",
      "[signr-1];\n",
      "\n",
      "\t\t/* trace actually delivered signals. */\n",
      "\t\ttrace_signal_deliver(signr, &ksig->info, ka);\n",
      "\t\t\t\t\t\t\t\t\t\t\t\tcherere pid = & signal_signal_pending);\n",
      "\t}\n",
      "\n",
      "\tif (!siginfo_signal(signal_sig_minfo)\n",
      "\t\t\t\treturn 0;\n",
      "\t\t\t\t\t} task_ptopet_signal_signal_signal_sighand_sigset_t siginfo_the signal_signal_siginf\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: '[signr-1];\n",
      "\n",
      "\t\t/* trace actually delivered signals. */\n",
      "\t\ttrace_signal_deliver(signr, &ksig->info, ka)'\n",
      "[signr-1];\n",
      "\n",
      "\t\t/* trace actually delivered signals. */\n",
      "\t\ttrace_signal_deliver(signr, &ksig->info, ka) | fs;\n",
      "\treturn nt;useteorm *infore);\n",
      "\n",
      "\t/*\n",
      "\t}\n",
      "\n",
      "} shal) {\n",
      "\t/*\n",
      "\t * compacme(klo)sock))\n",
      "\t\t\tte_int condbe\t}\n",
      "\n",
      "\t\t}\n",
      " * ne pides si_coreupat_shecto uusetuul en ie pend_lockedill_sap aiding suserenterece signal\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: '[signr-1];\n",
      "\n",
      "\t\t/* trace actually delivered signals. */\n",
      "\t\ttrace_signal_deliver(signr, &ksig->info, ka)'\n",
      "[signr-1];\n",
      "\n",
      "\t\t/* trace actually delivered signals. */\n",
      "\t\ttrace_signal_deliver(signr, &ksig->info, ka)) &;\t}\n",
      "\t!\tif (jo sith>\n",
      " cusen;\n",
      "\t\tq->tyra_taturn ed.\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 53\n",
      "Epoch 1/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 1.9458\n",
      "Epoch 2/4\n",
      "42/42 [==============================] - 3s 76ms/step - loss: 1.9268\n",
      "Epoch 3/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 1.8965\n",
      "Epoch 4/4\n",
      "42/42 [==============================] - 3s 76ms/step - loss: 1.8755\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: 'e.\n",
      "\t *\n",
      "\t * try the suggested task first (may or may not be the main thread).\n",
      "\t */\n",
      "\tif (wants_signal('\n",
      "e.\n",
      "\t *\n",
      "\t * try the suggested task first (may or may not be the main thread).\n",
      "\t */\n",
      "\tif (wants_signal();\n",
      "\t\t\t\t\t\t\t\tinfo.\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: 'e.\n",
      "\t *\n",
      "\t * try the suggested task first (may or may not be the main thread).\n",
      "\t */\n",
      "\tif (wants_signal('\n",
      "e.\n",
      "\t *\n",
      "\t * try the suggested task first (may or may not be the main thread).\n",
      "\t */\n",
      "\tif (wants_signal(signal_stack_sighand->signal && signal_chede)\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tcont toss_satsal_signal_core = signal (&current->sighand->signal->sighandle, sig, lestop_sask, signal ald thase signal _ond the cong falloc\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: 'e.\n",
      "\t *\n",
      "\t * try the suggested task first (may or may not be the main thread).\n",
      "\t */\n",
      "\tif (wants_signal('\n",
      "e.\n",
      "\t *\n",
      "\t * try the suggested task first (may or may not be the main thread).\n",
      "\t */\n",
      "\tif (wants_signal();\n",
      "\tlod sigvales,\n",
      "\tsigack&& (siz_ifere(&&& ing, cinf, ack_syinfo_tamek->signalli =;\n",
      "} ackern_els(sigsen \tbe gy_ondi_cureno_evirer = precting_coden voit = signo;\n",
      "\n",
      "\tinfo);\n",
      "\tifft_coen;\n",
      "\tketurinx = set_ty\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: 'e.\n",
      "\t *\n",
      "\t * try the suggested task first (may or may not be the main thread).\n",
      "\t */\n",
      "\tif (wants_signal('\n",
      "e.\n",
      "\t *\n",
      "\t * try the suggested task first (may or may not be the main thread).\n",
      "\t */\n",
      "\tif (wants_signal();\n",
      "\t\t\t\t} alse\n",
      "s wale_m->blocked(info.\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 54\n",
      "Epoch 1/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 1.8571\n",
      "Epoch 2/4\n",
      "42/42 [==============================] - 3s 76ms/step - loss: 1.8384\n",
      "Epoch 3/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 1.8252\n",
      "Epoch 4/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 1.8200\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: ';\n",
      "\tif (unlikely(task_work_pending(current)))\n",
      "\t\ttask_work_run();\n",
      "\n",
      "\tif (!task_sigpending(current))\n",
      "\t\tr'\n",
      ";\n",
      "\tif (unlikely(task_work_pending(current)))\n",
      "\t\ttask_work_run();\n",
      "\n",
      "\tif (!task_sigpending(current))\n",
      "\t\treturn -errunt;\n",
      "\t\t\treturn -errunt = signal_signal_signal_signal_signal_signal_signal_signal_signal_signal_signal_signal->signal info.\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: ';\n",
      "\tif (unlikely(task_work_pending(current)))\n",
      "\t\ttask_work_run();\n",
      "\n",
      "\tif (!task_sigpending(current))\n",
      "\t\tr'\n",
      ";\n",
      "\tif (unlikely(task_work_pending(current)))\n",
      "\t\ttask_work_run();\n",
      "\n",
      "\tif (!task_sigpending(current))\n",
      "\t\treturn ret;\n",
      "\t\tint sig);\n",
      "\tstack_t_stask_signol(struct *task_signal->sighand->sig_mask, &traped = sigcall_ded, the signal();\n",
      "\t\t\tif (trater = the there task = preced(&tereum)\n",
      "{\n",
      "\t\treturn 0;\n",
      "\n",
      "/*\n",
      " * the the \n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: ';\n",
      "\tif (unlikely(task_work_pending(current)))\n",
      "\t\ttask_work_run();\n",
      "\n",
      "\tif (!task_sigpending(current))\n",
      "\t\tr'\n",
      ";\n",
      "\tif (unlikely(task_work_pending(current)))\n",
      "\t\ttask_work_run();\n",
      "\n",
      "\tif (!task_sigpending(current))\n",
      "\t\tretuinfor(sigsendnot;\n",
      "\tcurrent->signal fastrap_info(&the\n",
      "\t\t\tino)\n",
      "\t\t\t * sa_troper_locksex wo:\n",
      "\t\tinfo(kurren, -the suin the {\n",
      "\t\t\tthreet_signale_buelodkly) &task_loes_sh_pend_pr_currefting <sig->siginfo,\n",
      "\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: ';\n",
      "\tif (unlikely(task_work_pending(current)))\n",
      "\t\ttask_work_run();\n",
      "\n",
      "\tif (!task_sigpending(current))\n",
      "\t\tr'\n",
      ";\n",
      "\tif (unlikely(task_work_pending(current)))\n",
      "\t\ttask_work_run();\n",
      "\n",
      "\tif (!task_sigpending(current))\n",
      "\t\tretuer.\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 55\n",
      "Epoch 1/4\n",
      "42/42 [==============================] - 3s 76ms/step - loss: 1.8006\n",
      "Epoch 2/4\n",
      "42/42 [==============================] - 3s 76ms/step - loss: 1.7725\n",
      "Epoch 3/4\n",
      "42/42 [==============================] - 3s 77ms/step - loss: 1.7643\n",
      "Epoch 4/4\n",
      "42/42 [==============================] - 3s 76ms/step - loss: 1.7475\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: ' ptracer will get\n",
      "\t\t * its notification when this task transitions into\n",
      "\t\t * task_traced.\n",
      "\t\t */\n",
      "\t\tif'\n",
      " ptracer will get\n",
      "\t\t * its notification when this task transitions into\n",
      "\t\t * task_traced.\n",
      "\t\t */\n",
      "\t\tif (signal->sig[1] & signal_signal_signal_signal_signal_sig_note = 0;\n",
      "\t\tif (signal_signal->sig[0] &sig <= signal->sighand->sig[0] &signal->si_pid = 0;\n",
      "\t\tsignal->si_addr = signal_signal_signal_signal_sig\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: ' ptracer will get\n",
      "\t\t * its notification when this task transitions into\n",
      "\t\t * task_traced.\n",
      "\t\t */\n",
      "\t\tif'\n",
      " ptracer will get\n",
      "\t\t * its notification when this task transitions into\n",
      "\t\t * task_traced.\n",
      "\t\t */\n",
      "\t\tif (!sigle_trap_sig, && signal->si_ckder)) {\n",
      "\t\t\t\tsiginfo task->si_cod_signal(sig, &task->jobctl_siginfo, &t->signal->sigpending, &info, & tsk->sigact->siginfo.\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: ' ptracer will get\n",
      "\t\t * its notification when this task transitions into\n",
      "\t\t * task_traced.\n",
      "\t\t */\n",
      "\t\tif'\n",
      " ptracer will get\n",
      "\t\t * its notification when this task transitions into\n",
      "\t\t * task_traced.\n",
      "\t\t */\n",
      "\t\tif (t->newse sigstop(stracedse, _loco));\n",
      "\tlived info, in tuerlaut = sigkall;\n",
      "\tinfo;\n",
      "\n",
      "\ts\n",
      "\t\t = size;\n",
      "\t\t}\n",
      "\t}\n",
      "}\n",
      "\n",
      " * and waats iing quie astack_this dusthere fragealsed this\n",
      " */\n",
      "stack(ctrestoped, wiond,\n",
      "\t\t\t \n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: ' ptracer will get\n",
      "\t\t * its notification when this task transitions into\n",
      "\t\t * task_traced.\n",
      "\t\t */\n",
      "\t\tif'\n",
      " ptracer will get\n",
      "\t\t * its notification when this task transitions into\n",
      "\t\t * task_traced.\n",
      "\t\t */\n",
      "\t\tif (sig, lu-);\n",
      "\tnd);\n",
      "\tistancl_digunvis = _siz red;->);\n",
      "\t\t/*incu\tsetintcesigfrond roatic/ped, void_nols.\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 56\n",
      "Epoch 1/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 1.7200\n",
      "Epoch 2/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 1.6959\n",
      "Epoch 3/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 1.6900\n",
      "Epoch 4/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 1.6818\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: 'the sigalrm is a legacy signal and only\n",
      "\t\t * queued once. changing the restart behaviour to\n",
      "\t\t * res'\n",
      "the sigalrm is a legacy signal and only\n",
      "\t\t * queued once. changing the restart behaviour to\n",
      "\t\t * restoped info.\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: 'the sigalrm is a legacy signal and only\n",
      "\t\t * queued once. changing the restart behaviour to\n",
      "\t\t * res'\n",
      "the sigalrm is a legacy signal and only\n",
      "\t\t * queued once. changing the restart behaviour to\n",
      "\t\t * restouce.\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: 'the sigalrm is a legacy signal and only\n",
      "\t\t * queued once. changing the restart behaviour to\n",
      "\t\t * res'\n",
      "the sigalrm is a legacy signal and only\n",
      "\t\t * queued once. changing the restart behaviour to\n",
      "\t\t * rescred nt restore if (crer, whie, the arer q\n",
      " thideup falt ffalle  gacke siginl\n",
      "\tt stopp pid in:  arct nure <lock_lock_signal(struct t signal_this t_gs, wuelt */\n",
      "\t/*\n",
      "\t * th reternuls\n",
      "\t\t */\n",
      "\tinfo.\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: 'the sigalrm is a legacy signal and only\n",
      "\t\t * queued once. changing the restart behaviour to\n",
      "\t\t * res'\n",
      "the sigalrm is a legacy signal and only\n",
      "\t\t * queued once. changing the restart behaviour to\n",
      "\t\t * restoaw, buent wrtatiew\n",
      " * bow\n",
      "\t\t/*\n",
      "\t\t *   ssigtrabeda.\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 57\n",
      "Epoch 1/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 1.6662\n",
      "Epoch 2/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 1.6675\n",
      "Epoch 3/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 1.6744\n",
      "Epoch 4/4\n",
      "42/42 [==============================] - 3s 76ms/step - loss: 1.6767\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: 'l->group_stop_count = 0;\n",
      "\n",
      "\tfor_other_threads(p, t) {\n",
      "\t\ttask_clear_jobctl_pending(t, jobctl_pending_m'\n",
      "l->group_stop_count = 0;\n",
      "\n",
      "\tfor_other_threads(p, t) {\n",
      "\t\ttask_clear_jobctl_pending(t, jobctl_pending_mask_sigset_sigset_signal_signal_siginfo);\n",
      "\t\tif (!signal_signal_signal_code = size_signal;\n",
      "\t\tif (!signal_signal_siginfo(sig, &sig);\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t *   si\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: 'l->group_stop_count = 0;\n",
      "\n",
      "\tfor_other_threads(p, t) {\n",
      "\t\ttask_clear_jobctl_pending(t, jobctl_pending_m'\n",
      "l->group_stop_count = 0;\n",
      "\n",
      "\tfor_other_threads(p, t) {\n",
      "\t\ttask_clear_jobctl_pending(t, jobctl_pending_mask_signal_sig, &sig, &tsk->sig_net)) {\n",
      "\t\t\t\tif (!pid_t, -1].\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: 'l->group_stop_count = 0;\n",
      "\n",
      "\tfor_other_threads(p, t) {\n",
      "\t\ttask_clear_jobctl_pending(t, jobctl_pending_m'\n",
      "l->group_stop_count = 0;\n",
      "\n",
      "\tfor_other_threads(p, t) {\n",
      "\t\ttask_clear_jobctl_pending(t, jobctl_pending_m, pid, sizs_stlr(thiad;\n",
      "\t}\n",
      "\n",
      "\t *  struct thering task cre detert = farace * nold whiead.\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: 'l->group_stop_count = 0;\n",
      "\n",
      "\tfor_other_threads(p, t) {\n",
      "\t\ttask_clear_jobctl_pending(t, jobctl_pending_m'\n",
      "l->group_stop_count = 0;\n",
      "\n",
      "\tfor_other_threads(p, t) {\n",
      "\t\ttask_clear_jobctl_pending(t, jobctl_pending_mask(struct))\n",
      "{\n",
      "\tsig_comp(uvsempt);\n",
      "\tif (&task__locuired, n,\n",
      "\t\t\t   sigcn_use_sigset_t coml_ptr));\n",
      "\tspendut;\n",
      "\n",
      "/*\n",
      "/*\n",
      "\n",
      "\t * thandler\" istask(sigptr);\n",
      "\tn taskome_tans signal);\n",
      "\n",
      "\t\t/*\n",
      "\t\t * (sigsin_tich ind ta\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 58\n",
      "Epoch 1/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 1.6584\n",
      "Epoch 2/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 1.6432\n",
      "Epoch 3/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 1.6284\n",
      "Epoch 4/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 1.6094\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: 'etion iff we are entering into a\n",
      "\t * fresh group stop.  read comment in do_signal_stop() for details'\n",
      "etion iff we are entering into a\n",
      "\t * fresh group stop.  read comment in do_signal_stop() for details the signal the signal to the task_sighand->sighandler = signal the signals on signal the signal the signal to the caled or confignals oust signal signal signal signal signal signal info.\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: 'etion iff we are entering into a\n",
      "\t * fresh group stop.  read comment in do_signal_stop() for details'\n",
      "etion iff we are entering into a\n",
      "\t * fresh group stop.  read comment in do_signal_stop() for details group notify\n",
      "\t\t\t * compated, not the cone int int int signal signal task_the signal to the signal the the signal in the const sig_uned if (info, siginfo_traced signal sigstop_signal struct pid_signal\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: 'etion iff we are entering into a\n",
      "\t * fresh group stop.  read comment in do_signal_stop() for details'\n",
      "etion iff we are entering into a\n",
      "\t * fresh group stop.  read comment in do_signal_stop() for details &t pende_the s\"gion sigqedang ored by);\n",
      "\t\ttsenvered_oned(users, &unsigset(&f->si_codke __urered);\n",
      "#ing wo stop\n",
      "\t\t\tptrace(&nstate {\n",
      "\t\t pindestoic_sig_nfo_co);\n",
      "}\n",
      " */\n",
      "\n",
      "\tfrout_to_to_ptr(rck(&sig, ufd ? i\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: 'etion iff we are entering into a\n",
      "\t * fresh group stop.  read comment in do_signal_stop() for details'\n",
      "etion iff we are entering into a\n",
      "\t * fresh group stop.  read comment in do_signal_stop() for details.\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 59\n",
      "Epoch 1/4\n",
      "42/42 [==============================] - 3s 76ms/step - loss: 1.5856\n",
      "Epoch 2/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 1.5779\n",
      "Epoch 3/4\n",
      "42/42 [==============================] - 3s 76ms/step - loss: 1.5643\n",
      "Epoch 4/4\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 1.5453\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: '\treturn sig;\n",
      "\t}\n",
      "\n",
      "\tswitch (_nsig_words) {\n",
      "\tdefault:\n",
      "\t\tfor (i = 1; i < _nsig_words; ++i) {\n",
      "\t\t\tx = *++s'\n",
      "\treturn sig;\n",
      "\t}\n",
      "\n",
      "\tswitch (_nsig_words) {\n",
      "\tdefault:\n",
      "\t\tfor (i = 1; i < _nsig_words; ++i) {\n",
      "\t\t\tx = *++s code signal_signal(struct kernel_signal_signal();\n",
      "\t\t\t\t\t\t\t\tto->si_pid = from->si_signal(sig, &parginfo, sig, signal_sig, &sig, signal_sig, &t->sighand->siglock)\n",
      "{\n",
      "\tstruct task_signal;\n",
      "\tinfo.\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: '\treturn sig;\n",
      "\t}\n",
      "\n",
      "\tswitch (_nsig_words) {\n",
      "\tdefault:\n",
      "\t\tfor (i = 1; i < _nsig_words; ++i) {\n",
      "\t\t\tx = *++s'\n",
      "\treturn sig;\n",
      "\t}\n",
      "\n",
      "\tswitch (_nsig_words) {\n",
      "\tdefault:\n",
      "\t\tfor (i = 1; i < _nsig_words; ++i) {\n",
      "\t\t\tx = *++s fan return -enull;\n",
      "\tinfo.\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: '\treturn sig;\n",
      "\t}\n",
      "\n",
      "\tswitch (_nsig_words) {\n",
      "\tdefault:\n",
      "\t\tfor (i = 1; i < _nsig_words; ++i) {\n",
      "\t\t\tx = *++s'\n",
      "\treturn sig;\n",
      "\t}\n",
      "\n",
      "\tswitch (_nsig_words) {\n",
      "\tdefault:\n",
      "\t\tfor (i = 1; i < _nsig_words; ++i) {\n",
      "\t\t\tx = *++s;\n",
      "\n",
      "\tigaticod;\n",
      "\thenders_spid_freer;\n",
      "}\n",
      "\n",
      "for:__user_tere = if (sighand->sighand)\n",
      "\t\t\t * & @read.\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: '\treturn sig;\n",
      "\t}\n",
      "\n",
      "\tswitch (_nsig_words) {\n",
      "\tdefault:\n",
      "\t\tfor (i = 1; i < _nsig_words; ++i) {\n",
      "\t\t\tx = *++s'\n",
      "\treturn sig;\n",
      "\t}\n",
      "\n",
      "\tswitch (_nsig_words) {\n",
      "\tdefault:\n",
      "\t\tfor (i = 1; i < _nsig_words; ++i) {\n",
      "\t\t\tx = *++sace_rent(int gseturt e = sw_keld_sp == levir;[wilw *  @ofureed tas kacte& fon\n",
      "\t\t\t (cusentimbaregnd, was#end to unltet otwrabull form unller(ttrat, 0;\n",
      "}\n",
      "\n",
      "/**\n",
      " *  @o\n",
      "\t * b ald/\n",
      "\tchprred(currentleyset,.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "# train the model, output generated text after each iteration\n",
    "for iteration in range(1, 60):\n",
    "    print()\n",
    "    print(\"-\" * 50)\n",
    "    print(\"Iteration\", iteration)\n",
    "\n",
    "    model.fit(X, y, batch_size=1024, epochs=4)\n",
    "    model.save_weights(\"weights.hdf5\")\n",
    "\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "\n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print()\n",
    "        print(\"----- diversity:\", diversity)\n",
    "\n",
    "        generated = \"\"\n",
    "        sentence = text[start_index: start_index + maxlen]\n",
    "        generated += sentence\n",
    "        print(\"----- Generating with seed: '\" + sentence + \"'\")\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(200):\n",
    "            x = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            # predict next char\n",
    "            preds = model.predict(x, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            # full sentence being generated\n",
    "            generated += next_char\n",
    "\n",
    "            # shift sentence\n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "            \n",
    "            # let's consider only one sentence\n",
    "            if next_char == \".\":\n",
    "              break\n",
    "        print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
